# ğŸ“˜ GuÃ­a Completa: Mantenimiento Predictivo en Represas con Machine Learning  
## Enfoque Profundo en Random Forest y ComparaciÃ³n con Otros Modelos

## 1. ğŸŒŠ SituaciÃ³n del problema: El desafÃ­o del mantenimiento en represas

### 1.1. Contexto operativo
Las represas son **infraestructuras crÃ­ticas** que:
- Almacenan agua para consumo humano, riego y generaciÃ³n hidroelÃ©ctrica.
- Controlan caudales para prevenir inundaciones.
- Soportan cargas hidrostÃ¡ticas, ambientales y estructurales extremas durante dÃ©cadas.

### 1.2. Consecuencias de una falla no anticipada
| Tipo de impacto | DescripciÃ³n |
|----------------|-------------|
| **Seguridad** | Riesgo de colapso, inundaciones, pÃ©rdida de vidas humanas |
| **Ambiental** | ContaminaciÃ³n por liberaciÃ³n de sedimentos, alteraciÃ³n de ecosistemas acuÃ¡ticos |
| **EconÃ³mico** | Costos de reparaciÃ³n de emergencia (hasta 10x mÃ¡s caros que mantenimiento preventivo) |
| **Operativo** | InterrupciÃ³n del suministro de agua o energÃ­a elÃ©ctrica |

### 1.3. Limitaciones de los enfoques tradicionales
| Enfoque | DescripciÃ³n | Problemas |
|--------|-------------|----------|
| **Correctivo** | Se actÃºa despuÃ©s de la falla | Alto riesgo, alto costo, daÃ±o colateral |
| **Preventivo por tiempo** | Mantenimiento programado cada X meses | Ineficiente: se mantiene lo que no necesita, se descuida lo que sÃ­ |
| **Preventivo por condiciÃ³n** | Inspecciones visuales periÃ³dicas | Subjetivo, costoso, no predictivo |

### 1.4. La soluciÃ³n con Machine Learning
El **mantenimiento predictivo** transforma datos en **acciones anticipadas**:
- **Predecir fallas 7 dÃ­as antes** de que ocurran.
- **Optimizar recursos**: intervenir solo cuando es necesario.
- **Reducir riesgos**: anticipar problemas crÃ­ticos con base en evidencia.

> **Objetivo del sistema**:  
> **Predecir si un componente crÃ­tico (compuerta, muro, turbina) fallarÃ¡ en los prÃ³ximos 7 dÃ­as**, usando datos de sensores, condiciones ambientales e historial de mantenimiento.

---

## 2. ğŸ¤– Modelos de Machine Learning para Mantenimiento Predictivo: AnÃ¡lisis Comparativo Profundo

### 2.1. CaracterÃ­sticas del problema en represas
Antes de elegir un modelo, debemos entender las **caracterÃ­sticas del problema**:

| CaracterÃ­stica | DescripciÃ³n | ImplicaciÃ³n para el modelo |
|---------------|-------------|---------------------------|
| **Datos desbalanceados** | Pocas fallas reales vs muchos dÃ­as sin falla (ej. 400 fallas / 1.3M observaciones) | El modelo debe manejar clases desbalanceadas |
| **Interpretabilidad** | Los ingenieros deben entender por quÃ© se predice una falla | Se requiere un modelo interpretable |
| **Robustez al ruido** | Los sensores pueden tener lecturas errÃ³neas | El modelo debe ser resistente a valores atÃ­picos |
| **No linealidades** | Las relaciones entre variables no son lineales (ej. presiÃ³n vs falla) | Se necesitan modelos no lineales |
| **CaracterÃ­sticas mixtas** | Variables numÃ©ricas (presiÃ³n) y derivadas (dÃ­as desde mantenimiento) | El modelo debe manejar ambos tipos |

---

### 2.2. ComparaciÃ³n detallada de modelos candidatos

#### ğŸ“Š Tabla comparativa: Random Forest vs Otros Modelos

| Criterio | **Random Forest** | RegresiÃ³n LogÃ­stica | SVM | Redes Neuronales | Ãrbol de DecisiÃ³n |
|---------|-------------------|---------------------|-----|------------------|-------------------|
| **Manejo de datos desbalanceados** | âœ… Excelente (con ajustes) | âŒ Pobre | âš ï¸ Moderado | âš ï¸ Requiere balanceo | âŒ Pobre |
| **Interpretabilidad** | âœ… Alta (importancia de variables) | âœ… Alta (coeficientes) | âŒ Baja | âŒ Muy baja | âœ… Alta |
| **Robustez al ruido** | âœ… Alta (promedio de Ã¡rboles) | âŒ Baja | âš ï¸ Moderada | âš ï¸ Moderada | âŒ Baja |
| **No linealidades** | âœ… Excelente | âŒ No maneja | âœ… Con kernels | âœ… Excelente | âœ… Buena |
| **Requiere normalizaciÃ³n** | âŒ No | âœ… SÃ­ | âœ… SÃ­ | âœ… SÃ­ | âŒ No |
| **Tiempo de entrenamiento** | âš ï¸ Moderado | âœ… RÃ¡pido | âŒ Lento (grandes datos) | âŒ Muy lento | âœ… RÃ¡pido |
| **ParÃ¡metros a ajustar** | âš ï¸ Pocos | âœ… Muy pocos | âŒ Muchos | âŒ Muchos | âœ… Pocos |
| **Sobreajuste** | âœ… Bajo (ensemble) | âœ… Bajo | âš ï¸ Moderado | âŒ Alto | âŒ Muy alto |

---

### 2.3. Â¿Por quÃ© Random Forest es la mejor opciÃ³n para represas?

#### âœ… Ventajas especÃ­ficas para el contexto de represas:

1. **Manejo natural de datos desbalanceados**  
   Random Forest puede ajustarse para dar mÃ¡s peso a la clase minoritaria (fallas) mediante el parÃ¡metro `class_weight='balanced'`, lo que es crucial cuando las fallas representan menos del 0.1% de los datos.

2. **Interpretabilidad operativa**  
   La **importancia de variables** permite a los ingenieros entender quÃ© factores contribuyen mÃ¡s a la predicciÃ³n:
   - Si `dias_desde_mant` es la variable mÃ¡s importante â†’ refuerza la importancia del mantenimiento periÃ³dico.
   - Si `vibracion_mm_s` es clave â†’ indica problemas mecÃ¡nicos inminentes.

3. **Robustez sin preprocesamiento complejo**  
   No requiere normalizaciÃ³n, maneja valores faltantes razonablemente bien, y es resistente a outliers (comÃºn en sensores).

4. **Captura de interacciones complejas**  
   Puede modelar relaciones no lineales como:  
   *"Alta presiÃ³n + alta humedad + muchos dÃ­as sin mantenimiento = alto riesgo"*  
   sin necesidad de crear manualmente variables de interacciÃ³n.

5. **Estabilidad y reproducibilidad**  
   El promedio de muchos Ã¡rboles reduce la varianza, haciendo que el modelo sea estable ante pequeÃ±os cambios en los datos.

#### ğŸ†š ComparaciÃ³n con casos especÃ­ficos:

- **vs RegresiÃ³n LogÃ­stica**:  
  La regresiÃ³n logÃ­stica asume relaciones lineales y no captura interacciones complejas sin ingenierÃ­a de caracterÃ­sticas manual. En represas, las relaciones son inherentemente no lineales.

- **vs Redes Neuronales**:  
  Aunque las redes neuronales pueden modelar cualquier funciÃ³n, son "cajas negras" que no permiten a los ingenieros entender por quÃ© se predice una falla. En infraestructuras crÃ­ticas, la interpretabilidad es tan importante como la precisiÃ³n.

- **vs Ãrbol de DecisiÃ³n individual**:  
  Un solo Ã¡rbol se sobreajusta fÃ¡cilmente a los datos de entrenamiento, especialmente con ruido en sensores. Random Forest promedia muchos Ã¡rboles, reduciendo drÃ¡sticamente el sobreajuste.

---

### 2.4. Â¿CuÃ¡ndo NO usar Random Forest?

Aunque Random Forest es ideal para la mayorÃ­a de escenarios de mantenimiento predictivo, hay casos donde otros modelos podrÃ­an ser mejores:

| Escenario | Modelo alternativo | RazÃ³n |
|----------|-------------------|-------|
| **Datos en tiempo real con latencia crÃ­tica** (< 10ms) | RegresiÃ³n LogÃ­stica | Random Forest es mÃ¡s lento en predicciÃ³n |
| **ImÃ¡genes de inspecciÃ³n visual** | Redes Neuronales Convolucionales | Random Forest no maneja imÃ¡genes |
| **Series temporales con patrones complejos** | LSTM | Random Forest no modela secuencias |
| **Dataset extremadamente grande** (> 10M filas) | XGBoost | MÃ¡s eficiente computacionalmente |

> **En el caso de represas con sensores tabulares**: **Random Forest sigue siendo la mejor opciÃ³n**.

---

## 3. ğŸ—ƒï¸ Modelo de datos para mantenimiento predictivo

### 3.1. Fuentes de datos y variables clave

| Fuente | Variables | Frecuencia | Importancia |
|--------|----------|------------|-------------|
| **Sensores IoT** | PresiÃ³n (bar), Humedad (%), VibraciÃ³n (mm/s), Temperatura (Â°C) | Cada hora | Alta: indican estado fÃ­sico |
| **Condiciones ambientales** | Lluvia acumulada (24h, 72h), Caudal del rÃ­o, Nivel del embalse | Diaria | Media: contexto operativo |
| **Historial de mantenimiento** | Fecha Ãºltimo mantenimiento, Tipo de mantenimiento, Componente intervenido | Eventual | Alta: predictor clave |
| **Registros de fallas** | Fecha, Tipo de falla, Gravedad, Componente afectado | Eventual | CrÃ­tica: etiqueta para supervisiÃ³n |

### 3.2. Modelo conceptual (entidades y relaciones)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Componente â”‚â”€â”€â”€â”€â”€â”€â”€â”‚   LecturaSensor  â”‚       â”‚   Evento    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â€¢ id_componente        â€¢ timestamp                â€¢ timestamp
â€¢ tipo                 â€¢ id_componente            â€¢ id_componente
â€¢ ubicacion            â€¢ presion_bar              â€¢ tipo_evento
â€¢ fecha_instalacion    â€¢ humedad_pct              â€¢ subtipo
                       â€¢ vibracion_mm_s           â€¢ gravedad
                       â€¢ temperatura_c
```

### 3.3. Dataset para Machine Learning (vista lÃ³gica)

Cada fila representa **una observaciÃ³n diaria por componente**:

| Campo | Tipo | DescripciÃ³n | Ejemplo |
|------|------|-------------|---------|
| `presion_bar` | float | PresiÃ³n promedio del dÃ­a | 1.45 |
| `humedad_pct` | float | Humedad relativa promedio | 78.2 |
| `vibracion_mm_s` | float | VibraciÃ³n promedio | 1.8 |
| `temperatura_c` | float | Temperatura promedio | 24.5 |
| `dias_desde_mant` | int | DÃ­as desde Ãºltimo mantenimiento | 142 |
| `lluvia_72h_mm` | float | Lluvia acumulada en 72h | 125.0 |
| `falla_prox_7d` | binario | **Etiqueta**: Â¿falla en prÃ³ximos 7 dÃ­as? | 1 |

> **Clave metodolÃ³gica**: la etiqueta `falla_prox_7d` se construye **mirando al futuro**, pero el modelo solo usa datos **hasta el momento de la predicciÃ³n** â†’ evita fuga de informaciÃ³n (data leakage).

---

## 4. ğŸ—‚ï¸ Estructura del proyecto y justificaciÃ³n

```
represa_ml/
â”‚
â”œâ”€â”€ data/                    â† Datos crudos y procesados
â”‚   â””â”€â”€ raw/                 â† CSV generados o reales
â”‚
â”œâ”€â”€ models/                  â† Modelos entrenados (.pkl)
â”‚
â”œâ”€â”€ reports/                 â† Informes PDF automÃ¡ticos
â”‚
â”œâ”€â”€ logs/                    â† Registros de ejecuciones programadas
â”‚
â”œâ”€â”€ src/                     â† CÃ³digo fuente modular
â”‚   â”œâ”€â”€ data_generation.py   â† Genera datos sintÃ©ticos
â”‚   â”œâ”€â”€ data_loader.py       â† Carga datos desde CSV
â”‚   â”œâ”€â”€ data_preparation.py  â† Crea features y etiquetas
â”‚   â”œâ”€â”€ model.py             â† Entrena y evalÃºa modelo
â”‚   â”œâ”€â”€ alerts.py            â† Gestiona alertas (sonora + correo)
â”‚   â”œâ”€â”€ email_alert.py       â† EnvÃ­a notificaciones por email
â”‚   â””â”€â”€ report_pdf.py        â† Genera informe PDF
â”‚
â”œâ”€â”€ scripts/                 â† AutomatizaciÃ³n
â”‚   â”œâ”€â”€ run_scheduled.py     â† Wrapper para tarea programada
â”‚   â””â”€â”€ schedule_daily_task.py â† Gestiona Task Scheduler
â”‚
â”œâ”€â”€ main.py                  â† Flujo principal de ejecuciÃ³n
â”œâ”€â”€ generate_data_cli.py     â† CLI para generar datos personalizados
â”œâ”€â”€ requirements.txt         â† Dependencias
â””â”€â”€ install_project.py       â† Instalador automÃ¡tico
```

### JustificaciÃ³n de la arquitectura
- **SeparaciÃ³n de responsabilidades**: cada mÃ³dulo tiene un propÃ³sito Ãºnico y claro.
- **Reproducibilidad**: datos, cÃ³digo y resultados estÃ¡n organizados para auditorÃ­a.
- **Escalabilidad**: fÃ¡cil agregar nuevos sensores, modelos o canales de alerta.
- **Mantenibilidad**: cÃ³digo modular, bien comentado y con manejo de errores.

---

## 5. ğŸ’» ImplementaciÃ³n en Python: CÃ³digos Completos y Explicados

*(Los cÃ³digos completos con comentarios detallados "Â¿para quÃ©?, Â¿por quÃ©?, Â¿cÃ³mo?" se mantienen igual que en la versiÃ³n anterior, ya que ya cumplen con los requisitos de documentaciÃ³n profunda.)*

---

## 6. ğŸ“Š EvaluaciÃ³n del modelo: MÃ©tricas explicadas para represas

### 6.1. Matriz de confusiÃ³n adaptada al contexto

|                     | **Predicho: Seguro** | **Predicho: Riesgo** |
|---------------------|----------------------|----------------------|
| **Real: Seguro**    | VN = Correcto        | FP = Falsa alarma    |
| **Real: Riesgo**    | **FN = FALLA NO DETECTADA** | VP = DetecciÃ³n correcta |

> **Prioridad operativa**: minimizar **FN** (falsos negativos), ya que representan fallas reales no detectadas.

### 6.2. MÃ©tricas clave y su interpretaciÃ³n

| MÃ©trica | FÃ³rmula | InterpretaciÃ³n en represas | Objetivo |
|--------|--------|----------------------------|----------|
| **Recall (Sensibilidad)** | VP / (VP + FN) | Â¿QuÃ© porcentaje de fallas reales detectamos? | **Maximizar** (> 70%) |
| **PrecisiÃ³n** | VP / (VP + FP) | Â¿QuÃ© porcentaje de alertas fueron reales? | Aceptar (> 70%) |
| **F1-Score** | 2Â·(PrecÂ·Rec)/(Prec+Rec) | Equilibrio entre precisiÃ³n y recall | > 0.75 |
| **Especificidad** | VN / (VN + FP) | Â¿QuÃ© porcentaje de dÃ­as seguros identificamos? | > 99% |

### 6.3. Umbral de decisiÃ³n
- **Umbral por defecto**: 0.5 (50% de probabilidad)
- **Umbral operativo en represas**: **0.7** (70% de probabilidad)
  - **RazÃ³n**: preferimos algunas falsas alarmas (FP) antes que fallas no detectadas (FN).

---

## 7. â–¶ï¸ Flujo de ejecuciÃ³n paso a paso

### Paso 1: Instalar el proyecto
```powershell
python install_project.py
cd represa_ml
venv\Scripts\activate
```

### Paso 2: Configurar notificaciones por correo
- Obtener contraseÃ±a de aplicaciÃ³n en Gmail.
- Configurar variables de entorno del sistema.

### Paso 3: Generar datos sintÃ©ticos densos
```powershell
python generate_data_cli.py --components 50 --days 1095 --freq-hours 1.0
```

### Paso 4: Ejecutar flujo completo
```powershell
python main.py
```

### Paso 5: Programar ejecuciÃ³n diaria
- Abrir PowerShell como administrador.
- Ejecutar:
  ```powershell
  python scripts/schedule_daily_task.py --install --hour 6
  ```

---

## 8. ğŸ“„ Resultados y salidas del sistema

### 8.1. Alertas multicanal
- **Sonora**: beep del sistema en Windows (centro de control).
- **Correo electrÃ³nico**: notificaciÃ³n a ingenieros remotos con PDF adjunto.

### 8.2. Informe PDF tÃ©cnico (5 secciones)
1. **Encabezado**: tÃ­tulo y fecha/hora de generaciÃ³n.
2. **Resumen de datos**: tamaÃ±o del dataset y grado de desbalance.
3. **MÃ©tricas del modelo**: precisiÃ³n, recall, F1-score por clase.
4. **Matriz de confusiÃ³n**: visualizaciÃ³n de tipos de errores.
5. **GrÃ¡fico de importancia**: quÃ© variables influyen mÃ¡s en las predicciones.

### 8.3. MÃ©tricas tÃ­picas esperadas
```
              precision    recall  f1-score   support
           0       1.00      1.00      1.00    262400
           1       0.85      0.76      0.80       400
```
- **Recall = 76%**: detectamos 76 de cada 100 fallas reales.
- **PrecisiÃ³n = 85%**: 85 de cada 100 alertas fueron reales.
- **F1-Score = 80%**: buen equilibrio para datos desbalanceados.

---

## 9. âœ… ConclusiÃ³n: Por quÃ© Random Forest es la elecciÃ³n Ã³ptima

Random Forest no es solo **uno mÃ¡s** de los modelos de Machine Learning; es la **elecciÃ³n Ã³ptima** para el mantenimiento predictivo en represas porque:

1. **Resuelve el problema principal**: maneja eficazmente la **extrema desbalanceo** de datos (pocas fallas).
2. **Proporciona interpretabilidad operativa**: los ingenieros pueden entender y confiar en las predicciones.
3. **Es robusto sin complejidad**: no requiere preprocesamiento sofisticado ni ajuste de muchos hiperparÃ¡metros.
4. **Captura la complejidad real**: modela interacciones no lineales entre variables sin intervenciÃ³n manual.
5. **Equilibra precisiÃ³n y practicidad**: ofrece un excelente rendimiento con implementaciÃ³n relativamente simple.

> **Impacto esperado**:  
> - **ReducciÃ³n del 30-50% en costos de mantenimiento** al evitar intervenciones innecesarias.  
> - **DisminuciÃ³n significativa del riesgo de fallas no anticipadas** gracias a la detecciÃ³n temprana.  
> - **Toma de decisiones basada en datos**, no en suposiciones o calendarios fijos.

---

**Â¿PrÃ³ximos pasos para la implementaciÃ³n real?**  
- Reemplazar datos sintÃ©ticos por lecturas reales de sensores IoT.  
- Integrar con sistemas SCADA existentes.  
- Agregar dashboard Streamlit para monitoreo en tiempo real.  
- Implementar reentrenamiento automÃ¡tico cuando hay nuevos datos de fallas.
