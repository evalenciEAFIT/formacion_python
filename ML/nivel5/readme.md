# Mantenimiento Predictivo en Represas con Machine Learning  
   
[Nivel 0: Buenas prÃ¡cticas](https://github.com/evalenciEAFIT/formacion_python/tree/main/ML/nivel0) | 
[Nivel 1: Uso de datos en SQL](https://github.com/evalenciEAFIT/formacion_python/tree/main/ML/nivel1) |
[Nivel 2: Uso Pandas](https://github.com/evalenciEAFIT/formacion_python/tree/main/ML/nivel2) |
[Nivel 3: Uso Dash](https://github.com/evalenciEAFIT/formacion_python/tree/main/ML/Nivel3) | 
[Nivel 4: Ejemplo Proyecto](https://github.com/evalenciEAFIT/formacion_python/tree/main/ML/nivel4) | 
[Nivel 5: Ejemplo Proyecto](https://github.com/evalenciEAFIT/formacion_python/tree/main/ML/nivel5)

---

# Modelos de Machine Learning para Servicios PÃºblicos

## **IntroducciÃ³n**

En sectores como la **gestiÃ³n de represas**, la **distribuciÃ³n de agua**, el **suministro de gas** o la **generaciÃ³n de energÃ­a hidroelÃ©ctrica**, el uso de Machine Learning permite mejorar la eficiencia, prevenir fallas, optimizar recursos y garantizar la continuidad del servicio. Esta guÃ­a explica de forma sencilla los principales modelos de ML, los problemas que resuelven y cÃ³mo se estructuran los datos en estos contextos.

---

## **A. Tipos de Problemas en Servicios PÃºblicos**

Antes de elegir un modelo, es clave identificar el **tipo de problema**:

| Tipo de problema | DescripciÃ³n | Ejemplo en servicios pÃºblicos |
|------------------|-------------|-------------------------------|
| **ClasificaciÃ³n** | Predecir una categorÃ­a o etiqueta | Â¿FallarÃ¡ una vÃ¡lvula en los prÃ³ximos 7 dÃ­as? (SÃ­/No) |
| **RegresiÃ³n** | Predecir un valor numÃ©rico continuo | Â¿CuÃ¡l serÃ¡ el nivel de agua en la represa maÃ±ana? |
| **DetecciÃ³n de anomalÃ­as** | Identificar comportamientos inusuales | Â¿Hay una fuga en la red de gas? |
| **Agrupamiento (Clustering)** | Agrupar datos similares sin etiquetas | Segmentar zonas con patrones similares de consumo de agua |
| **Series temporales** | Predecir valores futuros basados en el tiempo | Pronosticar demanda de electricidad por hora |

---

## **B. Modelos de Machine Learning y su AplicaciÃ³n**

### **B.1. RegresiÃ³n Lineal y RegresiÃ³n LogÃ­stica**

- **Problema que resuelve**:  
  - RegresiÃ³n lineal â†’ RegresiÃ³n  
  - RegresiÃ³n logÃ­stica â†’ ClasificaciÃ³n binaria  

- **Estructura de datos**:  
  Tabla con **caracterÃ­sticas (features)** numÃ©ricas/categÃ³ricas y una **variable objetivo** (numÃ©rica o binaria).

- **Ejemplo en represas**:  
  - *RegresiÃ³n lineal*: Predecir el caudal de salida de una represa segÃºn lluvia, nivel actual y temperatura.  
  - *RegresiÃ³n logÃ­stica*: Predecir si el nivel de sedimentos superarÃ¡ un umbral crÃ­tico (SÃ­/No).

---

### **B.2. Ãrboles de DecisiÃ³n y Bosques Aleatorios (Random Forest)**

- **Problema que resuelve**: ClasificaciÃ³n o regresiÃ³n  
- **Ventaja**: InterpretaciÃ³n fÃ¡cil, maneja datos no lineales y faltantes.

- **Estructura de datos**:  
  Tabla con mÃºltiples variables (presiÃ³n, caudal, temperatura, estado de vÃ¡lvulas, etc.).

- **Ejemplo en distribuciÃ³n de agua**:  
  - Predecir zonas con alto riesgo de rotura de tuberÃ­as usando edad de la red, presiÃ³n, tipo de material y clima.

---

### **B.3. MÃ¡quinas de Soporte Vectorial (SVM)**

- **Problema que resuelve**: ClasificaciÃ³n (principalmente), tambiÃ©n regresiÃ³n (SVR)  
- **Ãštil cuando**: Hay pocos datos pero muchas caracterÃ­sticas.

- **Estructura de datos**:  
  Datos normalizados, con pocas observaciones pero muchas variables tÃ©cnicas (sensores, alarmas, etc.).

- **Ejemplo en gasoductos**:  
  - Clasificar si una lectura de presiÃ³n indica una fuga inminente.

---

### **B.4. Redes Neuronales (incluyendo LSTM para series temporales)**

- **Problema que resuelve**:  
  - Redes densas â†’ RegresiÃ³n/clasificaciÃ³n compleja  
  - LSTM â†’ PredicciÃ³n en series temporales

- **Estructura de datos**:  
  - Para LSTM: Secuencias temporales (ej. mediciones horarias de los Ãºltimos 30 dÃ­as)  
  - Para redes densas: Tablas con muchas variables

- **Ejemplo en energÃ­a**:  
  - LSTM: Predecir generaciÃ³n hidroelÃ©ctrica diaria usando datos histÃ³ricos de lluvia, caudal y demanda.  
  - Red densa: Detectar fallas en turbinas a partir de vibraciones, temperatura y ruido.

---

### **B.5. Modelos de DetecciÃ³n de AnomalÃ­as (Isolation Forest, Autoencoders)**

- **Problema que resuelve**: DetecciÃ³n de comportamientos atÃ­picos  
- **Estructura de datos**:  
  - Datos sin etiquetas (no se sabe quÃ© es â€œnormalâ€ o â€œanÃ³maloâ€ a priori)  
  - Solo se usan las variables de entrada (sensores, caudales, presiones)

- **Ejemplo en represas**:  
  - Detectar fugas no reportadas en canales de derivaciÃ³n al identificar caudales de salida inconsistentes con los de entrada.

---

### **B.6. Clustering (K-Means, DBSCAN)**

- **Problema que resuelve**: Agrupar zonas o equipos con comportamientos similares  
- **Estructura de datos**:  
  Tabla con mÃ©tricas de operaciÃ³n (consumo, presiÃ³n, mantenimientos, etc.)

- **Ejemplo en agua potable**:  
  - Agrupar barrios por patrones de consumo para ajustar horarios de bombeo o detectar fraudes.

---

## **C. ComparaciÃ³n General de Modelos**

| Modelo | Tipo de problema | Interpretabilidad | Requiere muchos datos | Maneja datos temporales | Ideal para sensores IoT |
|--------|------------------|-------------------|------------------------|--------------------------|--------------------------|
| RegresiÃ³n lineal | RegresiÃ³n | Alta | No | No | SÃ­ (simple) |
| RegresiÃ³n logÃ­stica | ClasificaciÃ³n | Alta | No | No | SÃ­ |
| Ãrboles / Random Forest | Clasif./Reg. | Media-Alta | No-Media | No | SÃ­ |
| SVM | Clasif./Reg. | Baja | SÃ­ (en alta dimensiÃ³n) | No | Limitado |
| Redes Neuronales | Cualquiera | Baja | SÃ­ | SÃ­ (con LSTM) | SÃ­ (con suficientes datos) |
| Isolation Forest | AnomalÃ­as | Media | No | No | SÃ­ |
| K-Means | Clustering | Media | No | No | SÃ­ |

---

## **D. Recomendaciones para tu Proyecto de Monitoreo de Represas**

1. **Para mantenimiento predictivo**: Usa **Random Forest** o **XGBoost** (mÃ¡s potente) para predecir fallas en compuertas o sensores.
2. **Para pronÃ³stico de niveles**: Usa **LSTM** o modelos clÃ¡sicos como **ARIMA** si los datos son estacionales.
3. **Para detecciÃ³n de fugas o errores de mediciÃ³n**: Implementa **Isolation Forest** o **Autoencoders**.
4. **Para priorizar intervenciones**: Combina **clustering** (zonas similares) + **clasificaciÃ³n** (riesgo de falla).

---

Elegir el modelo adecuado depende del **tipo de problema**, la **calidad y cantidad de datos**, y la necesidad de **interpretabilidad**. En servicios pÃºblicos, donde la seguridad y la transparencia son crÃ­ticas, modelos como **Ã¡rboles de decisiÃ³n** o **regresiÃ³n logÃ­stica** suelen ser buenos puntos de partida. 

--- 
## 1. ğŸŒŠ SituaciÃ³n del problema

Las represas son infraestructuras crÃ­ticas donde las fallas no anticipadas pueden causar riesgos de seguridad, impacto ambiental y altos costos operativos. El mantenimiento predictivo con Machine Learning permite **predecir fallas 7 dÃ­as antes** de que ocurran.

---

## â“ Â¿QuÃ© preguntas puede responder el ML?

| Tipo de pregunta | Ejemplo concreto |
|------------------|------------------|
| **ClasificaciÃ³n binaria** | Â¿FallarÃ¡ el componente X en los prÃ³ximos 7 dÃ­as? (SÃ­/No) |
| **RegresiÃ³n** | Â¿CuÃ¡ntos dÃ­as faltan para que el sellado de la compuerta falle? |
| **DetecciÃ³n de anomalÃ­as** | Â¿Es anÃ³malo el aumento repentino de presiÃ³n en el muro este? |
| **PriorizaciÃ³n** | Â¿QuÃ© componente tiene mayor riesgo hoy y debe revisarse primero? |

## 2. ğŸ¤– Â¿Por quÃ© Random Forest es la mejor opciÃ³n?

### Random Forest
- **Â¿QuÃ© es?** Un conjunto de Ã¡rboles de decisiÃ³n entrenados con datos y variables aleatorias.
- **Â¿Por quÃ© usarlo?**  
  - Maneja bien datos desbalanceados (pocas fallas).  
  - No requiere normalizaciÃ³n.  
  - Proporciona **importancia de variables** â†’ interpretable.  
- **Â¿CÃ³mo funciona?** Cada Ã¡rbol vota; la mayorÃ­a decide.

### MÃ©tricas clave
| MÃ©trica | FÃ³rmula | Â¿Por quÃ© importa en represas? |
|--------|--------|-------------------------------|
| **PrecisiÃ³n** | VP / (VP + FP) | Reduce falsas alarmas (evita paradas innecesarias) |
| **Recall** | VP / (VP + FN) | **Prioridad**: detectar la mayor cantidad de fallas reales |
| **F1-Score** | 2Â·(PrecÂ·Rec)/(Prec+Rec) | Equilibrio cuando hay desbalance |

> En mantenimiento predictivo: **maximizar recall**, aunque aumente ligeramente las falsas alarmas.

### ComparaciÃ³n con otros modelos:

| Criterio | **Random Forest** | RegresiÃ³n LogÃ­stica | Redes Neuronales |
|---------|-------------------|---------------------|------------------|
| **Datos desbalanceados** | âœ… Excelente | âŒ Pobre | âš ï¸ Requiere balanceo |
| **Interpretabilidad** | âœ… Alta (importancia de variables) | âœ… Alta | âŒ Muy baja |
| **Robustez al ruido** | âœ… Alta | âŒ Baja | âš ï¸ Moderada |
| **No linealidades** | âœ… Excelente | âŒ No maneja | âœ… Excelente |
| **Requiere normalizaciÃ³n** | âŒ No | âœ… SÃ­ | âœ… SÃ­ |

**ConclusiÃ³n**: Random Forest es ideal para represas porque maneja datos desbalanceados, es interpretable y robusto sin requerir preprocesamiento complejo.

---

## 3. ğŸ—ƒï¸ Modelo de datos

### Fuentes de datos:
- **Sensores**: presiÃ³n, humedad, vibraciÃ³n, temperatura
- **Ambientales**: lluvia acumulada, caudal
- **HistÃ³ricos**: mantenimientos y fallas

### Dataset para ML:
| Campo | DescripciÃ³n |
|------|-------------|
| `presion_bar` | PresiÃ³n promedio del dÃ­a |
| `humedad_pct` | Humedad relativa promedio |
| `vibracion_mm_s` | VibraciÃ³n promedio |
| `dias_desde_mant` | DÃ­as desde Ãºltimo mantenimiento |
| `falla_prox_7d` | Etiqueta: Â¿falla en prÃ³ximos 7 dÃ­as? |

---

## 4. ğŸ—‚ï¸ Estructura del proyecto

```
represa_ml/
â”œâ”€â”€ install_project.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ main.py
â”œâ”€â”€ generate_data_cli.py
â”œâ”€â”€ data/raw/
â”œâ”€â”€ models/
â”œâ”€â”€ reports/
â”œâ”€â”€ logs/
â”œâ”€â”€ scripts/
â””â”€â”€ src/
```

---

## 5. ğŸ’» CÃ³digos en Python

### ğŸ“„ `install_project.py`
```python
"""
install_project.py

Â¿PARA QUÃ‰?
- Crear la estructura completa del proyecto con un solo comando.

Â¿POR QUÃ‰?
- Automatiza la configuraciÃ³n inicial.
- AÃ­sla dependencias en un entorno virtual.
- Evita errores manuales.

Â¿CÃ“MO?
1. Crea directorios y archivos vacÃ­os.
2. Genera requirements.txt con dependencias.
3. Crea entorno virtual (venv).
4. Instala paquetes automÃ¡ticamente.
"""

import os
import sys
import subprocess
import venv

PROJECT_NAME = "represa_ml"
REQUIREMENTS = [
    "pandas", "numpy", "scikit-learn", "streamlit",
    "joblib", "matplotlib", "reportlab"
]

ARCHIVOS = [
    "requirements.txt",
    "main.py",
    "generate_data_cli.py",
    "src/__init__.py",
    "src/data_generation.py",
    "src/data_loader.py",
    "src/data_preparation.py",
    "src/model.py",
    "src/alerts.py",
    "src/email_alert.py",
    "src/report_pdf.py",
    "scripts/run_scheduled.py",
    "scripts/schedule_daily_task.py"
]

DIRECTORIOS = ["data", "models", "reports", "logs", "scripts", "src"]

def crear_estructura(base_path):
    for d in DIRECTORIOS:
        os.makedirs(os.path.join(base_path, d), exist_ok=True)
    with open(os.path.join(base_path, "requirements.txt"), "w") as f:
        f.write("\n".join(REQUIREMENTS))
    for archivo in ARCHIVOS:
        if archivo == "requirements.txt": continue
        ruta = os.path.join(base_path, archivo)
        dir_name = os.path.dirname(ruta)
        if dir_name: os.makedirs(dir_name, exist_ok=True)
        with open(ruta, "w") as f: pass

def main():
    if os.path.basename(os.getcwd()) == PROJECT_NAME:
        print("âš ï¸ Ejecuta desde una carpeta PADRE.")
        sys.exit(1)
    base_dir = os.path.abspath(PROJECT_NAME)
    env_dir = os.path.join(base_dir, "venv")
    print(f"ğŸš€ Creando proyecto '{PROJECT_NAME}'...")
    os.makedirs(base_dir, exist_ok=True)
    crear_estructura(base_dir)
    venv.create(env_dir, with_pip=True)
    python_exe = os.path.join(env_dir, "Scripts", "python.exe")
    subprocess.check_call([python_exe, "-m", "pip", "install", "-r", os.path.join(base_dir, "requirements.txt")])
    print("\nğŸ‰ Â¡Listo! Activa el entorno con:\n   represa_ml\\venv\\Scripts\\activate")

if __name__ == "__main__":
    main()
```

---

### ğŸ“„ `generate_data_cli.py`
```python
"""
generate_data_cli.py

Â¿PARA QUÃ‰?
- Generar datos sintÃ©ticos densos desde la lÃ­nea de comandos.

Â¿POR QUÃ‰?
- Permite simular desde miles hasta millones de registros.
- Ãštil para pruebas de escalabilidad.

Â¿CÃ“MO?
- Usa argparse para recibir parÃ¡metros.
- Llama a la funciÃ³n de generaciÃ³n con esos valores.
"""

import argparse
from src.data_generation import generate_and_save_dummy_data

def main():
    parser = argparse.ArgumentParser(description="Genera datos sintÃ©ticos para represa.")
    parser.add_argument("--components", type=int, default=5, help="NÃºmero de componentes")
    parser.add_argument("--days", type=int, default=365, help="DÃ­as a simular")
    parser.add_argument("--freq-hours", type=float, default=1.0, help="Frecuencia en horas")
    parser.add_argument("--output", default="data/raw", help="Carpeta de salida")
    parser.add_argument("--seed", type=int, default=42, help="Semilla")
    args = parser.parse_args()
    generate_and_save_dummy_data(
        days=args.days,
        n_components=args.components,
        freq_hours=args.freq_hours,
        seed=args.seed,
        output_dir=args.output
    )

if __name__ == "__main__":
    main()
```

---

### ğŸ“„ `src/data_generation.py`
```python
"""
src/data_generation.py

Â¿PARA QUÃ‰?
- Generar datos sintÃ©ticos realistas y densos para sensores y eventos.

Â¿POR QUÃ‰?
- Permite probar el sistema sin sensores reales.
- Escalable: desde miles hasta millones de registros.
- Guarda en CSV para reutilizaciÃ³n.

Â¿CÃ“MO?
- Usa operaciones vectorizadas de pandas (rÃ¡pido y eficiente).
- Simula tendencias estacionales y ruido.
- Genera mantenimientos y fallas con lÃ³gica realista.
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import os

def generate_and_save_dummy_data(days=365, n_components=5, freq_hours=1, seed=42, output_dir="data/raw"):
    np.random.seed(seed)
    os.makedirs(output_dir, exist_ok=True)
    componentes = [f"compuerta_{i+1}" for i in range(n_components)]
    start_date = datetime(2024, 1, 1)
    freq_str = f"{int(freq_hours * 60)}min" if freq_hours < 1 else f"{int(freq_hours)}h"
    total_steps = int(days * 24 / freq_hours)
    dates = pd.date_range(start=start_date, periods=total_steps, freq=freq_str)
    print(f"ğŸ“… Generando datos: {n_components} componentes, {days} dÃ­as, cada {freq_hours}h â†’ {total_steps * n_components:,} registros...")
    time_series = pd.Series(dates.repeat(n_components))
    comp_series = pd.Series(componentes * total_steps)
    day_of_year = time_series.dt.dayofyear
    month = time_series.dt.month
    presion = 1.0 + 0.3 * np.sin(day_of_year / 365 * 2 * np.pi) + np.random.normal(0, 0.1, size=len(time_series))
    humedad = 60 + 20 * np.sin(month / 12 * 2 * np.pi) + np.random.normal(0, 5, size=len(time_series))
    vibracion = 0.5 + np.random.exponential(0.2, size=len(time_series))
    temperatura = 20 + 10 * np.sin(day_of_year / 365 * 2 * np.pi) + np.random.normal(0, 2, size=len(time_series))
    df_sensores = pd.DataFrame({
        'timestamp': time_series,
        'id_componente': comp_series,
        'presion_bar': np.clip(presion, 0.5, None),
        'humedad_pct': np.clip(humedad, 20, 100),
        'vibracion_mm_s': vibracion,
        'temperatura_c': temperatura
    })
    eventos = []
    for comp in componentes:
        maint_dates = [start_date + timedelta(days=d) for d in range(0, days, 90)]
        for md in maint_dates:
            eventos.append({'timestamp': md, 'id_componente': comp, 'tipo_evento': 'mantenimiento', 'subtipo': 'preventivo', 'gravedad': 'baja'})
        n_fallas = max(2, int(10 * days / 365))
        for _ in range(n_fallas):
            dias = np.random.randint(10, days)
            falla_date = start_date + timedelta(days=dias)
            if any(abs((falla_date - md).days) < 15 for md in maint_dates):
                continue
            eventos.append({'timestamp': falla_date, 'id_componente': comp, 'tipo_evento': 'falla', 'subtipo': np.random.choice(['fuga', 'bloqueo', 'corrosion']), 'gravedad': np.random.choice(['baja', 'media', 'alta'])})
    df_eventos = pd.DataFrame(eventos)
    df_sensores.to_csv(os.path.join(output_dir, "sensores.csv"), index=False)
    df_eventos.to_csv(os.path.join(output_dir, "eventos.csv"), index=False)
    print(f"âœ… Datos guardados: {len(df_sensores):,} lecturas, {len(df_eventos):,} eventos.")
    return df_sensores, df_eventos
```

---

### ğŸ“„ `src/data_loader.py`
```python
"""
src/data_loader.py

Â¿PARA QUÃ‰?
- Cargar datos desde archivos CSV.

Â¿POR QUÃ‰?
- Desacopla generaciÃ³n de datos del entrenamiento.
- Permite usar datos reales sin cambiar cÃ³digo.

Â¿CÃ“MO?
- Lee sensores.csv y eventos.csv.
- Convierte timestamp a datetime.
"""

import pandas as pd
import os

def load_data_from_csv(data_dir="data/raw"):
    sensores_path = os.path.join(data_dir, "sensores.csv")
    eventos_path = os.path.join(data_dir, "eventos.csv")
    if not os.path.exists(sensores_path):
        raise FileNotFoundError("Ejecuta generate_data_cli.py primero.")
    df_sensores = pd.read_csv(sensores_path, parse_dates=['timestamp'])
    df_eventos = pd.read_csv(eventos_path, parse_dates=['timestamp'])
    return df_sensores, df_eventos
```

---

### ğŸ“„ `src/data_preparation.py`
```python
"""
src/data_preparation.py

Â¿PARA QUÃ‰?
- Transformar datos crudos en dataset listo para ML.

Â¿POR QUÃ‰?
- El modelo necesita una observaciÃ³n por dÃ­a.
- La etiqueta debe construirse sin fuga de informaciÃ³n.

Â¿CÃ“MO?
1. Resamplea a diario.
2. Calcula dÃ­as desde Ãºltimo mantenimiento.
3. Crea etiqueta: Â¿falla en prÃ³ximos 7 dÃ­as?
"""

import pandas as pd
import numpy as np

def create_ml_dataset(df_sensores, df_eventos):
    df_fallas = df_eventos[df_eventos['tipo_evento'] == 'falla'][['timestamp', 'id_componente']].copy()
    df_fallas = df_fallas.rename(columns={'timestamp': 'falla_timestamp'})
    df_sensores['date'] = df_sensores['timestamp'].dt.floor('D')
    df_daily = df_sensores.groupby(['id_componente', 'date']).agg({
        'presion_bar': 'mean',
        'humedad_pct': 'mean',
        'vibracion_mm_s': 'mean',
        'temperatura_c': 'mean'
    }).reset_index()
    df_mant = df_eventos[df_eventos['tipo_evento'] == 'mantenimiento'][['timestamp', 'id_componente']].copy()
    df_mant = df_mant.rename(columns={'timestamp': 'mant_timestamp'})
    df_daily['dias_desde_mant'] = df_daily.apply(
        lambda row: min([
            (row['date'] - mant_row['mant_timestamp']).days
            for _, mant_row in df_mant[df_mant['id_componente'] == row['id_componente']].iterrows()
            if row['date'] >= mant_row['mant_timestamp']
        ], default=365), axis=1
    )
    df_daily['falla_prox_7d'] = df_daily.apply(
        lambda row: any(
            (falla_row['falla_timestamp'] > row['date']) and
            (falla_row['falla_timestamp'] <= row['date'] + pd.Timedelta(days=7)) and
            (falla_row['id_componente'] == row['id_componente'])
            for _, falla_row in df_fallas.iterrows()
        ), axis=1
    ).astype(int)
    cutoff_date = df_daily['date'].max() - pd.Timedelta(days=7)
    return df_daily[df_daily['date'] <= cutoff_date].copy()
```

---

### ğŸ“„ `src/model.py`
```python
"""
src/model.py

Â¿PARA QUÃ‰?
- Entrenar modelo y evaluar desempeÃ±o.

Â¿POR QUÃ‰?
- Random Forest es ideal para datos desbalanceados.
- Documenta resultados en PDF para auditorÃ­a.

Â¿CÃ“MO?
1. Divide datos (estratificado).
2. Entrena Random Forest.
3. EvalÃºa con mÃ©tricas (sin advertencias).
4. Genera informe PDF.
"""

import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import joblib
import os
from .report_pdf import generate_pdf_report

FEATURES = ['presion_bar', 'humedad_pct', 'vibracion_mm_s', 'temperatura_c', 'dias_desde_mant']
TARGET = 'falla_prox_7d'

def train_model(df, model_path='models/maintenance_model.pkl', generate_report=True):
    X = df[FEATURES]
    y = df[TARGET]
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    report_str = classification_report(y_test, y_pred, zero_division=0)
    cm = confusion_matrix(y_test, y_pred)
    os.makedirs(os.path.dirname(model_path), exist_ok=True)
    joblib.dump(model, model_path)
    pdf_path = None
    if generate_report:
        pdf_path = generate_pdf_report(report_str, cm, FEATURES, model.feature_importances_, len(df), int(y.sum()))
    return model, pdf_path

def load_model(model_path='models/maintenance_model.pkl'):
    return joblib.load(model_path)
```

---

### ğŸ“„ `src/alerts.py`
```python
"""
src/alerts.py

Â¿PARA QUÃ‰?
- Centralizar alertas (sonora + correo).

Â¿POR QUÃ‰?
- Separa lÃ³gica de alertas del entrenamiento.
- Facilita agregar nuevos canales.

Â¿CÃ“MO?
- Verifica umbral de probabilidad.
- Emite sonido en Windows.
- Llama a funciÃ³n de correo.
"""

import os
from .email_alert import send_email_alert

def emit_alert_if_high_risk(probability: float, threshold: float = 0.7, latest_report_path: str = None):
    if probability <= threshold:
        return
    if os.name == 'nt':
        try:
            import winsound
            winsound.MessageBeep(winsound.MB_ICONEXCLAMATION)
            print("ğŸ”Š Â¡ALERTA SONORA ACTIVADA!")
        except Exception as e:
            print(f"âš ï¸ Error en alerta sonora: {e}")
    send_email_alert(probability, threshold, latest_report_path)
```

---

### ğŸ“„ `src/email_alert.py`
```python
"""
src/email_alert.py

Â¿PARA QUÃ‰?
- Enviar notificaciones por correo.

Â¿POR QUÃ‰?
- Alerta a personal remoto.
- Deja registro escrito.

Â¿CÃ“MO?
- Usa variables de entorno para credenciales.
- Adjunta informe PDF.
- Usa SMTP de Gmail (cambiable).
"""

import smtplib
import os
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from email.mime.base import MIMEBase
from email import encoders
from datetime import datetime

def send_email_alert(probability: float, threshold: float = 0.7, latest_report_path: str = None):
    if probability <= threshold:
        return
    sender = os.getenv("ALERT_EMAIL_USER")
    password = os.getenv("ALERT_EMAIL_PASS")
    recipients = os.getenv("ALERT_EMAIL_RECIPIENTS", "").split(",")
    if not sender or not password or not recipients[0]:
        print("ğŸ“§ Correo no configurado.")
        return
    try:
        msg = MIMEMultipart()
        msg["From"] = sender
        msg["To"] = ", ".join(recipients)
        msg["Subject"] = "ğŸš¨ ALERTA: Alto riesgo de falla en represa"
        body = f"""
        Se ha detectado un alto riesgo de falla en un componente de la represa.
        - Probabilidad: {probability:.2%}
        - Umbral: {threshold:.0%}
        - Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
        Revise el sistema inmediatamente.
        """
        msg.attach(MIMEText(body, "plain"))
        if latest_report_path and os.path.exists(latest_report_path):
            with open(latest_report_path, "rb") as f:
                part = MIMEBase("application", "octet-stream")
                part.set_payload(f.read())
            encoders.encode_base64(part)
            part.add_header("Content-Disposition", f"attachment; filename= {os.path.basename(latest_report_path)}")
            msg.attach(part)
        server = smtplib.SMTP("smtp.gmail.com", 587)
        server.starttls()
        server.login(sender, password)
        server.sendmail(sender, recipients, msg.as_string())
        server.quit()
        print("ğŸ“§ Correo de alerta enviado.")
    except Exception as e:
        print(f"âŒ Error al enviar correo: {e}")
```

---

### ğŸ“„ `src/report_pdf.py`
```python
"""
src/report_pdf.py

Â¿PARA QUÃ‰?
- Generar informe PDF con resultados.

Â¿POR QUÃ‰?
- Formato estÃ¡ndar para reportes tÃ©cnicos.
- Incluye mÃ©tricas y grÃ¡ficos.

Â¿CÃ“MO?
- Usa reportlab para PDF.
- Matplotlib para grÃ¡fico de importancia.
"""

import os
from datetime import datetime
from reportlab.lib.pagesizes import A4
from reportlab.pdfgen import canvas
from reportlab.lib import colors
from reportlab.platypus import Table, TableStyle
import matplotlib.pyplot as plt
import io
from reportlab.lib.utils import ImageReader

def generate_pdf_report(report_str, cm, feature_names, importances, n_samples, n_failures, output_dir="reports"):
    os.makedirs(output_dir, exist_ok=True)
    pdf_path = os.path.join(output_dir, f"reporte_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf")
    plt.figure(figsize=(6, 4))
    plt.barh(feature_names, importances, color='steelblue')
    plt.xlabel("Importancia")
    plt.title("Importancia de Variables")
    plt.tight_layout()
    img_buffer = io.BytesIO()
    plt.savefig(img_buffer, format='png')
    img_buffer.seek(0)
    plt.close()
    c = canvas.Canvas(pdf_path, pagesize=A4)
    width, height = A4
    c.setFont("Helvetica-Bold", 16)
    c.drawString(50, height - 50, "Informe de Mantenimiento Predictivo - Represa")
    c.setFont("Helvetica", 10)
    c.drawString(50, height - 70, f"Generado: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    c.drawString(50, height - 100, f"â€¢ Muestras: {n_samples}, Fallas: {n_failures}")
    y = height - 130
    for line in report_str.split("\n"):
        if line.strip() and y > 100:
            c.drawString(50, y, line)
            y -= 15
    c.showPage()
    cm_data = [["", "Pred: 0", "Pred: 1"], ["Real: 0", str(cm[0][0]), str(cm[0][1])], ["Real: 1", str(cm[1][0]), str(cm[1][1])]]
    cm_table = Table(cm_data)
    cm_table.setStyle(TableStyle([('BACKGROUND', (0,0), (-1,0), colors.grey), ('GRID', (0,0), (-1,-1), 1, colors.black)]))
    cm_table.wrapOn(c, width, height)
    cm_table.drawOn(c, 50, height - 150)
    c.showPage()
    c.drawImage(ImageReader(img_buffer), 50, height - 400, width=500, height=300)
    c.save()
    return pdf_path
```

---

### ğŸ“„ `main.py`
```python
"""
main.py

Â¿PARA QUÃ‰?
- Orquestar flujo completo.

Â¿POR QUÃ‰?
- Punto de entrada principal.
- Genera datos por defecto si no existen.

Â¿CÃ“MO?
1. Verifica existencia de CSV.
2. Genera o carga datos.
3. Entrena modelo.
4. Activa alertas.
"""

from src.data_generation import generate_and_save_dummy_data
from src.data_loader import load_data_from_csv
from src.data_preparation import create_ml_dataset
from src.model import train_model, FEATURES
from src.alerts import emit_alert_if_high_risk
import pandas as pd
import os

def main():
    data_dir = "data/raw"
    sensores_path = os.path.join(data_dir, "sensores.csv")
    if not os.path.exists(sensores_path):
        print("ğŸ†• Generando datos por defecto...")
        df_sensores, df_eventos = generate_and_save_dummy_data(days=365, n_components=5)
    else:
        print("ğŸ“‚ Cargando datos desde CSV...")
        df_sensores, df_eventos = load_data_from_csv(data_dir)
    df_ml = create_ml_dataset(df_sensores, df_eventos)
    print(f"Dataset listo: {df_ml.shape[0]:,} muestras, {df_ml['falla_prox_7d'].sum()} fallas positivas.")
    model, pdf_path = train_model(df_ml)
    ejemplo_df = pd.DataFrame([[1.8, 85, 2.1, 28, 120]], columns=FEATURES)
    proba = model.predict_proba(ejemplo_df)[0][1]
    print(f"Probabilidad de falla: {proba:.2%}")
    emit_alert_if_high_risk(proba, latest_report_path=pdf_path)
    print("\nâœ… Proceso completado.")

if __name__ == "__main__":
    main()
```

---

### ğŸ“„ `scripts/run_scheduled.py`
```python
"""
scripts/run_scheduled.py

Â¿PARA QUÃ‰?
- Ser el punto de entrada para la ejecuciÃ³n diaria (Task Scheduler).

Â¿POR QUÃ‰?
- El Programador de Tareas no activa el entorno virtual automÃ¡ticamente.
- Este script garantiza que se use el entorno correcto.

Â¿CÃ“MO?
- Usa el intÃ©rprete del entorno virtual.
- Ejecuta main.py y redirige salida a logs/.
"""

import os
import sys
import subprocess
from datetime import datetime

def main():
    project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    venv_python = os.path.join(project_root, "venv", "Scripts", "python.exe")
    main_script = os.path.join(project_root, "main.py")
    log_dir = os.path.join(project_root, "logs")
    os.makedirs(log_dir, exist_ok=True)
    log_file = os.path.join(log_dir, f"execution_{datetime.now().strftime('%Y%m%d')}.log")
    if not os.path.exists(venv_python):
        print(f"âŒ Entorno virtual no encontrado: {venv_python}")
        sys.exit(1)
    if not os.path.exists(main_script):
        print(f"âŒ main.py no encontrado: {main_script}")
        sys.exit(1)
    with open(log_file, "w", encoding="utf-8") as f:
        f.write(f"=== Inicio: {datetime.now()} ===\n")
        try:
            subprocess.run([venv_python, main_script], cwd=project_root, stdout=f, stderr=subprocess.STDOUT, text=True, check=True)
            f.write("=== Finalizado con Ã©xito ===\n")
        except subprocess.CalledProcessError as e:
            f.write(f"=== ERROR: cÃ³digo {e.returncode} ===\n")
            sys.exit(e.returncode)

if __name__ == "__main__":
    main()
```

---

### ğŸ“„ `scripts/schedule_daily_task.py`
```python
"""
scripts/schedule_daily_task.py

Â¿PARA QUÃ‰?
- Gestionar la tarea diaria en el Programador de Tareas de Windows.

Â¿POR QUÃ‰?
- Evita configuraciÃ³n manual.
- Es reproducible en cualquier mÃ¡quina Windows.

Â¿CÃ“MO?
- Usa 'schtasks.exe' para crear/eliminar tareas.
- Permite especificar hora de ejecuciÃ³n.
"""

import os
import sys
import argparse
import subprocess

TASK_NAME = "RepresaML_Daily_Maintenance"
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
RUN_SCRIPT = os.path.join(PROJECT_ROOT, "scripts", "run_scheduled.py")
PYTHON_EXEC = sys.executable

def create_task(hour=6, minute=0):
    cmd = ["schtasks", "/create", "/tn", TASK_NAME, "/tr", f'"{PYTHON_EXEC}" "{RUN_SCRIPT}"',
           "/sc", "daily", "/st", f"{hour:02d}:{minute:02d}", "/rl", "highest", "/f"]
    try:
        subprocess.run(cmd, capture_output=True, text=True, check=True)
        print(f"âœ… Tarea '{TASK_NAME}' creada. EjecuciÃ³n diaria a las {hour:02d}:{minute:02d}.")
    except subprocess.CalledProcessError as e:
        print(f"âŒ Error: {e.stderr}")
        sys.exit(1)

def delete_task():
    cmd = ["schtasks", "/delete", "/tn", TASK_NAME, "/f"]
    try:
        subprocess.run(cmd, capture_output=True, text=True, check=True)
        print(f"ğŸ—‘ï¸ Tarea '{TASK_NAME}' eliminada.")
    except subprocess.CalledProcessError as e:
        if "does not exist" in e.stderr:
            print(f"â„¹ï¸ Tarea no existe.")
        else:
            print(f"âŒ Error: {e.stderr}")
            sys.exit(1)

def check_task_status():
    cmd = ["schtasks", "/query", "/tn", TASK_NAME]
    try:
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        print(f"ğŸ“Š Tarea programada:\n{result.stdout}")
    except subprocess.CalledProcessError:
        print(f"â„¹ï¸ Tarea '{TASK_NAME}' no programada.")

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--install", action="store_true")
    parser.add_argument("--uninstall", action="store_true")
    parser.add_argument("--status", action="store_true")
    parser.add_argument("--hour", type=int, default=6)
    parser.add_argument("--minute", type=int, default=0)
    args = parser.parse_args()
    if not os.path.exists(RUN_SCRIPT):
        print("âŒ Ejecuta desde la raÃ­z del proyecto 'represa_ml'.")
        sys.exit(1)
    if args.install:
        create_task(args.hour, args.minute)
    elif args.uninstall:
        delete_task()
    elif args.status:
        check_task_status()
    else:
        parser.print_help()

if __name__ == "__main__":
    main()
```

---

## 6. â–¶ï¸ CÃ³mo usar el sistema

### Paso 1: Instalar
```powershell
python install_project.py
cd represa_ml
venv\Scripts\activate
```

### Paso 2: Configurar correo
```powershell
# Variables de entorno del sistema (Panel de control > Sistema > Variables de entorno)
ALERT_EMAIL_USER=tu_correo@gmail.com
ALERT_EMAIL_PASS=contraseÃ±a_de_aplicacion
ALERT_EMAIL_RECIPIENTS=ingeniero1@empresa.com
```
### 2.1. ObtÃ©n una "contraseÃ±a de aplicaciÃ³n" en Gmail
1. Ve a [https://myaccount.google.com/apppasswords](https://myaccount.google.com/apppasswords)
2. Inicia sesiÃ³n
3. Selecciona **"Otra"** â†’ nombre: `represa_ml`
4. Haz clic en **"Generar"**
5. Copia la contraseÃ±a de 16 caracteres (ej. `abcd efgh ijkl mnop`)

> âš ï¸ **Nunca uses tu contraseÃ±a normal de Gmail**. Solo usa la contraseÃ±a de aplicaciÃ³n.

### 2.2. Configura las variables de entorno (en la misma terminal)
```powershell
$env:ALERT_EMAIL_USER="tu_correo@gmail.com"
$env:ALERT_EMAIL_PASS="abcd efgh ijkl mnop"          # â† Tu contraseÃ±a de aplicaciÃ³n
$env:ALERT_EMAIL_RECIPIENTS="ingeniero1@empresa.com,ingeniero2@empresa.com"
```

> ğŸ’¡ **Importante**: estas variables **solo existen en esta terminal**. Si la cierras, debes volver a configurarlas.
### Paso 3: Generar datos
```powershell
python generate_data_cli.py --components 50 --days 1095 --freq-hours 1.0
```

### Paso 4: Ejecutar
```powershell
python main.py
```

### Paso 5: Programar diariamente (como administrador)
```powershell
python scripts/schedule_daily_task.py --install --hour 6
```
---

### Bonus: Uso de Logs

Â¡Excelente observaciÃ³n, Edi! A continuaciÃ³n, te presento la **versiÃ³n mejorada de todos los cÃ³digos** con **sistema de logging completo**, que registra eventos, advertencias y errores en archivos de log estructurados, manteniendo toda la funcionalidad anterior.

---

## ğŸ“ ImplementaciÃ³n del sistema de logging

### Principios del logging implementado:
- **Niveles**: DEBUG, INFO, WARNING, ERROR, CRITICAL
- **Archivos separados**: `logs/app.log` (general) y `logs/execution_YYYYMMDD.log` (ejecuciones programadas)
- **Formato consistente**: fecha, nivel, mÃ³dulo, mensaje
- **RotaciÃ³n**: evita archivos de log demasiado grandes

---

## ğŸ“„ CÃ³digo actualizado: `src/utils/logger.py` (Nuevo archivo)

```python
"""
src/utils/logger.py

Â¿PARA QUÃ‰?
- Configurar y proporcionar un sistema de logging consistente para toda la aplicaciÃ³n.

Â¿POR QUÃ‰?
- Registrar eventos importantes para auditorÃ­a y depuraciÃ³n.
- Separar logs por tipo de ejecuciÃ³n (manual vs programada).
- Mantener trazabilidad de errores y decisiones del sistema.

Â¿CÃ“MO?
- Usa el mÃ³dulo logging estÃ¡ndar de Python.
- Configura formateadores y manejadores de archivo.
- Permite diferentes configuraciones para ejecuciÃ³n manual y programada.
"""

import logging
import os
from datetime import datetime

def setup_logger(name, log_file=None, level=logging.INFO):
    """
    Configura y devuelve un logger.
    
    ParÃ¡metros:
    - name: nombre del logger
    - log_file: archivo de log especÃ­fico (opcional)
    - level: nivel mÃ­nimo de registro
    
    Retorna:
    - logger configurado
    """
    os.makedirs("logs", exist_ok=True)
    
    # Si no se especifica archivo, usa app.log
    if log_file is None:
        log_file = os.path.join("logs", "app.log")
    
    # Formato consistente para todos los logs
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    # Manejador de archivo
    file_handler = logging.FileHandler(log_file, encoding='utf-8')
    file_handler.setFormatter(formatter)
    
    # Manejador de consola (solo para ejecuciÃ³n manual)
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(formatter)
    
    # Configurar logger
    logger = logging.getLogger(name)
    logger.setLevel(level)
    
    # Evitar duplicaciÃ³n de handlers
    if not logger.handlers:
        logger.addHandler(file_handler)
        # Solo agregar consola si no es ejecuciÃ³n programada
        if "SCHEDULED_EXECUTION" not in os.environ:
            logger.addHandler(console_handler)
    
    return logger
```

---

## ğŸ“„ CÃ³digo actualizado: `main.py`

```python
"""
main.py

Â¿PARA QUÃ‰?
- Orquestar flujo completo con logging integrado.

Â¿POR QUÃ‰?
- Registrar cada paso del proceso para auditorÃ­a y depuraciÃ³n.
- Trazar decisiones de alerta y resultados del modelo.

Â¿CÃ“MO?
- Usa el sistema de logging configurado.
- Registra eventos en diferentes niveles segÃºn su importancia.
"""

import os
import sys
import pandas as pd
from src.utils.logger import setup_logger
from src.data_generation import generate_and_save_dummy_data
from src.data_loader import load_data_from_csv
from src.data_preparation import create_ml_dataset
from src.model import train_model, FEATURES
from src.alerts import emit_alert_if_high_risk

# Configurar logger
logger = setup_logger('main')

def main():
    logger.info("=== INICIO DE EJECUCIÃ“N MANUAL ===")
    
    try:
        data_dir = "data/raw"
        sensores_path = os.path.join(data_dir, "sensores.csv")
        
        if not os.path.exists(sensores_path):
            logger.info("Generando datos sintÃ©ticos por defecto (5 componentes, 365 dÃ­as)")
            df_sensores, df_eventos = generate_and_save_dummy_data(days=365, n_components=5)
        else:
            logger.info("Cargando datos desde CSV")
            df_sensores, df_eventos = load_data_from_csv(data_dir)
        
        logger.info("Preparando dataset para ML")
        df_ml = create_ml_dataset(df_sensores, df_eventos)
        logger.info(f"Dataset listo: {df_ml.shape[0]:,} muestras, {df_ml['falla_prox_7d'].sum()} fallas positivas.")
        
        logger.info("Entrenando modelo y generando informe PDF")
        model, pdf_path = train_model(df_ml)
        
        # PredicciÃ³n de ejemplo con condiciones de alto riesgo
        ejemplo_df = pd.DataFrame([[1.8, 85, 2.1, 28, 120]], columns=FEATURES)
        proba = model.predict_proba(ejemplo_df)[0][1]
        logger.info(f"Probabilidad de falla en 7 dÃ­as: {proba:.2%}")
        
        # Activar alertas si aplica
        emit_alert_if_high_risk(proba, latest_report_path=pdf_path)
        
        logger.info("=== EJECUCIÃ“N COMPLETADA EXITOSAMENTE ===")
        
    except Exception as e:
        logger.critical(f"Error crÃ­tico durante la ejecuciÃ³n: {str(e)}", exc_info=True)
        sys.exit(1)

if __name__ == "__main__":
    main()
```

---

## ğŸ“„ CÃ³digo actualizado: `src/data_generation.py`

```python
"""
src/data_generation.py

Â¿PARA QUÃ‰?
- Generar datos sintÃ©ticos con logging integrado.

Â¿POR QUÃ‰?
- Registrar parÃ¡metros de generaciÃ³n para reproducibilidad.
- Trazar el volumen de datos generado.

Â¿CÃ“MO?
- Agrega logging en puntos clave del proceso.
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import os
from src.utils.logger import setup_logger

# Configurar logger para este mÃ³dulo
logger = setup_logger('data_generation')

def generate_and_save_dummy_data(days=365, n_components=5, freq_hours=1, seed=42, output_dir="data/raw"):
    logger.info(f"Iniciando generaciÃ³n de datos: {n_components} componentes, {days} dÃ­as, frecuencia cada {freq_hours}h")
    
    np.random.seed(seed)
    os.makedirs(output_dir, exist_ok=True)
    componentes = [f"compuerta_{i+1}" for i in range(n_components)]
    start_date = datetime(2024, 1, 1)
    freq_str = f"{int(freq_hours * 60)}min" if freq_hours < 1 else f"{int(freq_hours)}h"
    total_steps = int(days * 24 / freq_hours)
    dates = pd.date_range(start=start_date, periods=total_steps, freq=freq_str)
    
    time_series = pd.Series(dates.repeat(n_components))
    comp_series = pd.Series(componentes * total_steps)
    day_of_year = time_series.dt.dayofyear
    month = time_series.dt.month
    
    presion = 1.0 + 0.3 * np.sin(day_of_year / 365 * 2 * np.pi) + np.random.normal(0, 0.1, size=len(time_series))
    humedad = 60 + 20 * np.sin(month / 12 * 2 * np.pi) + np.random.normal(0, 5, size=len(time_series))
    vibracion = 0.5 + np.random.exponential(0.2, size=len(time_series))
    temperatura = 20 + 10 * np.sin(day_of_year / 365 * 2 * np.pi) + np.random.normal(0, 2, size=len(time_series))
    
    df_sensores = pd.DataFrame({
        'timestamp': time_series,
        'id_componente': comp_series,
        'presion_bar': np.clip(presion, 0.5, None),
        'humedad_pct': np.clip(humedad, 20, 100),
        'vibracion_mm_s': vibracion,
        'temperatura_c': temperatura
    })
    
    eventos = []
    for comp in componentes:
        maint_dates = [start_date + timedelta(days=d) for d in range(0, days, 90)]
        for md in maint_dates:
            eventos.append({'timestamp': md, 'id_componente': comp, 'tipo_evento': 'mantenimiento', 'subtipo': 'preventivo', 'gravedad': 'baja'})
        n_fallas = max(2, int(10 * days / 365))
        for _ in range(n_fallas):
            dias = np.random.randint(10, days)
            falla_date = start_date + timedelta(days=dias)
            if any(abs((falla_date - md).days) < 15 for md in maint_dates):
                continue
            eventos.append({'timestamp': falla_date, 'id_componente': comp, 'tipo_evento': 'falla', 'subtipo': np.random.choice(['fuga', 'bloqueo', 'corrosion']), 'gravedad': np.random.choice(['baja', 'media', 'alta'])})
    
    df_eventos = pd.DataFrame(eventos)
    sensores_path = os.path.join(output_dir, "sensores.csv")
    eventos_path = os.path.join(output_dir, "eventos.csv")
    df_sensores.to_csv(sensores_path, index=False)
    df_eventos.to_csv(eventos_path, index=False)
    
    logger.info(f"Datos guardados exitosamente: {len(df_sensores):,} lecturas, {len(df_eventos):,} eventos")
    return df_sensores, df_eventos
```

---

## ğŸ“„ CÃ³digo actualizado: `src/model.py`

```python
"""
src/model.py

Â¿PARA QUÃ‰?
- Entrenar modelo con logging detallado.

Â¿POR QUÃ‰?
- Registrar mÃ©tricas y parÃ¡metros para auditorÃ­a.
- Trazar el rendimiento del modelo.

Â¿CÃ“MO?
- Registra mÃ©tricas clave y caracterÃ­sticas del dataset.
"""

import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import joblib
import os
from src.utils.logger import setup_logger
from .report_pdf import generate_pdf_report

logger = setup_logger('model')

FEATURES = ['presion_bar', 'humedad_pct', 'vibracion_mm_s', 'temperatura_c', 'dias_desde_mant']
TARGET = 'falla_prox_7d'

def train_model(df, model_path='models/maintenance_model.pkl', generate_report=True):
    logger.info("Iniciando entrenamiento del modelo Random Forest")
    logger.info(f"Dataset: {len(df)} muestras, {df[TARGET].sum()} positivos ({df[TARGET].mean():.2%} de fallas)")
    
    X = df[FEATURES]
    y = df[TARGET]
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)
    
    logger.info(f"DivisiÃ³n de datos: {len(X_train)} entrenamiento, {len(X_test)} prueba")
    
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)
    
    y_pred = model.predict(X_test)
    report_str = classification_report(y_test, y_pred, zero_division=0)
    cm = confusion_matrix(y_test, y_pred)
    
    # Extraer mÃ©tricas para logging
    lines = report_str.strip().split('\n')
    for line in lines:
        if '1' in line and line.strip()[0] == '1':
            parts = line.split()
            if len(parts) >= 4:
                recall = float(parts[2])
                precision = float(parts[1])
                f1 = float(parts[3])
                logger.info(f"MÃ©tricas para fallas (clase 1): PrecisiÃ³n={precision:.3f}, Recall={recall:.3f}, F1={f1:.3f}")
                break
    
    os.makedirs(os.path.dirname(model_path), exist_ok=True)
    joblib.dump(model, model_path)
    logger.info(f"Modelo guardado en: {model_path}")
    
    pdf_path = None
    if generate_report:
        pdf_path = generate_pdf_report(report_str, cm, FEATURES, model.feature_importances_, len(df), int(y.sum()))
        logger.info(f"Informe PDF generado: {pdf_path}")
    
    logger.info("Entrenamiento completado exitosamente")
    return model, pdf_path

def load_model(model_path='models/maintenance_model.pkl'):
    logger.info(f"Cargando modelo desde: {model_path}")
    return joblib.load(model_path)
```

---

## ğŸ“„ CÃ³digo actualizado: `src/alerts.py`

```python
"""
src/alerts.py

Â¿PARA QUÃ‰?
- Gestionar alertas con logging integrado.

Â¿POR QUÃ‰?
- Registrar cuÃ¡ndo y por quÃ© se activan las alertas.
- Trazar la probabilidad que desencadenÃ³ la alerta.

Â¿CÃ“MO?
- Registra eventos de alerta en nivel INFO o WARNING.
"""

import os
from src.utils.logger import setup_logger
from .email_alert import send_email_alert

logger = setup_logger('alerts')

def emit_alert_if_high_risk(probability: float, threshold: float = 0.7, latest_report_path: str = None):
    if probability <= threshold:
        logger.debug(f"Probabilidad {probability:.2%} por debajo del umbral {threshold:.0%} - Sin alerta")
        return
    
    logger.warning(f"ALTA PROBABILIDAD DETECTADA: {probability:.2%} > umbral {threshold:.0%}")
    
    # Alerta sonora (solo Windows)
    if os.name == 'nt':
        try:
            import winsound
            winsound.MessageBeep(winsound.MB_ICONEXCLAMATION)
            logger.info("Alerta sonora activada en sistema Windows")
        except Exception as e:
            logger.error(f"Error al activar alerta sonora: {e}")
    
    # Alerta por correo
    send_email_alert(probability, threshold, latest_report_path)
    logger.info("Proceso de alertas completado")
```

---

## ğŸ“„ CÃ³digo actualizado: `src/email_alert.py`

```python
"""
src/email_alert.py

Â¿PARA QUÃ‰?
- Enviar notificaciones por correo con logging.

Â¿POR QUÃ‰?
- Registrar intentos de envÃ­o y resultados.
- Trazar errores en la configuraciÃ³n de correo.

Â¿CÃ“MO?
- Registra cada paso del proceso de envÃ­o.
"""

import smtplib
import os
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from email.mime.base import MIMEBase
from email import encoders
from datetime import datetime
from src.utils.logger import setup_logger

logger = setup_logger('email_alert')

def send_email_alert(probability: float, threshold: float = 0.7, latest_report_path: str = None):
    if probability <= threshold:
        return
    
    sender = os.getenv("ALERT_EMAIL_USER")
    password = os.getenv("ALERT_EMAIL_PASS")
    recipients = os.getenv("ALERT_EMAIL_RECIPIENTS", "").split(",")
    
    if not sender or not password or not recipients[0]:
        logger.error("Correo no configurado: faltan variables de entorno ALERT_EMAIL_USER, ALERT_EMAIL_PASS o ALERT_EMAIL_RECIPIENTS")
        return
    
    try:
        msg = MIMEMultipart()
        msg["From"] = sender
        msg["To"] = ", ".join(recipients)
        msg["Subject"] = "ğŸš¨ ALERTA: Alto riesgo de falla en represa"
        body = f"""
        Se ha detectado un alto riesgo de falla en un componente de la represa.
        - Probabilidad: {probability:.2%}
        - Umbral: {threshold:.0%}
        - Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
        Revise el sistema inmediatamente.
        """
        msg.attach(MIMEText(body, "plain"))
        
        if latest_report_path and os.path.exists(latest_report_path):
            with open(latest_report_path, "rb") as f:
                part = MIMEBase("application", "octet-stream")
                part.set_payload(f.read())
            encoders.encode_base64(part)
            part.add_header("Content-Disposition", f"attachment; filename= {os.path.basename(latest_report_path)}")
            msg.attach(part)
            logger.info(f"PDF adjunto al correo: {os.path.basename(latest_report_path)}")
        
        server = smtplib.SMTP("smtp.gmail.com", 587)
        server.starttls()
        server.login(sender, password)
        server.sendmail(sender, recipients, msg.as_string())
        server.quit()
        
        logger.info(f"Correo de alerta enviado exitosamente a {len(recipients)} destinatarios")
        
    except Exception as e:
        logger.critical(f"Error crÃ­tico al enviar correo de alerta: {e}")
```

---

## ğŸ“„ CÃ³digo actualizado: `scripts/run_scheduled.py`

```python
"""
scripts/run_scheduled.py

Â¿PARA QUÃ‰?
- Ejecutar el sistema programado con logging especÃ­fico.

Â¿POR QUÃ‰?
- Diferenciar logs de ejecuciÃ³n programada vs manual.
- Registrar cada ejecuciÃ³n diaria en archivo separado.

Â¿CÃ“MO?
- Establece variable de entorno para desactivar salida por consola.
- Usa archivo de log con marca de tiempo diaria.
"""

import os
import sys
import subprocess
from datetime import datetime
from src.utils.logger import setup_logger

# Indicar que es ejecuciÃ³n programada (desactiva salida por consola)
os.environ["SCHEDULED_EXECUTION"] = "1"

def main():
    project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    venv_python = os.path.join(project_root, "venv", "Scripts", "python.exe")
    main_script = os.path.join(project_root, "main.py")
    log_dir = os.path.join(project_root, "logs")
    os.makedirs(log_dir, exist_ok=True)
    log_file = os.path.join(log_dir, f"execution_{datetime.now().strftime('%Y%m%d')}.log")
    
    # Configurar logger especÃ­fico para esta ejecuciÃ³n
    logger = setup_logger('scheduled_execution', log_file=log_file)
    logger.info("=== INICIO DE EJECUCIÃ“N PROGRAMADA ===")
    
    if not os.path.exists(venv_python):
        logger.critical(f"Entorno virtual no encontrado: {venv_python}")
        sys.exit(1)
    if not os.path.exists(main_script):
        logger.critical(f"main.py no encontrado: {main_script}")
        sys.exit(1)
    
    try:
        result = subprocess.run(
            [venv_python, main_script],
            cwd=project_root,
            capture_output=True,
            text=True,
            check=True
        )
        logger.info("=== EJECUCIÃ“N PROGRAMADA COMPLETADA EXITOSAMENTE ===")
        
    except subprocess.CalledProcessError as e:
        logger.critical(f"Error en ejecuciÃ³n programada - CÃ³digo de retorno: {e.returncode}")
        logger.critical(f"Salida de error: {e.stderr}")
        sys.exit(e.returncode)
    except Exception as e:
        logger.critical(f"Error inesperado en ejecuciÃ³n programada: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
```

---

## ğŸ“„ ActualizaciÃ³n de `install_project.py`

Agrega el nuevo archivo al listado:

```python
ARCHIVOS = [
    "requirements.txt",
    "main.py",
    "generate_data_cli.py",
    "src/__init__.py",
    "src/utils/__init__.py",          # â† Nuevo
    "src/utils/logger.py",            # â† Nuevo
    "src/data_generation.py",
    "src/data_loader.py",
    "src/data_preparation.py",
    "src/model.py",
    "src/alerts.py",
    "src/email_alert.py",
    "src/report_pdf.py",
    "scripts/run_scheduled.py",
    "scripts/schedule_daily_task.py"
]

DIRECTORIOS = ["data", "models", "reports", "logs", "scripts", "src", "src/utils"]  # â† Agrega src/utils
```

---

## ğŸ“ Estructura final con logging

```
represa_ml/
â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ app.log                    â† Logs de ejecuciones manuales
â”‚   â””â”€â”€ execution_20251021.log     â† Logs de ejecuciones programadas
â”œâ”€â”€ src/
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ logger.py              â† Sistema de logging
â””â”€â”€ ... (resto de archivos)
```

---

## ğŸ“Š Ejemplo de contenido en `logs/app.log`

```
2025-10-21 14:30:22 - main - INFO - === INICIO DE EJECUCIÃ“N MANUAL ===
2025-10-21 14:30:23 - data_generation - INFO - Iniciando generaciÃ³n de datos: 5 componentes, 365 dÃ­as, frecuencia cada 1.0h
2025-10-21 14:30:25 - data_generation - INFO - Datos guardados exitosamente: 43,800 lecturas, 40 eventos
2025-10-21 14:30:26 - model - INFO - MÃ©tricas para fallas (clase 1): PrecisiÃ³n=0.850, Recall=0.760, F1=0.800
2025-10-21 14:30:28 - alerts - WARNING - ALTA PROBABILIDAD DETECTADA: 78.50% > umbral 70%
2025-10-21 14:30:28 - alerts - INFO - Alerta sonora activada en sistema Windows
2025-10-21 14:30:29 - email_alert - INFO - Correo de alerta enviado exitosamente a 2 destinatarios
2025-10-21 14:30:29 - main - INFO - === EJECUCIÃ“N COMPLETADA EXITOSAMENTE ===
```

---

Con este sistema de logging completo, tienes **trazabilidad total** de todas las operaciones del sistema, **auditorÃ­a tÃ©cnica** de decisiones y **depuraciÃ³n eficiente** de errores, manteniendo todos los beneficios del sistema original de mantenimiento predictivo para represas.

