Â¡Claro, Edi! A continuaciÃ³n, te presento la **GuÃ­a Paso a Paso Completa y Definitiva** para implementar un **Sistema de Mantenimiento Predictivo para Represas con Machine Learning**, con:

âœ… **ExplicaciÃ³n clara de Random Forest y mÃ©tricas (precisiÃ³n, recall, F1)**  
âœ… **GeneraciÃ³n de datos sintÃ©ticos densos** (hasta 1 millÃ³n+ de registros)  
âœ… **Guardado en archivos CSV**  
âœ… **Alerta sonora en Windows**  
âœ… **NotificaciÃ³n por correo electrÃ³nico**  
âœ… **Informe PDF automÃ¡tico**  
âœ… **EjecuciÃ³n diaria programada**  
âœ… **CÃ³digo modular, bien estructurado y comentado**  
âœ… **Comentarios en cada funciÃ³n**: **Â¿Para quÃ©?**, **Â¿Por quÃ©?**, **Â¿CÃ³mo?**

---

# ğŸ“˜ GuÃ­a Paso a Paso: Sistema de Mantenimiento Predictivo para Represas con Machine Learning

---

## 1. ğŸ¯ Objetivo

Predecir fallas en componentes crÃ­ticos de una represa **7 dÃ­as antes** de que ocurran, usando Machine Learning, y notificar al equipo tÃ©cnico mediante **alerta sonora + correo electrÃ³nico**, con **informe PDF automÃ¡tico** y **ejecuciÃ³n diaria programada**.

---

## 2. ğŸŒ³ Random Forest y MÃ©tricas (ExplicaciÃ³n Simple)

### Â¿QuÃ© es Random Forest?
- **Para quÃ©**: predecir si un componente fallarÃ¡.
- **CÃ³mo**: combina cientos de Ã¡rboles de decisiÃ³n que votan en conjunto.
- **Por quÃ©**: es robusto, maneja datos desbalanceados y muestra quÃ© variables son mÃ¡s importantes.

### MÃ©tricas clave
| MÃ©trica | Para quÃ© | Por quÃ© es importante en represas |
|--------|--------|-------------------------------|
| **PrecisiÃ³n** | Â¿CuÃ¡ntas alertas fueron reales? | Evita falsas alarmas que detienen operaciones innecesariamente |
| **Recall** | Â¿Detectamos la mayorÃ­a de fallas reales? | **Prioridad**: no queremos fallas no detectadas |
| **F1-Score** | Equilibrio entre ambas | Ãštil cuando hay pocas fallas (datos desbalanceados) |

> En mantenimiento predictivo: **maximizamos recall**, aunque aumenten ligeramente las falsas alarmas.

---

## 3. ğŸ—‚ï¸ Estructura del Proyecto

El script `install_project.py` crearÃ¡ automÃ¡ticamente:

```
represa_ml/
â”œâ”€â”€ install_project.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ main.py
â”œâ”€â”€ generate_data_cli.py        â† Genera datos personalizados
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/
â”‚       â”œâ”€â”€ sensores.csv        â† Datos de sensores (densos)
â”‚       â””â”€â”€ eventos.csv         â† Mantenimientos y fallas
â”œâ”€â”€ models/
â”œâ”€â”€ reports/
â”œâ”€â”€ logs/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_scheduled.py        â† EjecuciÃ³n diaria
â”‚   â””â”€â”€ schedule_daily_task.py  â† Gestiona tarea programada
â””â”€â”€ src/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ data_generation.py      â† Genera datos sintÃ©ticos
    â”œâ”€â”€ data_loader.py          â† Carga datos desde CSV
    â”œâ”€â”€ data_preparation.py     â† Prepara dataset para ML
    â”œâ”€â”€ model.py                â† Entrena modelo y evalÃºa mÃ©tricas
    â”œâ”€â”€ alerts.py               â† Alerta sonora + correo
    â”œâ”€â”€ email_alert.py          â† EnvÃ­a notificaciones por email
    â””â”€â”€ report_pdf.py           â† Genera informe PDF
```

---

## 4. ğŸ› ï¸ Script de InstalaciÃ³n: `install_project.py`

```python
"""
install_project.py

Â¿Para quÃ©?
- Crear la estructura completa del proyecto con un solo comando.

Â¿Por quÃ©?
- Automatiza la configuraciÃ³n inicial.
- AÃ­sla dependencias en un entorno virtual.
- Permite comenzar a trabajar inmediatamente.

Â¿CÃ³mo?
1. Crea directorios y archivos vacÃ­os.
2. Genera requirements.txt con dependencias.
3. Crea entorno virtual (venv).
4. Instala paquetes automÃ¡ticamente.
"""

import os
import sys
import subprocess
import venv

PROJECT_NAME = "represa_ml"
REQUIREMENTS = [
    "pandas", "numpy", "scikit-learn", "streamlit",
    "joblib", "matplotlib", "reportlab"
]

ARCHIVOS = [
    "requirements.txt",
    "main.py",
    "generate_data_cli.py",
    "src/__init__.py",
    "src/data_generation.py",
    "src/data_loader.py",
    "src/data_preparation.py",
    "src/model.py",
    "src/alerts.py",
    "src/email_alert.py",
    "src/report_pdf.py",
    "scripts/run_scheduled.py",
    "scripts/schedule_daily_task.py"
]

DIRECTORIOS = ["data", "models", "reports", "logs", "scripts", "src"]

def crear_estructura(base_path):
    for d in DIRECTORIOS:
        os.makedirs(os.path.join(base_path, d), exist_ok=True)
    
    # Crear requirements.txt con contenido
    with open(os.path.join(base_path, "requirements.txt"), "w") as f:
        f.write("\n".join(REQUIREMENTS))
    
    # Crear otros archivos vacÃ­os
    for archivo in ARCHIVOS:
        if archivo == "requirements.txt":
            continue
        ruta = os.path.join(base_path, archivo)
        dir_name = os.path.dirname(ruta)
        if dir_name:
            os.makedirs(dir_name, exist_ok=True)
        with open(ruta, "w") as f:
            pass

def crear_entorno_virtual(env_path):
    print("ğŸ› ï¸ Creando entorno virtual...")
    venv.create(env_path, with_pip=True)

def instalar_dependencias(env_path):
    print("ğŸ“¦ Instalando dependencias...")
    python_exe = os.path.join(env_path, "Scripts", "python.exe") if os.name == "nt" else os.path.join(env_path, "bin", "python")
    req_file = os.path.join(env_path, "..", "requirements.txt")
    subprocess.check_call([python_exe, "-m", "pip", "install", "-r", req_file])

def main():
    if os.path.basename(os.getcwd()) == PROJECT_NAME:
        print("âš ï¸ Ejecuta desde una carpeta PADRE.")
        sys.exit(1)
    
    base_dir = os.path.abspath(PROJECT_NAME)
    env_dir = os.path.join(base_dir, "venv")
    
    print(f"ğŸš€ Creando proyecto '{PROJECT_NAME}'...")
    os.makedirs(base_dir, exist_ok=True)
    crear_estructura(base_dir)
    crear_entorno_virtual(env_dir)
    instalar_dependencias(env_dir)
    
    print("\nğŸ‰ Â¡Listo! Activa el entorno y edita los archivos.")

if __name__ == "__main__":
    main()
```

---

## 5. ğŸ’» CÃ³digos Completos (Bien Comentados)

> **Copia cada bloque en su archivo correspondiente** dentro de `represa_ml/`.

---

### ğŸ“„ `generate_data_cli.py`
```python
"""
generate_data_cli.py

Â¿Para quÃ©?
- Generar datos sintÃ©ticos densos desde la lÃ­nea de comandos.

Â¿Por quÃ©?
- Permite simular desde miles hasta millones de registros.
- Ãštil para pruebas de escalabilidad o escenarios realistas.

Â¿CÃ³mo?
- Usa argparse para recibir parÃ¡metros.
- Llama a la funciÃ³n de generaciÃ³n con esos valores.
"""

import argparse
from src.data_generation import generate_and_save_dummy_data

def main():
    parser = argparse.ArgumentParser(description="Genera datos sintÃ©ticos para represa.")
    parser.add_argument("--components", type=int, default=5, help="NÃºmero de componentes")
    parser.add_argument("--days", type=int, default=365, help="DÃ­as a simular")
    parser.add_argument("--freq-hours", type=float, default=1.0, help="Frecuencia en horas")
    parser.add_argument("--output", default="data/raw", help="Carpeta de salida")
    parser.add_argument("--seed", type=int, default=42, help="Semilla")
    args = parser.parse_args()
    
    generate_and_save_dummy_data(
        days=args.days,
        n_components=args.components,
        freq_hours=args.freq_hours,
        seed=args.seed,
        output_dir=args.output
    )

if __name__ == "__main__":
    main()
```

---

### ğŸ“„ `src/data_generation.py`
```python
"""
src/data_generation.py

Â¿Para quÃ©?
- Generar datos sintÃ©ticos realistas y densos para sensores y eventos.

Â¿Por quÃ©?
- Permite probar el sistema sin sensores reales.
- Escalable: desde miles hasta millones de registros.
- Guarda en CSV para reutilizaciÃ³n.

Â¿CÃ³mo?
- Usa operaciones vectorizadas (rÃ¡pido y eficiente).
- Simula tendencias estacionales y ruido.
- Genera mantenimientos y fallas con lÃ³gica realista.
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import os

def generate_and_save_dummy_data(days=365, n_components=5, freq_hours=1, seed=42, output_dir="data/raw"):
    np.random.seed(seed)
    os.makedirs(output_dir, exist_ok=True)
    
    # Definir fechas y componentes
    componentes = [f"compuerta_{i+1}" for i in range(n_components)]
    start_date = datetime(2024, 1, 1)
    total_hours = int(days * 24 / freq_hours)
    freq_str = f"{int(freq_hours * 60)}T" if freq_hours < 1 else f"{int(freq_hours)}H"
    dates = pd.date_range(start=start_date, periods=total_hours, freq=freq_str)
    
    # Generar sensores (vectorizado)
    comp_rep = np.repeat(componentes, total_hours)
    time_rep = np.tile(dates, n_components)
    day_of_year = time_rep.dayofyear
    month = time_rep.month
    
    presion = 1.0 + 0.3 * np.sin(day_of_year / 365 * 2 * np.pi) + np.random.normal(0, 0.1, len(time_rep))
    humedad = 60 + 20 * np.sin(month / 12 * 2 * np.pi) + np.random.normal(0, 5, len(time_rep))
    vibracion = 0.5 + np.random.exponential(0.2, len(time_rep))
    temperatura = 20 + 10 * np.sin(day_of_year / 365 * 2 * np.pi) + np.random.normal(0, 2, len(time_rep))
    
    df_sensores = pd.DataFrame({
        'timestamp': time_rep,
        'id_componente': comp_rep,
        'presion_bar': np.clip(presion, 0.5, None),
        'humedad_pct': np.clip(humedad, 20, 100),
        'vibracion_mm_s': vibracion,
        'temperatura_c': temperatura
    })
    
    # Generar eventos
    eventos = []
    for comp in componentes:
        maint_dates = [start_date + timedelta(days=d) for d in range(0, days, 90)]
        for md in maint_dates:
            eventos.append({'timestamp': md, 'id_componente': comp, 'tipo_evento': 'mantenimiento', 'subtipo': 'preventivo', 'gravedad': 'baja'})
        n_fallas = max(1, int(8 * days / 365))
        for _ in range(n_fallas):
            dias = np.random.randint(10, days)
            falla_date = start_date + timedelta(days=dias)
            if any(abs((falla_date - md).days) < 15 for md in maint_dates):
                continue
            eventos.append({'timestamp': falla_date, 'id_componente': comp, 'tipo_evento': 'falla', 'subtipo': np.random.choice(['fuga', 'bloqueo', 'corrosion']), 'gravedad': np.random.choice(['baja', 'media', 'alta'])})
    
    df_eventos = pd.DataFrame(eventos)
    
    # Guardar en CSV
    df_sensores.to_csv(os.path.join(output_dir, "sensores.csv"), index=False)
    df_eventos.to_csv(os.path.join(output_dir, "eventos.csv"), index=False)
    print(f"âœ… Datos guardados: {len(df_sensores):,} lecturas.")
    return df_sensores, df_eventos
```

---

### ğŸ“„ `src/data_loader.py`
```python
"""
src/data_loader.py

Â¿Para quÃ©?
- Cargar datos desde archivos CSV.

Â¿Por quÃ©?
- Desacopla generaciÃ³n de datos del entrenamiento.
- Permite usar datos reales sin cambiar cÃ³digo.

Â¿CÃ³mo?
- Lee sensores.csv y eventos.csv.
- Convierte timestamp a datetime.
"""

import pandas as pd
import os

def load_data_from_csv(data_dir="data/raw"):
    sensores_path = os.path.join(data_dir, "sensores.csv")
    eventos_path = os.path.join(data_dir, "eventos.csv")
    if not os.path.exists(sensores_path):
        raise FileNotFoundError("Ejecuta generate_data_cli.py primero.")
    df_sensores = pd.read_csv(sensores_path, parse_dates=['timestamp'])
    df_eventos = pd.read_csv(eventos_path, parse_dates=['timestamp'])
    return df_sensores, df_eventos
```

---

### ğŸ“„ `src/data_preparation.py`
```python
"""
src/data_preparation.py

Â¿Para quÃ©?
- Transformar datos crudos en dataset listo para ML.

Â¿Por quÃ©?
- El modelo necesita una observaciÃ³n por dÃ­a.
- La etiqueta debe construirse sin fuga de informaciÃ³n.

Â¿CÃ³mo?
1. Resamplea a diario.
2. Calcula dÃ­as desde Ãºltimo mantenimiento.
3. Crea etiqueta: Â¿falla en prÃ³ximos 7 dÃ­as?
"""

import pandas as pd
import numpy as np

def create_ml_dataset(df_sensores, df_eventos):
    df_fallas = df_eventos[df_eventos['tipo_evento'] == 'falla'][['timestamp', 'id_componente']].copy()
    df_fallas = df_fallas.rename(columns={'timestamp': 'falla_timestamp'})
    
    df_sensores['date'] = df_sensores['timestamp'].dt.floor('D')
    df_daily = df_sensores.groupby(['id_componente', 'date']).agg({
        'presion_bar': 'mean',
        'humedad_pct': 'mean',
        'vibracion_mm_s': 'mean',
        'temperatura_c': 'mean'
    }).reset_index()
    
    df_mant = df_eventos[df_eventos['tipo_evento'] == 'mantenimiento'][['timestamp', 'id_componente']].copy()
    df_mant = df_mant.rename(columns={'timestamp': 'mant_timestamp'})
    df_daily['dias_desde_mant'] = df_daily.apply(
        lambda row: min([
            (row['date'] - mant_row['mant_timestamp']).days
            for _, mant_row in df_mant[df_mant['id_componente'] == row['id_componente']].iterrows()
            if row['date'] >= mant_row['mant_timestamp']
        ], default=365), axis=1
    )
    
    df_daily['falla_prox_7d'] = df_daily.apply(
        lambda row: any(
            (falla_row['falla_timestamp'] > row['date']) and
            (falla_row['falla_timestamp'] <= row['date'] + pd.Timedelta(days=7)) and
            (falla_row['id_componente'] == row['id_componente'])
            for _, falla_row in df_fallas.iterrows()
        ), axis=1
    ).astype(int)
    
    cutoff_date = df_daily['date'].max() - pd.Timedelta(days=7)
    return df_daily[df_daily['date'] <= cutoff_date].copy()
```

---

### ğŸ“„ `src/model.py`
```python
"""
src/model.py

Â¿Para quÃ©?
- Entrenar modelo y evaluar desempeÃ±o.

Â¿Por quÃ©?
- Random Forest es ideal para datos desbalanceados.
- Documenta resultados en PDF para auditorÃ­a.

Â¿CÃ³mo?
1. Divide datos (estratificado).
2. Entrena Random Forest.
3. EvalÃºa con mÃ©tricas.
4. Genera informe PDF.
"""

import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import joblib
import os
from .report_pdf import generate_pdf_report

FEATURES = ['presion_bar', 'humedad_pct', 'vibracion_mm_s', 'temperatura_c', 'dias_desde_mant']
TARGET = 'falla_prox_7d'

def train_model(df, model_path='models/maintenance_model.pkl', generate_report=True):
    X = df[FEATURES]
    y = df[TARGET]
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)
    
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)
    
    y_pred = model.predict(X_test)
    report_str = classification_report(y_test, y_pred)
    cm = confusion_matrix(y_test, y_test)
    
    os.makedirs(os.path.dirname(model_path), exist_ok=True)
    joblib.dump(model, model_path)
    
    pdf_path = None
    if generate_report:
        pdf_path = generate_pdf_report(report_str, cm, FEATURES, model.feature_importances_, len(df), int(y.sum()))
    return model, pdf_path

def load_model(model_path='models/maintenance_model.pkl'):
    return joblib.load(model_path)
```

---

### ğŸ“„ `src/alerts.py`
```python
"""
src/alerts.py

Â¿Para quÃ©?
- Centralizar alertas (sonora + correo).

Â¿Por quÃ©?
- Separa lÃ³gica de alertas del entrenamiento.
- Facilita agregar nuevos canales.

Â¿CÃ³mo?
- Verifica umbral de probabilidad.
- Emite sonido en Windows.
- Llama a funciÃ³n de correo.
"""

import os
from .email_alert import send_email_alert

def emit_alert_if_high_risk(probability: float, threshold: float = 0.7, latest_report_path: str = None):
    if probability <= threshold:
        return
    if os.name == 'nt':
        try:
            import winsound
            winsound.MessageBeep(winsound.MB_ICONEXCLAMATION)
            print("ğŸ”Š Â¡ALERTA SONORA ACTIVADA!")
        except Exception as e:
            print(f"âš ï¸ Error en alerta sonora: {e}")
    send_email_alert(probability, threshold, latest_report_path)
```

---

### ğŸ“„ `src/email_alert.py`
```python
"""
src/email_alert.py

Â¿Para quÃ©?
- Enviar notificaciones por correo.

Â¿Por quÃ©?
- Alerta a personal remoto.
- Deja registro escrito.

Â¿CÃ³mo?
- Usa variables de entorno para credenciales.
- Adjunta informe PDF.
- Usa SMTP de Gmail (cambiable).
"""

import smtplib
import os
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from email.mime.base import MIMEBase
from email import encoders
from datetime import datetime

def send_email_alert(probability: float, threshold: float = 0.7, latest_report_path: str = None):
    if probability <= threshold:
        return
    sender = os.getenv("ALERT_EMAIL_USER")
    password = os.getenv("ALERT_EMAIL_PASS")
    recipients = os.getenv("ALERT_EMAIL_RECIPIENTS", "").split(",")
    if not sender or not password or not recipients[0]:
        print("ğŸ“§ Correo no configurado.")
        return
    try:
        msg = MIMEMultipart()
        msg["From"] = sender
        msg["To"] = ", ".join(recipients)
        msg["Subject"] = "ğŸš¨ ALERTA: Alto riesgo de falla en represa"
        body = f"Probabilidad: {probability:.2%}\nFecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
        msg.attach(MIMEText(body, "plain"))
        if latest_report_path and os.path.exists(latest_report_path):
            with open(latest_report_path, "rb") as f:
                part = MIMEBase("application", "octet-stream")
                part.set_payload(f.read())
            encoders.encode_base64(part)
            part.add_header("Content-Disposition", f"attachment; filename= {os.path.basename(latest_report_path)}")
            msg.attach(part)
        server = smtplib.SMTP("smtp.gmail.com", 587)
        server.starttls()
        server.login(sender, password)
        server.sendmail(sender, recipients, msg.as_string())
        server.quit()
        print("ğŸ“§ Correo enviado.")
    except Exception as e:
        print(f"âŒ Error: {e}")
```

---

### ğŸ“„ `src/report_pdf.py`
```python
"""
src/report_pdf.py

Â¿Para quÃ©?
- Generar informe PDF con resultados.

Â¿Por quÃ©?
- Formato estÃ¡ndar para reportes tÃ©cnicos.
- Incluye mÃ©tricas y grÃ¡ficos.

Â¿CÃ³mo?
- Usa reportlab para PDF.
- Matplotlib para grÃ¡fico de importancia.
"""

import os
from datetime import datetime
from reportlab.lib.pagesizes import A4
from reportlab.pdfgen import canvas
from reportlab.lib import colors
from reportlab.platypus import Table, TableStyle
import matplotlib.pyplot as plt
import io
from reportlab.lib.utils import ImageReader

def generate_pdf_report(report_str, cm, feature_names, importances, n_samples, n_failures, output_dir="reports"):
    os.makedirs(output_dir, exist_ok=True)
    pdf_path = os.path.join(output_dir, f"reporte_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf")
    
    plt.figure(figsize=(6, 4))
    plt.barh(feature_names, importances, color='steelblue')
    plt.xlabel("Importancia")
    plt.title("Importancia de Variables")
    plt.tight_layout()
    img_buffer = io.BytesIO()
    plt.savefig(img_buffer, format='png')
    img_buffer.seek(0)
    plt.close()
    
    c = canvas.Canvas(pdf_path, pagesize=A4)
    width, height = A4
    c.setFont("Helvetica-Bold", 16)
    c.drawString(50, height - 50, "Informe de Mantenimiento Predictivo")
    c.setFont("Helvetica", 10)
    c.drawString(50, height - 70, f"Generado: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    c.drawString(50, height - 100, f"â€¢ Muestras: {n_samples}, Fallas: {n_failures}")
    y = height - 130
    for line in report_str.split("\n"):
        if line.strip() and y > 100:
            c.drawString(50, y, line)
            y -= 15
    c.showPage()
    cm_data = [["", "Pred: 0", "Pred: 1"], ["Real: 0", str(cm[0][0]), str(cm[0][1])], ["Real: 1", str(cm[1][0]), str(cm[1][1])]]
    cm_table = Table(cm_data)
    cm_table.setStyle(TableStyle([('BACKGROUND', (0,0), (-1,0), colors.grey), ('GRID', (0,0), (-1,-1), 1, colors.black)]))
    cm_table.wrapOn(c, width, height)
    cm_table.drawOn(c, 50, height - 150)
    c.showPage()
    c.drawImage(ImageReader(img_buffer), 50, height - 400, width=500, height=300)
    c.save()
    return pdf_path
```

---

### ğŸ“„ `main.py`
```python
"""
main.py

Â¿Para quÃ©?
- Orquestar flujo completo.

Â¿Por quÃ©?
- Punto de entrada principal.
- Genera datos por defecto si no existen.

Â¿CÃ³mo?
1. Verifica existencia de CSV.
2. Genera o carga datos.
3. Entrena modelo.
4. Activa alertas.
"""

from src.data_generation import generate_and_save_dummy_data
from src.data_loader import load_data_from_csv
from src.data_preparation import create_ml_dataset
from src.model import train_model
from src.alerts import emit_alert_if_high_risk
import numpy as np
import os

def main():
    data_dir = "data/raw"
    if not os.path.exists(os.path.join(data_dir, "sensores.csv")):
        print("ğŸ†• Generando datos por defecto...")
        df_sensores, df_eventos = generate_and_save_dummy_data(days=365, n_components=5)
    else:
        print("ğŸ“‚ Cargando datos desde CSV...")
        df_sensores, df_eventos = load_data_from_csv(data_dir)
    
    df_ml = create_ml_dataset(df_sensores, df_eventos)
    model, pdf_path = train_model(df_ml)
    
    ejemplo = np.array([[1.8, 85, 2.1, 28, 120]])
    proba = model.predict_proba(ejemplo)[0][1]
    print(f"Probabilidad de falla: {proba:.2%}")
    
    emit_alert_if_high_risk(proba, latest_report_path=pdf_path)
    print("\nâœ… Proceso completado.")

if __name__ == "__main__":
    main()
```

---

### ğŸ“„ `scripts/run_scheduled.py` y `scripts/schedule_daily_task.py`
*(Iguales a versiones anteriores, ya explicadas)*

---

## 6. â–¶ï¸ CÃ³mo Usar el Sistema

### Paso 1: Instalar
```powershell
python install_project.py
cd represa_ml
venv\Scripts\activate
```

### Paso 2: Generar datos (opcional)
```powershell
# Ejemplo: 1 millÃ³n de registros
python generate_data_cli.py --components 50 --days 1095 --freq-hours 1.0
```

### Paso 3: Configurar correo
```powershell
$env:ALERT_EMAIL_USER="tu_correo@gmail.com"
$env:ALERT_EMAIL_PASS="contraseÃ±a_de_aplicacion"
$env:ALERT_EMAIL_RECIPIENTS="ingeniero1@empresa.com"
```

### Paso 4: Ejecutar
```powershell
python main.py
```

### Paso 5: Programar diariamente
```powershell
python scripts/schedule_daily_task.py --install --hour 6
```

---

## 7. ğŸ“Œ Beneficios Finales

- âœ… **Escalable**: genera millones de registros en segundos  
- âœ… **Persistente**: datos en CSV, reutilizables  
- âœ… **Alertas multicanal**: sonido + correo  
- âœ… **DocumentaciÃ³n automÃ¡tica**: PDF con mÃ©tricas  
- âœ… **AutomÃ¡tico**: ejecuciÃ³n diaria sin intervenciÃ³n  
- âœ… **Listo para producciÃ³n**: estructura profesional y cÃ³digo claro  

Este sistema estÃ¡ diseÃ±ado para **proteger infraestructuras crÃ­ticas** con ciencia de datos aplicada, buenas prÃ¡cticas y robustez operativa.

Â¿Necesitas ayuda para conectarlo a sensores reales o una base de datos industrial? Estoy aquÃ­ para seguir construyendo contigo.
