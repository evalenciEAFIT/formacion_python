# ğŸ Curso PrÃ¡ctico de Python para GestiÃ³n de Datos y Machine Learning
Nivel 0 - nivelaciÃ³n
https://github.com/evalenciEAFIT/formacion_python/tree/main/ML/nivel0
[ğŸ“š Nivel 0](https://github.com/evalenciEAFIT/formacion_python/tree/main/ML/nivel0) | 
[ğŸ” Nivel 1](https://github.com/evalenciEAFIT/formacion_python/tree/main/ML/nivel1) | 
[ğŸ  Repositorio](https://github.com/evalenciEAFIT/formacion_python)

## Tabla de Contenidos

1. CÃ³mo pasar parÃ¡metros por CLI al inicio
2. Buenas PrÃ¡cticas de ProgramaciÃ³n en Python (incluyendo `main`)
3. Entornos Virtuales: DefiniciÃ³n y JustificaciÃ³n
4. Estructuras de Datos BÃ¡sicas: Ventajas y Desventajas
5. Almacenamiento en Archivos Planos
6. Bases de Datos Relacionales (SQLite)
7. AnÃ¡lisis de Datos con Pandas
8. GestiÃ³n Avanzada de Archivos
9. Ejemplo Integrado: Sistema de Tareas
10. PreparaciÃ³n de Datos para Machine Learning
11. Bonus: Logging, ConfiguraciÃ³n y Manejo de Errores

---

## 1. CÃ³mo pasar parÃ¡metros por CLI al inicio

Permitir que tu programa reciba argumentos desde la **lÃ­nea de comandos (CLI)** es esencial para:
- AutomatizaciÃ³n
- Scripts reutilizables
- IntegraciÃ³n con otros sistemas
- Pruebas sin modificar el cÃ³digo

### OpciÃ³n 1: Usando `sys.argv` (simple)

```python
# cli_simple.py
import sys

def main():
    if len(sys.argv) < 2:
        print("Uso: python cli_simple.py <nombre> [edad]")
        sys.exit(1)

    nombre = sys.argv[1]
    edad = sys.argv[2] if len(sys.argv) > 2 else "desconocida"

    print(f"Hola {nombre}, tienes {edad} aÃ±os.")

if __name__ == "__main__":
    main()
```

**EjecuciÃ³n:**

```bash
Comando:
python cli_simple.py Ana 25

Salida:
Hola Ana, tienes 25 aÃ±os.
```

---

### OpciÃ³n 2: Usando `argparse` (recomendado para proyectos serios)

```python
# cli_avanzado.py
import argparse

def main():
    parser = argparse.ArgumentParser(description="Sistema de gestiÃ³n de tareas por CLI")
    parser.add_argument("--nombre", "-n", type=str, required=True, help="Tu nombre")
    parser.add_argument("--edad", "-e", type=int, default=0, help="Tu edad (opcional)")
    parser.add_argument("--verbose", "-v", action="store_true", help="Mostrar logs detallados")

    args = parser.parse_args()

    if args.verbose:
        print("[INFO] Modo verboso activado")

    print(f"Â¡Hola {args.nombre}!")
    if args.edad > 0:
        print(f"Tienes {args.edad} aÃ±os.")

if __name__ == "__main__":
    main()
```

**EjecuciÃ³n:**

```bash
Comando:
python cli_avanzado.py -n "Carlos" -e 30 -v

Salida:
[INFO] Modo verboso activado
Â¡Hola Carlos!
Tienes 30 aÃ±os.
```

---

### Consejos para CLI

- Usa `--help` o `-h` para que argparse genere ayuda automÃ¡tica.
- Valida tipos de datos (`type=int`, `type=float`, etc.).
- Define valores por defecto (`default=...`).
- Agrupa argumentos con `add_argument_group` si son muchos.
- Para ML: recibe rutas de archivos, hiperparÃ¡metros, modos (train/test), etc.

---

## 2. Buenas PrÃ¡cticas de ProgramaciÃ³n en Python (incluyendo `main`)
### Â¿Por quÃ© importa?
- Legibilidad
- Mantenibilidad
- Reusabilidad
- Evitar efectos secundarios al importar

### Recomendaciones

```python
# Buen ejemplo: uso de if __name__ == "__main__"
def saludar(nombre):
    return f"Hola, {nombre}!"

def main():
    nombre = input("Ingresa tu nombre: ")
    print(saludar(nombre))

if __name__ == "__main__":
    main()
```

### Consejos Adicionales

- Usa nombres descriptivos: `calcular_promedio()` mejor que `calc()`
- Divide en mÃ³dulos y paquetes cuando crezca el proyecto

---

## 3. Entornos Virtuales: DefiniciÃ³n y JustificaciÃ³n

### Â¿QuÃ© es un entorno virtual?
Un entorno virtual es un espacio aislado donde puedes instalar paquetes sin afectar el sistema global ni otros proyectos.

### Â¿Por quÃ© usarlo?
- Evita conflictos de versiones entre proyectos
- Facilita la replicabilidad (`requirements.txt`)
- Ideal para colaboraciÃ³n y despliegue

### CÃ³mo crear uno

```bash
# Crear entorno
python -m venv mi_entorno

# Activar (Windows)
mi_entorno\Scripts\activate

# Activar (Linux/Mac)
source mi_entorno/bin/activate

# Instalar paquetes
pip install pandas numpy

# Guardar dependencias
pip freeze > requirements.txt

# Desactivar
deactivate
```

> **Tip**: Usa `pipenv` o `poetry` para gestiÃ³n avanzada de dependencias.

---

## 4. Estructuras de Datos BÃ¡sicas: Ventajas y Desventajas

| Estructura | Mutable | Ordenada | Duplicados | Uso tÃ­pico | Ventajas | Desventajas |
|------------|---------|----------|------------|------------|----------|-------------|
| `list`     | âœ…      | âœ…       | âœ…         | Secuencias | DinÃ¡mica, indexada | Lenta en bÃºsquedas grandes |
| `tuple`    | âŒ      | âœ…       | âœ…         | Datos inmutables | RÃ¡pida, segura | No modificable |
| `set`      | âœ…      | âŒ       | âŒ         | Eliminar duplicados | BÃºsquedas O(1) | Sin orden, no indexado |
| `dict`     | âœ…      | âœ… (3.7+) | âŒ claves  | Mapeos clave-valor | Acceso rÃ¡pido por clave | Mayor consumo de memoria |

### Ejemplo prÃ¡ctico

```python
# Lista: agregar tareas
tareas = ["Comprar leche", "Estudiar Python"]
tareas.append("Hacer ejercicio")

# Tupla: coordenadas geogrÃ¡ficas
coordenadas = (19.4326, -99.1332)

# Set: eliminar duplicados
emails = ["a@b.com", "c@d.com", "a@b.com"]
unicos = set(emails)  # {'a@b.com', 'c@d.com'}

# Diccionario: perfil de usuario
usuario = {
    "nombre": "Ana",
    "edad": 25,
    "activo": True
}
```

---

## 5. Almacenamiento en Archivos Planos

### Escribir y leer archivos `.txt`

```python
# Escribir
with open("notas.txt", "w", encoding="utf-8") as f:
    f.write("Primera lÃ­nea\nSegunda lÃ­nea")

# Leer
with open("notas.txt", "r", encoding="utf-8") as f:
    contenido = f.read()
    print(contenido)
```

### CSV: Comma Separated Values

```python
import csv

# Escribir CSV
datos = [["Nombre", "Edad"], ["Ana", 25], ["Luis", 30]]
with open("personas.csv", "w", newline="", encoding="utf-8") as f:
    writer = csv.writer(f)
    writer.writerows(datos)

# Leer CSV
with open("personas.csv", "r", encoding="utf-8") as f:
    reader = csv.reader(f)
    for row in reader:
        print(row)
```

> Usa `csv.DictReader` y `csv.DictWriter` para trabajar con diccionarios.

---

## 6. Bases de Datos Relacionales (SQLite)

### Â¿Por quÃ© SQLite?
- Liviana, sin servidor
- Ideal para prototipos y aplicaciones pequeÃ±as
- Soportada nativamente en Python

### Ejemplo prÃ¡ctico: CRUD bÃ¡sico

```python
import sqlite3
from contextlib import contextmanager

# Gestor de contexto para conexiÃ³n segura
@contextmanager
def obtener_conexion(db_path="tareas.db"):
    """Maneja la conexiÃ³n a la base de datos de forma segura."""
    conn = sqlite3.connect(db_path)
    conn.row_factory = sqlite3.Row  # Permite acceder a columnas por nombre
    try:
        yield conn
    except sqlite3.Error as e:
        print(f"âŒ Error en la base de datos: {e}")
        conn.rollback()
        raise
    finally:
        conn.close()

# Crear tabla si no existe
def crear_tabla():
    with obtener_conexion() as conn:
        conn.execute("""
            CREATE TABLE IF NOT EXISTS tareas (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                titulo TEXT NOT NULL,
                completada INTEGER DEFAULT 0,
                fecha_creacion TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        conn.commit()
        print("Tabla 'tareas' creada o ya existente.")

# INSERTAR: Crear nueva tarea
def crear_tarea(titulo):
    with obtener_conexion() as conn:
        try:
            cursor = conn.execute(
                "INSERT INTO tareas (titulo) VALUES (?)",
                (titulo,)
            )
            conn.commit()
            print(f"âœ… Tarea creada con ID: {cursor.lastrowid} â†’ '{titulo}'")
            return cursor.lastrowid
        except sqlite3.Error as e:
            print(f"âŒ Error al crear tarea: {e}")
            return None

# LEER: Listar todas las tareas
def listar_tareas():
    with obtener_conexion() as conn:
        cursor = conn.execute("""
            SELECT id, titulo, completada, fecha_creacion
            FROM tareas
            ORDER BY fecha_creacion DESC
        """)
        tareas = cursor.fetchall()
        
        if not tareas:
            print("No hay tareas registradas.")
            return []
        
        print(f"\nLISTA DE TAREAS ({len(tareas)}):")
        print("-" * 60)
        for tarea in tareas:
            estado = "âœ… Completada" if tarea["completada"] else "âŒ Pendiente"
            print(f"ID: {tarea['id']} | {tarea['titulo']} | {estado} | Creada: {tarea['fecha_creacion']}")
        print("-" * 60)
        return tareas

# ACTUALIZAR: Marcar tarea como completada
def actualizar_tarea(id_tarea, completada=True):
    with obtener_conexion() as conn:
        cursor = conn.execute(
            "UPDATE tareas SET completada = ? WHERE id = ?",
            (1 if completada else 0, id_tarea)
        )
        conn.commit()
        
        if cursor.rowcount == 0:
            print(f"âš  No se encontrÃ³ tarea con ID: {id_tarea}")
            return False
        else:
            estado = "completada" if completada else "marcada como pendiente"
            print(f"Tarea ID {id_tarea} {estado}.")
            return True

# ELIMINAR: Borrar tarea por ID
def eliminar_tarea(id_tarea):
    with obtener_conexion() as conn:
        cursor = conn.execute("DELETE FROM tareas WHERE id = ?", (id_tarea,))
        conn.commit()
        
        if cursor.rowcount == 0:
            print(f"âš  No se encontrÃ³ tarea con ID: {id_tarea}")
            return False
        else:
            print(f"Tarea ID {id_tarea} eliminada.")
            return True

# BUSCAR: Buscar tarea por tÃ­tulo (bÃºsqueda parcial)
def buscar_tarea_por_titulo(palabra_clave):
    with obtener_conexion() as conn:
        cursor = conn.execute(
            "SELECT id, titulo, completada, fecha_creacion FROM tareas WHERE titulo LIKE ?",
            (f"%{palabra_clave}%",)
        )
        resultados = cursor.fetchall()
        
        if not resultados:
            print(f"No se encontraron tareas con '{palabra_clave}'.")
            return []
        
        print(f"\nRESULTADOS PARA '{palabra_clave}' ({len(resultados)}):")
        print("-" * 60)
        for tarea in resultados:
            estado = "âœ… Completada" if tarea["completada"] else "âŒ Pendiente"
            print(f"ID: {tarea['id']} | {tarea['titulo']} | {estado} | Creada: {tarea['fecha_creacion']}")
        print("-" * 60)
        return resultados

# FunciÃ³n principal de demostraciÃ³n
def main():
    print("INICIANDO DEMO CRUD CON SQLITE...\n")
    
    # 1. Crear tabla
    crear_tabla()
    
    # 2. Insertar tareas
    id1 = crear_tarea("Aprender SQL")
    id2 = crear_tarea("Practicar Python")
    id3 = crear_tarea("Hacer ejercicio")
    
    print("\n" + "="*60)
    
    # 3. Listar todas
    listar_tareas()
    
    print("\n" + "="*60)
    
    # 4. Actualizar (marcar como completada)
    actualizar_tarea(id1, completada=True)
    actualizar_tarea(id2, completada=True)
    
    print("\n" + "="*60)
    
    # 5. Listar nuevamente
    listar_tareas()
    
    print("\n" + "="*60)
    
    # 6. Buscar por palabra clave
    buscar_tarea_por_titulo("Python")
    
    print("\n" + "="*60)
    
    # 7. Eliminar una tarea
    eliminar_tarea(id3)
    
    print("\n" + "="*60)
    
    # 8. Listar final
    listar_tareas()

# Ejecutar demo
if __name__ == "__main__":
    main()
```

> Usa parÃ¡metros `?` para evitar inyecciones SQL.

---

## 7. AnÃ¡lisis de Datos con Pandas

### InstalaciÃ³n

```bash
pip install pandas matplotlib
```

### Ejemplo: AnÃ¡lisis de ventas

```python
import pandas as pd

# Crear DataFrame
data = {
    "Producto": ["A", "B", "C", "A"],
    "Ventas": [100, 150, 200, 120],
    "Mes": ["Ene", "Ene", "Feb", "Feb"]
}
df = pd.DataFrame(data)

# Operaciones comunes
print(df.head())
print(df.groupby("Producto")["Ventas"].sum())
print(df[df["Ventas"] > 130])

# Guardar y cargar
df.to_csv("ventas.csv", index=False)
df_cargado = pd.read_csv("ventas.csv")
```

### VisualizaciÃ³n rÃ¡pida

```python
import matplotlib.pyplot as plt

df.groupby("Producto")["Ventas"].sum().plot(kind="bar")
plt.title("Ventas por Producto")
plt.show()
```

---

## 8. GestiÃ³n Avanzada de Archivos

### 8.0.  Manejo de fechas en nombres de archivos

```python
from datetime import datetime

hoy = datetime.now().strftime("%Y%m%d_%H%M%S")
nombre = f"backup_{hoy}.zip"
print(nombre)  # backup_20250405_103045.zip
```


###  8.1. Recorrer Directorios (con `pathlib` â€” forma moderna y recomendada)

###  Ejemplo: `listar_csv_en_directorio.py`

```python
from pathlib import Path

def listar_archivos_csv(ruta_directorio="datasets"):
    """
    Lista todos los archivos .csv en un directorio.
    Si el directorio no existe, lo crea vacÃ­o.
    """
    directorio = Path(ruta_directorio)
    
    # Crear directorio si no existe
    directorio.mkdir(exist_ok=True)
    print(f" Buscando archivos CSV en: '{directorio.absolute()}'\n")

    # Obtener todos los .csv
    archivos_csv = list(directorio.glob("*.csv"))
    
    if not archivos_csv:
        print(" No se encontraron archivos .csv")
        return []

    print(f" Encontrados {len(archivos_csv)} archivos CSV:")
    print("-" * 50)
    for i, archivo in enumerate(archivos_csv, 1):
        # archivo.name â†’ solo nombre
        # archivo.stem â†’ nombre sin extensiÃ³n
        # archivo.suffix â†’ extensiÃ³n
        print(f"{i:2}. {archivo.name} (TamaÃ±o: {archivo.stat().st_size} bytes)")

    return archivos_csv

#  Ejecutar ejemplo
if __name__ == "__main__":
    listar_archivos_csv()
```

###  Salida esperada (si tienes `ventas.csv`, `personas.csv`):

```
 Buscando archivos CSV en: 'C:\tu_proyecto\datasets'

 Encontrados 2 archivos CSV:
--------------------------------------------------
 1. ventas.csv (TamaÃ±o: 128 bytes)
 2. personas.csv (TamaÃ±o: 85 bytes)
```

---

###  8.2. Crear Directorios (con estructura anidada)

###  Ejemplo: `crear_estructura_proyecto.py`

```python
from pathlib import Path

def crear_estructura_datos():
    """
    Crea una estructura tÃ­pica para gestiÃ³n de datos.
    """
    estructura = [
        "data/raw",
        "data/processed",
        "data/external",
        "backups",
        "logs",
        "exports"
    ]

    print("Creando estructura de directorios...")
    for carpeta in estructura:
        Path(carpeta).mkdir(parents=True, exist_ok=True)
        print(f" {carpeta}/ creado")

    print("\n Estructura final:")
    for item in Path(".").glob("data*/"):
        print(f"  â””â”€â”€ {item}")
```

###  Salida esperada:

```
Creando estructura de directorios...
 data/raw/ creado
 data/processed/ creado
 data/external/ creado
 backups/ creado
 logs/ creado
 exports/ creado

 Estructura final:
  â””â”€â”€ data/
```

---

###  8.3. Comprimir Archivos en ZIP (con manejo de errores)

###  Ejemplo: `comprimir_csvs.py`

```python
from pathlib import Path
import zipfile
from datetime import datetime

def comprimir_archivos_csv(origen="datasets", destino="backups"):
    """
    Comprime todos los .csv de un directorio en un ZIP con timestamp.
    """
    directorio_origen = Path(origen)
    directorio_destino = Path(destino)
    
    # Crear directorio de destino
    directorio_destino.mkdir(exist_ok=True)

    # Buscar CSVs
    archivos_csv = list(directorio_origen.glob("*.csv"))
    if not archivos_csv:
        print(f"âš  No hay archivos .csv en '{origen}' para comprimir.")
        return None

    # Nombre con fecha y hora
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    nombre_zip = directorio_destino / f"backup_csv_{timestamp}.zip"

    print(f" Creando backup: {nombre_zip.name}")
    print("-" * 50)

    try:
        with zipfile.ZipFile(nombre_zip, "w", zipfile.ZIP_DEFLATED) as zf:
            for archivo in archivos_csv:
                zf.write(archivo, arcname=archivo.name)  # arcname evita rutas largas
                print(f"   + {archivo.name} ({archivo.stat().st_size} bytes)")

        print(f"\n Â¡CompresiÃ³n exitosa! TamaÃ±o total: {nombre_zip.stat().st_size} bytes")
        return nombre_zip

    except Exception as e:
        print(f" Error al comprimir: {e}")
        return None

# Ejecutar ejemplo
if __name__ == "__main__":
    comprimir_archivos_csv()
```

###  Salida esperada:

```
Creando backup: backup_csv_20250504_123045.zip
--------------------------------------------------
   + ventas.csv (128 bytes)
   + personas.csv (85 bytes)

Â¡CompresiÃ³n exitosa! TamaÃ±o total: 427 bytes
```


### 8.4. Descomprimir Archivos ZIP (con manejo de errores y limpieza)

###  Ejemplo: `descomprimir_backup.py`

```python
from pathlib import Path
import zipfile

def descomprimir_zip(ruta_zip, destino="restaurado"):
    """
    Descomprime un archivo .zip en una carpeta especÃ­fica.
    """
    archivo_zip = Path(ruta_zip)
    directorio_destino = Path(destino)

    # Verificar que el ZIP existe
    if not archivo_zip.exists():
        print(f" El archivo {ruta_zip} no existe.")
        return False

    # Crear carpeta de destino
    directorio_destino.mkdir(exist_ok=True)

    try:
        with zipfile.ZipFile(archivo_zip, "r") as zf:
            print(f" Descomprimiendo {archivo_zip.name} en '{directorio_destino}/'...")
            zf.extractall(directorio_destino)
            
            # Listar archivos extraÃ­dos
            extraidos = list(directorio_destino.iterdir())
            print(f" {len(extraidos)} archivos extraÃ­dos:")
            for archivo in extraidos:
                print(f"   - {archivo.name}")
                
        return True

    except zipfile.BadZipFile:
        print(" El archivo no es un ZIP vÃ¡lido.")
        return False
    except Exception as e:
        print(f" Error al descomprimir: {e}")
        return False

#  Ejecutar ejemplo
if __name__ == "__main__":
    # Suponiendo que ya ejecutaste el ejemplo anterior y generaste un .zip
    backups = list(Path("backups").glob("*.zip"))
    if backups:
        ultimo_backup = sorted(backups)[-1]  # el mÃ¡s reciente
        descomprimir_zip(ultimo_backup, "datos_restaurados")
    else:
        print(" No hay backups disponibles para restaurar.")
```

### Salida esperada:

```
 Descomprimiendo backup_csv_20250504_123045.zip en 'datos_restaurados/'...
 2 archivos extraÃ­dos:
   - ventas.csv
   - personas.csv
```

---

### 8.5. Bonus: Copiar, Mover y Eliminar Archivos

### Ejemplo: `gestion_archivos_bonus.py`

```python
from pathlib import Path
import shutil

def copiar_csv_a_procesados(origen="datasets", destino="data/processed"):
    """Copia todos los .csv al directorio 'processed'."""
    Path(destino).mkdir(parents=True, exist_ok=True)
    
    for csv in Path(origen).glob("*.csv"):
        destino_path = Path(destino) / csv.name
        shutil.copy2(csv, destino_path)  # copy2 copia tambiÃ©n metadatos
        print(f" Copiado: {csv.name} â†’ {destino_path}")

def mover_csv_a_raw(origen="datasets", destino="data/raw"):
    """Mueve (no copia) los CSVs al directorio 'raw'."""
    Path(destino).mkdir(parents=True, exist_ok=True)
    
    for csv in Path(origen).glob("*.csv"):
        destino_path = Path(destino) / csv.name
        shutil.move(csv, destino_path)
        print(f" Movido: {csv.name} â†’ {destino_path}")

def limpiar_directorio_vacio(ruta):
    """Elimina un directorio si estÃ¡ vacÃ­o."""
    carpeta = Path(ruta)
    if carpeta.exists() and not any(carpeta.iterdir()):
        carpeta.rmdir()
        print(f" Directorio vacÃ­o eliminado: {ruta}")
```


### EjecuciÃ³n Recomendada (para probar todo en orden)

Crea un script `ejecutar_gestion_archivos.py`:

```python
from pathlib import Path

# 1. Crear estructura
from crear_estructura_proyecto import crear_estructura_datos
crear_estructura_datos()

print("\n" + "="*60 + "\n")

# 2. Listar CSVs
from listar_csv_en_directorio import listar_archivos_csv
listar_archivos_csv()

print("\n" + "="*60 + "\n")

# 3. Comprimir
from comprimir_csvs import comprimir_archivos_csv
zip_creado = comprimir_archivos_csv()

print("\n" + "="*60 + "\n")

# 4. Descomprimir
if zip_creado:
    from descomprimir_backup import descomprimir_zip
    descomprimir_zip(zip_creado, "datos_restaurados")

print("\n" + "="*60 + "\n")

# 5. Copiar a processed
from gestion_archivos_bonus import copiar_csv_a_procesados
copiar_csv_a_procesados()
```
---

### Estructura Final del Proyecto

```
gestion_archivos/
â”œâ”€â”€ datasets/
â”‚   â”œâ”€â”€ ventas.csv
â”‚   â””â”€â”€ personas.csv
â”œâ”€â”€ listar_csv_en_directorio.py
â”œâ”€â”€ crear_estructura_proyecto.py
â”œâ”€â”€ comprimir_csvs.py
â”œâ”€â”€ descomprimir_backup.py
â”œâ”€â”€ gestion_archivos_bonus.py
â””â”€â”€ ejecutar_gestion_archivos.py  â† Â¡Ejecuta todo en orden!
```

---

## 9. Ejemplo Integrado: Sistema de Tareas

> Un sistema modular, profesional y listo para usar, con SQLite, CLI, logging, validaciÃ³n y buenas prÃ¡cticas.

---
## ğŸ“¥ Â¿CÃ³mo empezar?

1. Crea la carpeta `sistema_tareas/`
2. Guarda los 4 archivos: `main.py`, `database.py`, `models.py`, `utils.py`
3. Ejecuta:

```bash
python main.py -h
```
---
## ğŸ“ Estructura del Proyecto (Actualizada)

```
sistema_tareas/
â”œâ”€â”€ main.py          â† CLI principal (mejorado)
â”œâ”€â”€ database.py      â† CRUD completo + migraciones
â”œâ”€â”€ models.py        â† Clase Tarea
â”œâ”€â”€ utils.py         â† Â¡AHORA INCLUIDO! (validaciÃ³n, logging, ayuda)
â””â”€â”€ tareas.db        â† se crea automÃ¡ticamente
```

---

## ğŸ“„ 9.1. `models.py` â€” Clase Tarea (sin cambios, pero completo)

```python
class Tarea:
    def __init__(self, id, titulo, completada=False):
        self.id = id
        self.titulo = titulo
        self.completada = bool(completada)  # Asegura tipo booleano

    def __str__(self):
        estado = "âœ…" if self.completada else "âŒ"
        return f"{self.id:2}. {self.titulo:<30} {estado}"

    def __repr__(self):
        return f"Tarea(id={self.id}, titulo='{self.titulo}', completada={self.completada})"
```

---

## ğŸ“„ 9.2. `database.py` â€” CRUD Completo + Migraciones

```python

import sqlite3
from contextlib import contextmanager
from pathlib import Path
from models import Tarea  # âœ… Â¡IMPORTANTE! Sin esto, 'Tarea' no existe

@contextmanager
def obtener_conexion(db_path="tareas.db"):
    """Gestiona conexiÃ³n segura a la base de datos."""
    conn = sqlite3.connect(db_path)
    conn.row_factory = sqlite3.Row
    try:
        yield conn
    except sqlite3.Error as e:
        print(f"âŒ Error en la base de datos: {e}")
        conn.rollback()
        raise
    finally:
        conn.close()

def crear_tabla():
    """Crea la tabla si no existe."""
    with obtener_conexion() as conn:
        conn.execute("""
            CREATE TABLE IF NOT EXISTS tareas (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                titulo TEXT NOT NULL,
                completada INTEGER DEFAULT 0,
                fecha_creacion TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        conn.commit()

def agregar_columna_fecha_si_no_existe():
    """Agrega columna 'fecha_creacion' si no existe (migraciÃ³n)."""
    with obtener_conexion() as conn:
        cursor = conn.execute("PRAGMA table_info(tareas)")
        columnas = [col[1] for col in cursor.fetchall()]
        if "fecha_creacion" not in columnas:
            conn.execute("ALTER TABLE tareas ADD COLUMN fecha_creacion TIMESTAMP DEFAULT CURRENT_TIMESTAMP")
            conn.commit()

class TareaDB:
    def __init__(self, db_path="tareas.db"):
        self.db_path = db_path
        Path(db_path).touch(exist_ok=True)  # Crea archivo si no existe
        crear_tabla()
        agregar_columna_fecha_si_no_existe()

    def agregar(self, titulo):
        with obtener_conexion(self.db_path) as conn:
            cursor = conn.execute("INSERT INTO tareas (titulo) VALUES (?)", (titulo,))
            conn.commit()
            return cursor.lastrowid

    def listar(self):
        with obtener_conexion(self.db_path) as conn:
            cursor = conn.execute("""
                SELECT id, titulo, completada 
                FROM tareas 
                ORDER BY id DESC
            """)
            # âœ… Ahora 'Tarea' estÃ¡ definido gracias al import
            return [Tarea(row["id"], row["titulo"], row["completada"]) for row in cursor.fetchall()]

    def completar(self, id_tarea):
        with obtener_conexion(self.db_path) as conn:
            cursor = conn.execute("UPDATE tareas SET completada = 1 WHERE id = ?", (id_tarea,))
            conn.commit()
            return cursor.rowcount > 0

    def eliminar(self, id_tarea):
        with obtener_conexion(self.db_path) as conn:
            cursor = conn.execute("DELETE FROM tareas WHERE id = ?", (id_tarea,))
            conn.commit()
            return cursor.rowcount > 0

    def buscar(self, palabra):
        with obtener_conexion(self.db_path) as conn:
            cursor = conn.execute(
                "SELECT id, titulo, completada FROM tareas WHERE titulo LIKE ?",
                (f"%{palabra}%",)
            )
            return [Tarea(row["id"], row["titulo"], row["completada"]) for row in cursor.fetchall()]

```

---

## ğŸ“„ 9.3. `utils.py`

```python
import logging
import argparse

def configurar_logging(nivel=logging.INFO):
    """Configura el sistema de logging para la aplicaciÃ³n."""
    logging.basicConfig(
        level=nivel,
        format="%(asctime)s - %(levelname)s - %(message)s",
        handlers=[
            logging.FileHandler("sistema_tareas.log", encoding="utf-8"),
            logging.StreamHandler()
        ]
    )

def validar_titulo(titulo):
    """Valida que el tÃ­tulo no estÃ© vacÃ­o y tenga longitud razonable."""
    if not titulo or not titulo.strip():
        raise ValueError("âŒ El tÃ­tulo no puede estar vacÃ­o.")
    if len(titulo) > 200:
        raise ValueError("âŒ El tÃ­tulo es demasiado largo (mÃ¡x. 200 caracteres).")
    return titulo.strip()

def mostrar_ayuda_personalizada():
    """Muestra una ayuda amigable con emojis y ejemplos."""
    ayuda = """
ğŸŒŸ SISTEMA DE GESTIÃ“N DE TAREAS ğŸŒŸ

Uso:
  python main.py [OPCIÃ“N]

Opciones:
  -a, --agregar TEXTO     â• Agregar nueva tarea
  -l, --listar            ğŸ“‹ Listar todas las tareas
  -c, --completar ID      âœ… Marcar tarea como completada
  -e, --eliminar ID       ğŸ—‘ï¸  Eliminar tarea por ID
  -b, --buscar PALABRA    ğŸ” Buscar tareas por palabra clave
  -v, --verbose           ğŸ“¢ Modo detallado (muestra logs)
  -h, --help              â“ Mostrar esta ayuda

Ejemplos:
  python main.py -a "Estudiar Python"
  python main.py -l
  python main.py -c 1
  python main.py -b "Python"
"""
    print(ayuda)
```

---

## ğŸ“„ 9.4. `main.py` 

```python
import argparse
from database import TareaDB
from models import Tarea
from utils import configurar_logging, validar_titulo, mostrar_ayuda_personalizada
import logging

def main():
    parser = argparse.ArgumentParser(add_help=False)  # Desactivamos ayuda automÃ¡tica
    parser.add_argument("--agregar", "-a", type=str, help="Agregar nueva tarea")
    parser.add_argument("--listar", "-l", action="store_true", help="Listar tareas")
    parser.add_argument("--completar", "-c", type=int, help="Completar tarea por ID")
    parser.add_argument("--eliminar", "-e", type=int, help="Eliminar tarea por ID")
    parser.add_argument("--buscar", "-b", type=str, help="Buscar tareas por palabra clave")
    parser.add_argument("--verbose", "-v", action="store_true", help="Modo detallado")
    parser.add_argument("--help", "-h", action="store_true", help="Mostrar ayuda")

    args = parser.parse_args()

    # Configurar logging
    nivel = logging.INFO if args.verbose else logging.WARNING
    configurar_logging(nivel)

    # Mostrar ayuda personalizada
    if args.help:
        mostrar_ayuda_personalizada()
        return

    # Inicializar base de datos
    db = TareaDB()

    try:
        if args.agregar:
            titulo = validar_titulo(args.agregar)
            id_nueva = db.agregar(titulo)
            print(f"âœ… Tarea agregada con ID {id_nueva}: '{titulo}'")
            logging.info(f"Tarea agregada: ID {id_nueva}, '{titulo}'")

        elif args.listar:
            tareas = db.listar()
            if not tareas:
                print("ğŸ“­ No hay tareas registradas.")
            else:
                print(f"\nğŸ“‹ LISTA DE TAREAS ({len(tareas)}):")
                print("=" * 60)
                for tarea in tareas:
                    print(tarea)
                print("=" * 60)

        elif args.completar is not None:
            if db.completar(args.completar):
                print(f"âœ… Tarea ID {args.completar} marcada como completada.")
                logging.info(f"Tarea completada: ID {args.completar}")
            else:
                print(f"âš ï¸  No se encontrÃ³ tarea con ID {args.completar}.")

        elif args.eliminar is not None:
            if db.eliminar(args.eliminar):
                print(f"ğŸ—‘ï¸  Tarea ID {args.eliminar} eliminada.")
                logging.info(f"Tarea eliminada: ID {args.eliminar}")
            else:
                print(f"âš ï¸  No se encontrÃ³ tarea con ID {args.eliminar}.")

        elif args.buscar:
            resultados = db.buscar(args.buscar)
            if not resultados:
                print(f"ğŸ” No se encontraron tareas con '{args.buscar}'.")
            else:
                print(f"\nğŸ” RESULTADOS PARA '{args.buscar}' ({len(resultados)}):")
                print("=" * 60)
                for tarea in resultados:
                    print(tarea)
                print("=" * 60)

        else:
            mostrar_ayuda_personalizada()

    except ValueError as ve:
        print(ve)
        logging.error(f"Error de validaciÃ³n: {ve}")
    except Exception as e:
        print(f"âŒ Error inesperado: {e}")
        logging.error(f"Error inesperado: {e}")

if __name__ == "__main__":
    main()
```

---

## ğŸ§ª EjecuciÃ³n y Salidas Esperadas

### â• Agregar tarea

```bash
python main.py -a "Aprender Pandas"
```
```
âœ… Tarea agregada con ID 1: 'Aprender Pandas'
```

### ğŸ“‹ Listar tareas

```bash
python main.py -l
```
```
ğŸ“‹ LISTA DE TAREAS (2):
============================================================
 1. Aprender Pandas                     âœ…
 2. Hacer ejercicio                     âŒ
============================================================
```

### âœ… Completar tarea

```bash
python main.py -c 2
```
```
âœ… Tarea ID 2 marcada como completada.
```

### ğŸ—‘ï¸ Eliminar tarea

```bash
python main.py -e 1
```
```
ğŸ—‘ï¸  Tarea ID 1 eliminada.
```

### ğŸ” Buscar tarea

```bash
python main.py -b "Pandas"
```
```
ğŸ” RESULTADOS PARA 'Pandas' (1):
============================================================
 3. Aprender Pandas                     âœ…
============================================================
```

### â“ Mostrar ayuda

```bash
python main.py -h
```
```
ğŸŒŸ SISTEMA DE GESTIÃ“N DE TAREAS ğŸŒŸ

Uso:
  python main.py [OPCIÃ“N]

Opciones:
  -a, --agregar TEXTO     â• Agregar nueva tarea
  -l, --listar            ğŸ“‹ Listar todas las tareas
  -c, --completar ID      âœ… Marcar tarea como completada
  -e, --eliminar ID       ğŸ—‘ï¸  Eliminar tarea por ID
  -b, --buscar PALABRA    ğŸ” Buscar tareas por palabra clave
  -v, --verbose           ğŸ“¢ Modo detallado (muestra logs)
  -h, --help              â“ Mostrar esta ayuda

Ejemplos:
  python main.py -a "Estudiar Python"
  python main.py -l
  python main.py -c 1
  python main.py -b "Python"
```

---

## ğŸ“„ Archivo de Log Generado (`sistema_tareas.log`)

```
2025-05-04 14:30:45,123 - INFO - Tarea agregada: ID 1, 'Aprender Pandas'
2025-05-04 14:31:10,456 - INFO - Tarea completada: ID 2
2025-05-04 14:32:05,789 - INFO - Tarea eliminada: ID 1
```

---


## 10. PreparaciÃ³n de Datos para Machine Learning
> Aprende a limpiar, transformar y preparar tus datos para modelos de ML â€” con cÃ³digo listo para producciÃ³n, manejo de errores y buenas prÃ¡cticas.

## ğŸ“¦ 10.1. GuÃ­a para Instalar Paquetes Necesarios

### âœ… OpciÃ³n 1: InstalaciÃ³n manual (recomendada para aprendizaje)

```bash
# Activa tu entorno virtual primero (si lo usas)
# En Windows:
mi_entorno\Scripts\activate

# En Linux/Mac:
source mi_entorno/bin/activate

# Instala los paquetes esenciales
pip install pandas scikit-learn joblib numpy matplotlib
```

### âœ… OpciÃ³n 2: Usar `requirements.txt` (recomendado para proyectos y colaboraciÃ³n)

Crea un archivo `requirements.txt` en la raÃ­z de tu proyecto:

```txt
# requirements.txt
pandas>=2.0.0
scikit-learn>=1.3.0
joblib>=1.3.0
numpy>=1.24.0
matplotlib>=3.7.0
```

Luego ejecuta:

```bash
pip install -r requirements.txt
```

> ğŸ’¡ **Tip profesional**: Siempre fija versiones mÃ­nimas para evitar incompatibilidades.

---

## ğŸ§¹ 10.2. Limpieza y PreparaciÃ³n de Datos â€” Script Completo y Robusto

### ğŸ“„ `src/data_preprocessing.py`

```python
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
import joblib
import logging
import os
from pathlib import Path

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler("preprocessing.log", encoding="utf-8"),
        logging.StreamHandler()
    ]
)

def cargar_datos(ruta):
    """Carga un CSV y valida que exista."""
    if not os.path.exists(ruta):
        raise FileNotFoundError(f"âŒ Archivo no encontrado: {ruta}")
    
    logging.info(f"ğŸ“‚ Cargando datos desde: {ruta}")
    df = pd.read_csv(ruta)
    logging.info(f"ğŸ“Š Forma inicial: {df.shape}")
    return df

def explorar_datos(df):
    """Muestra informaciÃ³n bÃ¡sica del dataset."""
    print("\nğŸ” INFORMACIÃ“N DEL DATASET:")
    print("=" * 50)
    print("Columnas:", list(df.columns))
    print("\nâ“ Valores nulos por columna:")
    print(df.isnull().sum())
    print(f"\nğŸ“ˆ Tipos de datos:\n{df.dtypes}")
    print(f"\nğŸ“‰ DescripciÃ³n estadÃ­stica:\n{df.describe(include='all').T}")

def limpiar_datos(df):
    """Limpia el dataset paso a paso."""
    logging.info("ğŸ§¹ Iniciando limpieza de datos...")

    # 1. Eliminar filas con mÃ¡s del 50% de valores nulos
    umbral = len(df.columns) * 0.5
    df = df.dropna(thresh=umbral)
    logging.info(f"ğŸ—‘ï¸  Filas eliminadas por muchos nulos. Nueva forma: {df.shape}")

    # 2. Rellenar Edad (si existe)
    if "Edad" in df.columns:
        if df["Edad"].isnull().any():
            mediana_edad = df["Edad"].median()
            df["Edad"] = df["Edad"].fillna(mediana_edad)
            logging.info(f"ğŸ§“ Edad rellenada con mediana: {mediana_edad}")

    # 3. Rellenar Ingreso (si existe)
    if "Ingreso" in df.columns:
        if df["Ingreso"].isnull().any():
            media_ingreso = df["Ingreso"].mean()
            df["Ingreso"] = df["Ingreso"].fillna(media_ingreso)
            logging.info(f"ğŸ’° Ingreso rellenado con media: {media_ingreso:.2f}")

    # 4. Codificar variables categÃ³ricas
    columnas_categoricas = df.select_dtypes(include=["object"]).columns.tolist()
    columnas_categoricas = [col for col in columnas_categoricas if col != "Nombre"]  # Excluir identificadores

    if columnas_categoricas:
        logging.info(f"ğŸ”¤ Codificando variables categÃ³ricas: {columnas_categoricas}")
        df = pd.get_dummies(df, columns=columnas_categoricas, prefix_sep="_", dummy_na=True)

    return df

def escalar_datos(df, columnas_numericas=None):
    """Escala columnas numÃ©ricas usando StandardScaler."""
    if columnas_numericas is None:
        columnas_numericas = ["Edad", "Ingreso"]
    
    # Filtrar solo columnas que existan
    columnas_numericas = [col for col in columnas_numericas if col in df.columns]
    
    if not columnas_numericas:
        logging.warning("âš ï¸  No hay columnas numÃ©ricas para escalar.")
        return df, None

    scaler = StandardScaler()
    df[columnas_numericas] = scaler.fit_transform(df[columnas_numericas])
    logging.info(f"ğŸ“ Columnas escaladas: {columnas_numericas}")
    
    return df, scaler

def guardar_datos(df, ruta_salida):
    """Guarda el dataset limpio."""
    # Asegurar que el directorio exista
    Path(ruta_salida).parent.mkdir(parents=True, exist_ok=True)
    
    df.to_csv(ruta_salida, index=False, encoding="utf-8")
    logging.info(f"âœ… Datos limpios guardados en: {ruta_salida}")
    return ruta_salida

def main():
    try:
        # Rutas (ajusta segÃºn tu estructura)
        RUTA_ENTRADA = "data/raw/datos_sucios.csv"
        RUTA_SALIDA = "data/processed/datos_limpios.csv"
        RUTA_SCALER = "models/scaler.pkl"

        # Crear estructura de directorios
        for carpeta in ["data/raw", "data/processed", "models", "logs"]:
            Path(carpeta).mkdir(parents=True, exist_ok=True)

        # Proceso completo
        df = cargar_datos(RUTA_ENTRADA)
        explorar_datos(df)
        
        df_limpio = limpiar_datos(df)
        df_limpio, scaler = escalar_datos(df_limpio)
        
        guardar_datos(df_limpio, RUTA_SALIDA)
        
        if scaler:
            joblib.dump(scaler, RUTA_SCALER)
            logging.info(f"ğŸ’¾ Scaler guardado en: {RUTA_SCALER}")

        print(f"\nğŸ‰ Â¡Proceso completado exitosamente!")
        print(f"âœ… Datos limpios: {RUTA_SALIDA}")
        print(f"âœ… Scaler guardado: {RUTA_SCALER}")

    except Exception as e:
        logging.error(f"ğŸ’¥ Error durante el procesamiento: {e}")
        raise

if __name__ == "__main__":
    main()
```

---

## ğŸ“‚10.3. Estructura de Proyecto Recomendada

```
proyecto_ml/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ datos_sucios.csv          â† Â¡DescÃ¡rgalo del curso!
â”‚   â””â”€â”€ processed/
â”‚       â””â”€â”€ datos_limpios.csv         â† Â¡Se genera automÃ¡ticamente!
â”œâ”€â”€ models/
â”‚   â””â”€â”€ scaler.pkl                    â† Â¡Se genera automÃ¡ticamente!
â”œâ”€â”€ src/
â”‚   â””â”€â”€ data_preprocessing.py         â† Script principal
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ preprocessing.log             â† Registro de ejecuciÃ³n
â”œâ”€â”€ requirements.txt                  â† Dependencias
â””â”€â”€ README.md                         â† Instrucciones
```

---

## ğŸ§ª 10.4. EjecuciÃ³n Paso a Paso

### Paso 1: Crear entorno virtual (opcional pero recomendado)

```bash
python -m venv ml_entorno
ml_entorno\Scripts\activate    # Windows
source ml_entorno/bin/activate # Linux/Mac
```

### Paso 2: Instalar dependencias

```bash
pip install -r requirements.txt
```

### Paso 3: Colocar `datos_sucios.csv` en `data/raw/`

> Si no lo tienes, aquÃ­ estÃ¡ el contenido mÃ­nimo para probar:

```csv
Nombre,Edad,Categoria,Ingreso
Ana,25,A,3500
Luis,,B,4200
Maria,30,,5000
Juan,22,A,
,28,C,3800
```

### Paso 4: Ejecutar el script

```bash
python src/data_preprocessing.py
```

### âœ… Salida esperada:

```
2025-05-04 16:30:45,123 - INFO - ğŸ“‚ Cargando datos desde: data/raw/datos_sucios.csv
2025-05-04 16:30:45,456 - INFO - ğŸ“Š Forma inicial: (5, 4)
...
2025-05-04 16:30:46,789 - INFO - ğŸ§“ Edad rellenada con mediana: 25.0
2025-05-04 16:30:46,890 - INFO - ğŸ’° Ingreso rellenado con media: 4125.00
2025-05-04 16:30:47,001 - INFO - ğŸ”¤ Codificando variables categÃ³ricas: ['Categoria']
2025-05-04 16:30:47,112 - INFO - ğŸ“ Columnas escaladas: ['Edad', 'Ingreso']
2025-05-04 16:30:47,223 - INFO - âœ… Datos limpios guardados en: data/processed/datos_limpios.csv
2025-05-04 16:30:47,334 - INFO - ğŸ’¾ Scaler guardado en: models/scaler.pkl

ğŸ‰ Â¡Proceso completado exitosamente!
âœ… Datos limpios: data/processed/datos_limpios.csv
âœ… Scaler guardado: models/scaler.pkl
```

---

## ğŸ“„ 10.5. Archivo `requirements.txt` Completo

```txt
# requirements.txt - Proyecto de PreparaciÃ³n de Datos para ML

# Procesamiento de datos
pandas>=2.0.0
numpy>=1.24.0

# Machine Learning
scikit-learn>=1.3.0

# SerializaciÃ³n
joblib>=1.3.0

# VisualizaciÃ³n (opcional)
matplotlib>=3.7.0

# Para notebooks (opcional)
jupyter>=1.0.0
```

---

## ğŸ§© 10.6. Bonus: Script para Verificar InstalaciÃ³n

Crea `verificar_instalacion.py`:

```python
def verificar_paquetes():
    paquetes = ["pandas", "sklearn", "joblib", "numpy"]
    todos_instalados = True
    
    print("ğŸ” Verificando instalaciÃ³n de paquetes...\n")
    
    for paquete in paquetes:
        try:
            __import__(paquete)
            print(f"âœ… {paquete} - INSTALADO")
        except ImportError:
            print(f"âŒ {paquete} - NO INSTALADO")
            todos_instalados = False
    
    if todos_instalados:
        print("\nğŸ‰ Â¡Todos los paquetes estÃ¡n instalados correctamente!")
    else:
        print("\nâš ï¸  Algunos paquetes faltan. Ejecuta: pip install -r requirements.txt")

if __name__ == "__main__":
    verificar_paquetes()
```

EjecÃºtalo con:

```bash
python verificar_instalacion.py
```

---
## CLARIDAD de pkl
### ğŸ“¦ Â¿QuÃ© es un archivo `.pkl` y para quÃ© sirve?

---

### DefiniciÃ³n simple

Un archivo con extensiÃ³n **`.pkl`** es un archivo **serializado en formato "pickle"**, que permite **guardar y cargar objetos de Python** (como modelos de machine learning, estructuras de datos, scalers, etc.) **en disco**, para usarlos mÃ¡s tarde sin tener que volver a crearlos o entrenarlos.

> El nombre viene de **"pickle"** â€” el mÃ³dulo de Python que se encarga de la serializaciÃ³n.

---

### Â¿QuÃ© significa "serializar"?

**Serializar** = Convertir un objeto en memoria (como un modelo entrenado, una lista, un diccionario, un scaler, etc.) en una secuencia de bytes que se puede guardar en un archivo o enviar por red.

**Deserializar** = Hacer el proceso inverso: leer esos bytes y reconstruir el objeto original en memoria.

---

### ğŸ†š `pickle` vs `joblib`

Ambos sirven para lo mismo, pero:

| CaracterÃ­stica          | `pickle` (built-in)           | `joblib` (recomendado para ML)       |
|-------------------------|-------------------------------|--------------------------------------|
| Velocidad               | ğŸ¢ MÃ¡s lento con arrays NumPy | ğŸ‡ MÃ¡s rÃ¡pido con arrays NumPy       |
| TamaÃ±o de archivo       | MÃ¡s grande                    | MÃ¡s compacto                         |
| Uso tÃ­pico              | Objetos pequeÃ±os              | Modelos, datasets, scalers grandes   |
| Compatibilidad          | Nativo en Python              | Necesita `pip install joblib`        |

> âœ… **RecomendaciÃ³n profesional**: Usa **`joblib`** para machine learning. Es mÃ¡s eficiente y es el estÃ¡ndar en la comunidad (scikit-learn lo usa internamente).

---

### âš ï¸ Advertencias de seguridad

**NUNCA cargues un `.pkl` de fuente no confiable.**

El formato pickle puede ejecutar cÃ³digo arbitrario al deserializar. Solo usa archivos `.pkl` generados por ti o por fuentes de confianza.

> ğŸ” Para entornos de producciÃ³n o APIs, considera formatos mÃ¡s seguros como `JSON`, `HDF5`, o formatos de modelo como `ONNX`.

---

### ğŸ“ Ejemplo prÃ¡ctico: Flujo tÃ­pico en ML

```bash
proyecto_ml/
â”œâ”€â”€ train.py           # Entrena y guarda modelo.pkl + scaler.pkl
â”œâ”€â”€ predict.py         # Carga modelo.pkl + scaler.pkl y predice
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ modelo.pkl
â”‚   â””â”€â”€ scaler.pkl
â””â”€â”€ data/
    â””â”€â”€ nuevos_datos.csv
```


### ğŸ¯ Â¿Por quÃ© usar `.pkl`?

| Ventaja                           | ExplicaciÃ³n                                                                 |
|-----------------------------------|-----------------------------------------------------------------------------|
| â±ï¸ Ahorra tiempo                 | No necesitas reentrenar modelos cada vez que ejecutas tu app.               |
| ğŸ’¾ Persistencia                  | Guardas el estado exacto de un objeto complejo.                             |
| ğŸ”„ Consistencia                  | Aseguras que usas los mismos parÃ¡metros/preprocesadores en train y predict. |
| ğŸ§© Modularidad                   | Separas entrenamiento de inferencia.                                        |
| ğŸš€ ProducciÃ³n                    | Es el formato estÃ¡ndar para desplegar modelos en entornos reales.           |

---

### âŒ Â¿CuÃ¡ndo NO usar `.pkl`?

- Si necesitas interoperabilidad con otros lenguajes (usa `JSON`, `Parquet`, `ONNX`).
- Si el archivo serÃ¡ leÃ­do por humanos (usa `CSV`, `JSON`).
- Si la seguridad es crÃ­tica y los archivos vienen de fuentes externas.

 
Un archivo **`.pkl` es como una "foto" de un objeto de Python que puedes guardar y restaurar despuÃ©s. Es esencial en machine learning para no perder horas de entrenamiento y mantener consistencia entre preparaciÃ³n y predicciÃ³n.**

---
---

## 11. Bonus: Logging, ConfiguraciÃ³n y Manejo de Errores

### ğŸ“ Logging

```python
import logging

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler("app.log"),
        logging.StreamHandler()
    ]
)

logging.info("AplicaciÃ³n iniciada")
logging.error("Error al conectar a la base de datos")
```

### Archivo de configuraciÃ³n (`config.ini`)

```ini
[DATABASE]
path = tareas.db

[LOGGING]
level = INFO
```

```python
import configparser

config = configparser.ConfigParser()
config.read("config.ini")
db_path = config["DATABASE"]["path"]
```

### Manejo de errores

```python
import logging

def dividir(a, b):
    try:
        return a / b
    except ZeroDivisionError:
        logging.error("DivisiÃ³n por cero intentada")
        return None
    except Exception as e:
        logging.error(f"Error inesperado: {e}")
        raise

print(dividir(10, 0))
```

---

