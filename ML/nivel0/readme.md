# üêç Curso Pr√°ctico de Python para Gesti√≥n de Datos y Machine Learning
Nivel 0 - nivelaci√≥n
https://github.com/evalenciEAFIT/formacion_python/tree/main/ML/nivel0
[üìö Nivel 0](https://github.com/evalenciEAFIT/formacion_python/tree/main/ML/nivel0) | 
[üîç Nivel 1](https://github.com/evalenciEAFIT/formacion_python/tree/main/ML/nivel1) | 
[üè† Repositorio](https://github.com/evalenciEAFIT/formacion_python)

## Tabla de Contenidos

1. C√≥mo pasar par√°metros por CLI al inicio
2. Buenas Pr√°cticas de Programaci√≥n en Python (incluyendo `main`)
3. Entornos Virtuales: Definici√≥n y Justificaci√≥n
4. Estructuras de Datos B√°sicas: Ventajas y Desventajas
5. Almacenamiento en Archivos Planos
6. Bases de Datos Relacionales (SQLite)
7. An√°lisis de Datos con Pandas
8. Gesti√≥n Avanzada de Archivos
9. Ejemplo Integrado: Sistema de Tareas
10. Preparaci√≥n de Datos para Machine Learning
11. Bonus: Logging, Configuraci√≥n y Manejo de Errores

---

## 1. C√≥mo pasar par√°metros por CLI al inicio

Permitir que tu programa reciba argumentos desde la **l√≠nea de comandos (CLI)** es esencial para:
- Automatizaci√≥n
- Scripts reutilizables
- Integraci√≥n con otros sistemas
- Pruebas sin modificar el c√≥digo

### Opci√≥n 1: Usando `sys.argv` (simple)

```python
# cli_simple.py
import sys

def main():
    if len(sys.argv) < 2:
        print("Uso: python cli_simple.py <nombre> [edad]")
        sys.exit(1)

    nombre = sys.argv[1]
    edad = sys.argv[2] if len(sys.argv) > 2 else "desconocida"

    print(f"Hola {nombre}, tienes {edad} a√±os.")

if __name__ == "__main__":
    main()
```

**Ejecuci√≥n:**

```bash
Comando:
python cli_simple.py Ana 25

Salida:
Hola Ana, tienes 25 a√±os.
```

---

### Opci√≥n 2: Usando `argparse` (recomendado para proyectos serios)

```python
# cli_avanzado.py
import argparse

def main():
    parser = argparse.ArgumentParser(description="Sistema de gesti√≥n de tareas por CLI")
    parser.add_argument("--nombre", "-n", type=str, required=True, help="Tu nombre")
    parser.add_argument("--edad", "-e", type=int, default=0, help="Tu edad (opcional)")
    parser.add_argument("--verbose", "-v", action="store_true", help="Mostrar logs detallados")

    args = parser.parse_args()

    if args.verbose:
        print("[INFO] Modo verboso activado")

    print(f"¬°Hola {args.nombre}!")
    if args.edad > 0:
        print(f"Tienes {args.edad} a√±os.")

if __name__ == "__main__":
    main()
```

**Ejecuci√≥n:**

```bash
Comando:
python cli_avanzado.py -n "Carlos" -e 30 -v

Salida:
[INFO] Modo verboso activado
¬°Hola Carlos!
Tienes 30 a√±os.
```

---

### Consejos para CLI

- Usa `--help` o `-h` para que argparse genere ayuda autom√°tica.
- Valida tipos de datos (`type=int`, `type=float`, etc.).
- Define valores por defecto (`default=...`).
- Agrupa argumentos con `add_argument_group` si son muchos.
- Para ML: recibe rutas de archivos, hiperpar√°metros, modos (train/test), etc.

---

## 2. Buenas Pr√°cticas de Programaci√≥n en Python (incluyendo `main`)
### ¬øPor qu√© importa?
- Legibilidad
- Mantenibilidad
- Reusabilidad
- Evitar efectos secundarios al importar

### Recomendaciones

```python
# Buen ejemplo: uso de if __name__ == "__main__"
def saludar(nombre):
    return f"Hola, {nombre}!"

def main():
    nombre = input("Ingresa tu nombre: ")
    print(saludar(nombre))

if __name__ == "__main__":
    main()
```

### Consejos Adicionales

- Usa nombres descriptivos: `calcular_promedio()` mejor que `calc()`
- Divide en m√≥dulos y paquetes cuando crezca el proyecto

---

## 3. Entornos Virtuales: Definici√≥n y Justificaci√≥n

### ¬øQu√© es un entorno virtual?
Un entorno virtual es un espacio aislado donde puedes instalar paquetes sin afectar el sistema global ni otros proyectos.

### ¬øPor qu√© usarlo?
- Evita conflictos de versiones entre proyectos
- Facilita la replicabilidad (`requirements.txt`)
- Ideal para colaboraci√≥n y despliegue

### C√≥mo crear uno

```bash
# Crear entorno
python -m venv mi_entorno

# Activar (Windows)
mi_entorno\Scripts\activate

# Activar (Linux/Mac)
source mi_entorno/bin/activate

# Instalar paquetes
pip install pandas numpy

# Guardar dependencias
pip freeze > requirements.txt

# Desactivar
deactivate
```

> **Tip**: Usa `pipenv` o `poetry` para gesti√≥n avanzada de dependencias.

---

## 4. Estructuras de Datos B√°sicas: Ventajas y Desventajas

| Estructura | Mutable | Ordenada | Duplicados | Uso t√≠pico | Ventajas | Desventajas |
|------------|---------|----------|------------|------------|----------|-------------|
| `list`     | ‚úÖ      | ‚úÖ       | ‚úÖ         | Secuencias | Din√°mica, indexada | Lenta en b√∫squedas grandes |
| `tuple`    | ‚ùå      | ‚úÖ       | ‚úÖ         | Datos inmutables | R√°pida, segura | No modificable |
| `set`      | ‚úÖ      | ‚ùå       | ‚ùå         | Eliminar duplicados | B√∫squedas O(1) | Sin orden, no indexado |
| `dict`     | ‚úÖ      | ‚úÖ (3.7+) | ‚ùå claves  | Mapeos clave-valor | Acceso r√°pido por clave | Mayor consumo de memoria |

### Ejemplo pr√°ctico

```python
# Lista: agregar tareas
tareas = ["Comprar leche", "Estudiar Python"]
tareas.append("Hacer ejercicio")

# Tupla: coordenadas geogr√°ficas
coordenadas = (19.4326, -99.1332)

# Set: eliminar duplicados
emails = ["a@b.com", "c@d.com", "a@b.com"]
unicos = set(emails)  # {'a@b.com', 'c@d.com'}

# Diccionario: perfil de usuario
usuario = {
    "nombre": "Ana",
    "edad": 25,
    "activo": True
}
```

---

## 5. Almacenamiento en Archivos Planos

### Escribir y leer archivos `.txt`

```python
# Escribir
with open("notas.txt", "w", encoding="utf-8") as f:
    f.write("Primera l√≠nea\nSegunda l√≠nea")

# Leer
with open("notas.txt", "r", encoding="utf-8") as f:
    contenido = f.read()
    print(contenido)
```

### CSV: Comma Separated Values

```python
import csv

# Escribir CSV
datos = [["Nombre", "Edad"], ["Ana", 25], ["Luis", 30]]
with open("personas.csv", "w", newline="", encoding="utf-8") as f:
    writer = csv.writer(f)
    writer.writerows(datos)

# Leer CSV
with open("personas.csv", "r", encoding="utf-8") as f:
    reader = csv.reader(f)
    for row in reader:
        print(row)
```

> Usa `csv.DictReader` y `csv.DictWriter` para trabajar con diccionarios.

---

## 6. Bases de Datos Relacionales (SQLite)

### ¬øPor qu√© SQLite?
- Liviana, sin servidor
- Ideal para prototipos y aplicaciones peque√±as
- Soportada nativamente en Python

### Ejemplo pr√°ctico: CRUD b√°sico

```python
import sqlite3
from contextlib import contextmanager

# Gestor de contexto para conexi√≥n segura
@contextmanager
def obtener_conexion(db_path="tareas.db"):
    """Maneja la conexi√≥n a la base de datos de forma segura."""
    conn = sqlite3.connect(db_path)
    conn.row_factory = sqlite3.Row  # Permite acceder a columnas por nombre
    try:
        yield conn
    except sqlite3.Error as e:
        print(f"‚ùå Error en la base de datos: {e}")
        conn.rollback()
        raise
    finally:
        conn.close()

# Crear tabla si no existe
def crear_tabla():
    with obtener_conexion() as conn:
        conn.execute("""
            CREATE TABLE IF NOT EXISTS tareas (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                titulo TEXT NOT NULL,
                completada INTEGER DEFAULT 0,
                fecha_creacion TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        conn.commit()
        print("Tabla 'tareas' creada o ya existente.")

# INSERTAR: Crear nueva tarea
def crear_tarea(titulo):
    with obtener_conexion() as conn:
        try:
            cursor = conn.execute(
                "INSERT INTO tareas (titulo) VALUES (?)",
                (titulo,)
            )
            conn.commit()
            print(f"‚úÖ Tarea creada con ID: {cursor.lastrowid} ‚Üí '{titulo}'")
            return cursor.lastrowid
        except sqlite3.Error as e:
            print(f"‚ùå Error al crear tarea: {e}")
            return None

# LEER: Listar todas las tareas
def listar_tareas():
    with obtener_conexion() as conn:
        cursor = conn.execute("""
            SELECT id, titulo, completada, fecha_creacion
            FROM tareas
            ORDER BY fecha_creacion DESC
        """)
        tareas = cursor.fetchall()
        
        if not tareas:
            print("No hay tareas registradas.")
            return []
        
        print(f"\nLISTA DE TAREAS ({len(tareas)}):")
        print("-" * 60)
        for tarea in tareas:
            estado = "‚úÖ Completada" if tarea["completada"] else "‚ùå Pendiente"
            print(f"ID: {tarea['id']} | {tarea['titulo']} | {estado} | Creada: {tarea['fecha_creacion']}")
        print("-" * 60)
        return tareas

# ACTUALIZAR: Marcar tarea como completada
def actualizar_tarea(id_tarea, completada=True):
    with obtener_conexion() as conn:
        cursor = conn.execute(
            "UPDATE tareas SET completada = ? WHERE id = ?",
            (1 if completada else 0, id_tarea)
        )
        conn.commit()
        
        if cursor.rowcount == 0:
            print(f"‚ö† No se encontr√≥ tarea con ID: {id_tarea}")
            return False
        else:
            estado = "completada" if completada else "marcada como pendiente"
            print(f"Tarea ID {id_tarea} {estado}.")
            return True

# ELIMINAR: Borrar tarea por ID
def eliminar_tarea(id_tarea):
    with obtener_conexion() as conn:
        cursor = conn.execute("DELETE FROM tareas WHERE id = ?", (id_tarea,))
        conn.commit()
        
        if cursor.rowcount == 0:
            print(f"‚ö† No se encontr√≥ tarea con ID: {id_tarea}")
            return False
        else:
            print(f"Tarea ID {id_tarea} eliminada.")
            return True

# BUSCAR: Buscar tarea por t√≠tulo (b√∫squeda parcial)
def buscar_tarea_por_titulo(palabra_clave):
    with obtener_conexion() as conn:
        cursor = conn.execute(
            "SELECT id, titulo, completada, fecha_creacion FROM tareas WHERE titulo LIKE ?",
            (f"%{palabra_clave}%",)
        )
        resultados = cursor.fetchall()
        
        if not resultados:
            print(f"No se encontraron tareas con '{palabra_clave}'.")
            return []
        
        print(f"\nRESULTADOS PARA '{palabra_clave}' ({len(resultados)}):")
        print("-" * 60)
        for tarea in resultados:
            estado = "‚úÖ Completada" if tarea["completada"] else "‚ùå Pendiente"
            print(f"ID: {tarea['id']} | {tarea['titulo']} | {estado} | Creada: {tarea['fecha_creacion']}")
        print("-" * 60)
        return resultados

# Funci√≥n principal de demostraci√≥n
def main():
    print("INICIANDO DEMO CRUD CON SQLITE...\n")
    
    # 1. Crear tabla
    crear_tabla()
    
    # 2. Insertar tareas
    id1 = crear_tarea("Aprender SQL")
    id2 = crear_tarea("Practicar Python")
    id3 = crear_tarea("Hacer ejercicio")
    
    print("\n" + "="*60)
    
    # 3. Listar todas
    listar_tareas()
    
    print("\n" + "="*60)
    
    # 4. Actualizar (marcar como completada)
    actualizar_tarea(id1, completada=True)
    actualizar_tarea(id2, completada=True)
    
    print("\n" + "="*60)
    
    # 5. Listar nuevamente
    listar_tareas()
    
    print("\n" + "="*60)
    
    # 6. Buscar por palabra clave
    buscar_tarea_por_titulo("Python")
    
    print("\n" + "="*60)
    
    # 7. Eliminar una tarea
    eliminar_tarea(id3)
    
    print("\n" + "="*60)
    
    # 8. Listar final
    listar_tareas()

# Ejecutar demo
if __name__ == "__main__":
    main()
```

> Usa par√°metros `?` para evitar inyecciones SQL.

---

## 7. An√°lisis de Datos con Pandas

### Instalaci√≥n

```bash
pip install pandas matplotlib
```

### Ejemplo: An√°lisis de ventas

```python
import pandas as pd

# Crear DataFrame
data = {
    "Producto": ["A", "B", "C", "A"],
    "Ventas": [100, 150, 200, 120],
    "Mes": ["Ene", "Ene", "Feb", "Feb"]
}
df = pd.DataFrame(data)

# Operaciones comunes
print(df.head())
print(df.groupby("Producto")["Ventas"].sum())
print(df[df["Ventas"] > 130])

# Guardar y cargar
df.to_csv("ventas.csv", index=False)
df_cargado = pd.read_csv("ventas.csv")
```

### Visualizaci√≥n r√°pida

```python
import matplotlib.pyplot as plt

df.groupby("Producto")["Ventas"].sum().plot(kind="bar")
plt.title("Ventas por Producto")
plt.show()
```

---

## 8. Gesti√≥n Avanzada de Archivos

### 8.0.  Manejo de fechas en nombres de archivos

```python
from datetime import datetime

hoy = datetime.now().strftime("%Y%m%d_%H%M%S")
nombre = f"backup_{hoy}.zip"
print(nombre)  # backup_20250405_103045.zip
```


###  8.1. Recorrer Directorios (con `pathlib` ‚Äî forma moderna y recomendada)

###  Ejemplo: `listar_csv_en_directorio.py`

```python
from pathlib import Path

def listar_archivos_csv(ruta_directorio="datasets"):
    """
    Lista todos los archivos .csv en un directorio.
    Si el directorio no existe, lo crea vac√≠o.
    """
    directorio = Path(ruta_directorio)
    
    # Crear directorio si no existe
    directorio.mkdir(exist_ok=True)
    print(f" Buscando archivos CSV en: '{directorio.absolute()}'\n")

    # Obtener todos los .csv
    archivos_csv = list(directorio.glob("*.csv"))
    
    if not archivos_csv:
        print(" No se encontraron archivos .csv")
        return []

    print(f" Encontrados {len(archivos_csv)} archivos CSV:")
    print("-" * 50)
    for i, archivo in enumerate(archivos_csv, 1):
        # archivo.name ‚Üí solo nombre
        # archivo.stem ‚Üí nombre sin extensi√≥n
        # archivo.suffix ‚Üí extensi√≥n
        print(f"{i:2}. {archivo.name} (Tama√±o: {archivo.stat().st_size} bytes)")

    return archivos_csv

#  Ejecutar ejemplo
if __name__ == "__main__":
    listar_archivos_csv()
```

###  Salida esperada (si tienes `ventas.csv`, `personas.csv`):

```
 Buscando archivos CSV en: 'C:\tu_proyecto\datasets'

 Encontrados 2 archivos CSV:
--------------------------------------------------
 1. ventas.csv (Tama√±o: 128 bytes)
 2. personas.csv (Tama√±o: 85 bytes)
```

---

###  8.2. Crear Directorios (con estructura anidada)

###  Ejemplo: `crear_estructura_proyecto.py`

```python
from pathlib import Path

def crear_estructura_datos():
    """
    Crea una estructura t√≠pica para gesti√≥n de datos.
    """
    estructura = [
        "data/raw",
        "data/processed",
        "data/external",
        "backups",
        "logs",
        "exports"
    ]

    print("Creando estructura de directorios...")
    for carpeta in estructura:
        Path(carpeta).mkdir(parents=True, exist_ok=True)
        print(f" {carpeta}/ creado")

    print("\n Estructura final:")
    for item in Path(".").glob("data*/"):
        print(f"  ‚îî‚îÄ‚îÄ {item}")
```

###  Salida esperada:

```
Creando estructura de directorios...
 data/raw/ creado
 data/processed/ creado
 data/external/ creado
 backups/ creado
 logs/ creado
 exports/ creado

 Estructura final:
  ‚îî‚îÄ‚îÄ data/
```

---

###  8.3. Comprimir Archivos en ZIP (con manejo de errores)

###  Ejemplo: `comprimir_csvs.py`

```python
from pathlib import Path
import zipfile
from datetime import datetime

def comprimir_archivos_csv(origen="datasets", destino="backups"):
    """
    Comprime todos los .csv de un directorio en un ZIP con timestamp.
    """
    directorio_origen = Path(origen)
    directorio_destino = Path(destino)
    
    # Crear directorio de destino
    directorio_destino.mkdir(exist_ok=True)

    # Buscar CSVs
    archivos_csv = list(directorio_origen.glob("*.csv"))
    if not archivos_csv:
        print(f"‚ö† No hay archivos .csv en '{origen}' para comprimir.")
        return None

    # Nombre con fecha y hora
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    nombre_zip = directorio_destino / f"backup_csv_{timestamp}.zip"

    print(f" Creando backup: {nombre_zip.name}")
    print("-" * 50)

    try:
        with zipfile.ZipFile(nombre_zip, "w", zipfile.ZIP_DEFLATED) as zf:
            for archivo in archivos_csv:
                zf.write(archivo, arcname=archivo.name)  # arcname evita rutas largas
                print(f"   + {archivo.name} ({archivo.stat().st_size} bytes)")

        print(f"\n ¬°Compresi√≥n exitosa! Tama√±o total: {nombre_zip.stat().st_size} bytes")
        return nombre_zip

    except Exception as e:
        print(f" Error al comprimir: {e}")
        return None

# Ejecutar ejemplo
if __name__ == "__main__":
    comprimir_archivos_csv()
```

###  Salida esperada:

```
Creando backup: backup_csv_20250504_123045.zip
--------------------------------------------------
   + ventas.csv (128 bytes)
   + personas.csv (85 bytes)

¬°Compresi√≥n exitosa! Tama√±o total: 427 bytes
```


### 8.4. Descomprimir Archivos ZIP (con manejo de errores y limpieza)

###  Ejemplo: `descomprimir_backup.py`

```python
from pathlib import Path
import zipfile

def descomprimir_zip(ruta_zip, destino="restaurado"):
    """
    Descomprime un archivo .zip en una carpeta espec√≠fica.
    """
    archivo_zip = Path(ruta_zip)
    directorio_destino = Path(destino)

    # Verificar que el ZIP existe
    if not archivo_zip.exists():
        print(f" El archivo {ruta_zip} no existe.")
        return False

    # Crear carpeta de destino
    directorio_destino.mkdir(exist_ok=True)

    try:
        with zipfile.ZipFile(archivo_zip, "r") as zf:
            print(f" Descomprimiendo {archivo_zip.name} en '{directorio_destino}/'...")
            zf.extractall(directorio_destino)
            
            # Listar archivos extra√≠dos
            extraidos = list(directorio_destino.iterdir())
            print(f" {len(extraidos)} archivos extra√≠dos:")
            for archivo in extraidos:
                print(f"   - {archivo.name}")
                
        return True

    except zipfile.BadZipFile:
        print(" El archivo no es un ZIP v√°lido.")
        return False
    except Exception as e:
        print(f" Error al descomprimir: {e}")
        return False

#  Ejecutar ejemplo
if __name__ == "__main__":
    # Suponiendo que ya ejecutaste el ejemplo anterior y generaste un .zip
    backups = list(Path("backups").glob("*.zip"))
    if backups:
        ultimo_backup = sorted(backups)[-1]  # el m√°s reciente
        descomprimir_zip(ultimo_backup, "datos_restaurados")
    else:
        print(" No hay backups disponibles para restaurar.")
```

### Salida esperada:

```
 Descomprimiendo backup_csv_20250504_123045.zip en 'datos_restaurados/'...
 2 archivos extra√≠dos:
   - ventas.csv
   - personas.csv
```

---

### 8.5. Bonus: Copiar, Mover y Eliminar Archivos

### Ejemplo: `gestion_archivos_bonus.py`

```python
from pathlib import Path
import shutil

def copiar_csv_a_procesados(origen="datasets", destino="data/processed"):
    """Copia todos los .csv al directorio 'processed'."""
    Path(destino).mkdir(parents=True, exist_ok=True)
    
    for csv in Path(origen).glob("*.csv"):
        destino_path = Path(destino) / csv.name
        shutil.copy2(csv, destino_path)  # copy2 copia tambi√©n metadatos
        print(f" Copiado: {csv.name} ‚Üí {destino_path}")

def mover_csv_a_raw(origen="datasets", destino="data/raw"):
    """Mueve (no copia) los CSVs al directorio 'raw'."""
    Path(destino).mkdir(parents=True, exist_ok=True)
    
    for csv in Path(origen).glob("*.csv"):
        destino_path = Path(destino) / csv.name
        shutil.move(csv, destino_path)
        print(f" Movido: {csv.name} ‚Üí {destino_path}")

def limpiar_directorio_vacio(ruta):
    """Elimina un directorio si est√° vac√≠o."""
    carpeta = Path(ruta)
    if carpeta.exists() and not any(carpeta.iterdir()):
        carpeta.rmdir()
        print(f" Directorio vac√≠o eliminado: {ruta}")
```


### Ejecuci√≥n Recomendada (para probar todo en orden)

Crea un script `ejecutar_gestion_archivos.py`:

```python
from pathlib import Path

# 1. Crear estructura
from crear_estructura_proyecto import crear_estructura_datos
crear_estructura_datos()

print("\n" + "="*60 + "\n")

# 2. Listar CSVs
from listar_csv_en_directorio import listar_archivos_csv
listar_archivos_csv()

print("\n" + "="*60 + "\n")

# 3. Comprimir
from comprimir_csvs import comprimir_archivos_csv
zip_creado = comprimir_archivos_csv()

print("\n" + "="*60 + "\n")

# 4. Descomprimir
if zip_creado:
    from descomprimir_backup import descomprimir_zip
    descomprimir_zip(zip_creado, "datos_restaurados")

print("\n" + "="*60 + "\n")

# 5. Copiar a processed
from gestion_archivos_bonus import copiar_csv_a_procesados
copiar_csv_a_procesados()
```
---

### Estructura Final del Proyecto

```
gestion_archivos/
‚îú‚îÄ‚îÄ datasets/
‚îÇ   ‚îú‚îÄ‚îÄ ventas.csv
‚îÇ   ‚îî‚îÄ‚îÄ personas.csv
‚îú‚îÄ‚îÄ listar_csv_en_directorio.py
‚îú‚îÄ‚îÄ crear_estructura_proyecto.py
‚îú‚îÄ‚îÄ comprimir_csvs.py
‚îú‚îÄ‚îÄ descomprimir_backup.py
‚îú‚îÄ‚îÄ gestion_archivos_bonus.py
‚îî‚îÄ‚îÄ ejecutar_gestion_archivos.py  ‚Üê ¬°Ejecuta todo en orden!
```

---

## 9. Ejemplo Integrado: Sistema de Tareas

> Un sistema modular, profesional y listo para usar, con SQLite, CLI, logging, validaci√≥n y buenas pr√°cticas.

---
## üì• ¬øC√≥mo empezar?

1. Crea la carpeta `sistema_tareas/`
2. Guarda los 4 archivos: `main.py`, `database.py`, `models.py`, `utils.py`
3. Ejecuta:

```bash
python main.py -h
```
---
## üìÅ Estructura del Proyecto (Actualizada)

```
sistema_tareas/
‚îú‚îÄ‚îÄ main.py          ‚Üê CLI principal (mejorado)
‚îú‚îÄ‚îÄ database.py      ‚Üê CRUD completo + migraciones
‚îú‚îÄ‚îÄ models.py        ‚Üê Clase Tarea
‚îú‚îÄ‚îÄ utils.py         ‚Üê ¬°AHORA INCLUIDO! (validaci√≥n, logging, ayuda)
‚îî‚îÄ‚îÄ tareas.db        ‚Üê se crea autom√°ticamente
```

---

## üìÑ 9.1. `models.py` ‚Äî Clase Tarea (sin cambios, pero completo)

```python
class Tarea:
    def __init__(self, id, titulo, completada=False):
        self.id = id
        self.titulo = titulo
        self.completada = bool(completada)  # Asegura tipo booleano

    def __str__(self):
        estado = "‚úÖ" if self.completada else "‚ùå"
        return f"{self.id:2}. {self.titulo:<30} {estado}"

    def __repr__(self):
        return f"Tarea(id={self.id}, titulo='{self.titulo}', completada={self.completada})"
```

---

## üìÑ 9.2. `database.py` ‚Äî CRUD Completo + Migraciones

```python

import sqlite3
from contextlib import contextmanager
from pathlib import Path
from models import Tarea  # ‚úÖ ¬°IMPORTANTE! Sin esto, 'Tarea' no existe

@contextmanager
def obtener_conexion(db_path="tareas.db"):
    """Gestiona conexi√≥n segura a la base de datos."""
    conn = sqlite3.connect(db_path)
    conn.row_factory = sqlite3.Row
    try:
        yield conn
    except sqlite3.Error as e:
        print(f"‚ùå Error en la base de datos: {e}")
        conn.rollback()
        raise
    finally:
        conn.close()

def crear_tabla():
    """Crea la tabla si no existe."""
    with obtener_conexion() as conn:
        conn.execute("""
            CREATE TABLE IF NOT EXISTS tareas (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                titulo TEXT NOT NULL,
                completada INTEGER DEFAULT 0,
                fecha_creacion TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        conn.commit()

def agregar_columna_fecha_si_no_existe():
    """Agrega columna 'fecha_creacion' si no existe (migraci√≥n)."""
    with obtener_conexion() as conn:
        cursor = conn.execute("PRAGMA table_info(tareas)")
        columnas = [col[1] for col in cursor.fetchall()]
        if "fecha_creacion" not in columnas:
            conn.execute("ALTER TABLE tareas ADD COLUMN fecha_creacion TIMESTAMP DEFAULT CURRENT_TIMESTAMP")
            conn.commit()

class TareaDB:
    def __init__(self, db_path="tareas.db"):
        self.db_path = db_path
        Path(db_path).touch(exist_ok=True)  # Crea archivo si no existe
        crear_tabla()
        agregar_columna_fecha_si_no_existe()

    def agregar(self, titulo):
        with obtener_conexion(self.db_path) as conn:
            cursor = conn.execute("INSERT INTO tareas (titulo) VALUES (?)", (titulo,))
            conn.commit()
            return cursor.lastrowid

    def listar(self):
        with obtener_conexion(self.db_path) as conn:
            cursor = conn.execute("""
                SELECT id, titulo, completada 
                FROM tareas 
                ORDER BY id DESC
            """)
            # ‚úÖ Ahora 'Tarea' est√° definido gracias al import
            return [Tarea(row["id"], row["titulo"], row["completada"]) for row in cursor.fetchall()]

    def completar(self, id_tarea):
        with obtener_conexion(self.db_path) as conn:
            cursor = conn.execute("UPDATE tareas SET completada = 1 WHERE id = ?", (id_tarea,))
            conn.commit()
            return cursor.rowcount > 0

    def eliminar(self, id_tarea):
        with obtener_conexion(self.db_path) as conn:
            cursor = conn.execute("DELETE FROM tareas WHERE id = ?", (id_tarea,))
            conn.commit()
            return cursor.rowcount > 0

    def buscar(self, palabra):
        with obtener_conexion(self.db_path) as conn:
            cursor = conn.execute(
                "SELECT id, titulo, completada FROM tareas WHERE titulo LIKE ?",
                (f"%{palabra}%",)
            )
            return [Tarea(row["id"], row["titulo"], row["completada"]) for row in cursor.fetchall()]

```

---

## üìÑ 9.3. `utils.py`

```python
import logging
import argparse

def configurar_logging(nivel=logging.INFO):
    """Configura el sistema de logging para la aplicaci√≥n."""
    logging.basicConfig(
        level=nivel,
        format="%(asctime)s - %(levelname)s - %(message)s",
        handlers=[
            logging.FileHandler("sistema_tareas.log", encoding="utf-8"),
            logging.StreamHandler()
        ]
    )

def validar_titulo(titulo):
    """Valida que el t√≠tulo no est√© vac√≠o y tenga longitud razonable."""
    if not titulo or not titulo.strip():
        raise ValueError("‚ùå El t√≠tulo no puede estar vac√≠o.")
    if len(titulo) > 200:
        raise ValueError("‚ùå El t√≠tulo es demasiado largo (m√°x. 200 caracteres).")
    return titulo.strip()

def mostrar_ayuda_personalizada():
    """Muestra una ayuda amigable con emojis y ejemplos."""
    ayuda = """
üåü SISTEMA DE GESTI√ìN DE TAREAS üåü

Uso:
  python main.py [OPCI√ìN]

Opciones:
  -a, --agregar TEXTO     ‚ûï Agregar nueva tarea
  -l, --listar            üìã Listar todas las tareas
  -c, --completar ID      ‚úÖ Marcar tarea como completada
  -e, --eliminar ID       üóëÔ∏è  Eliminar tarea por ID
  -b, --buscar PALABRA    üîç Buscar tareas por palabra clave
  -v, --verbose           üì¢ Modo detallado (muestra logs)
  -h, --help              ‚ùì Mostrar esta ayuda

Ejemplos:
  python main.py -a "Estudiar Python"
  python main.py -l
  python main.py -c 1
  python main.py -b "Python"
"""
    print(ayuda)
```

---

## üìÑ 9.4. `main.py` 

```python
import argparse
from database import TareaDB
from models import Tarea
from utils import configurar_logging, validar_titulo, mostrar_ayuda_personalizada
import logging

def main():
    parser = argparse.ArgumentParser(add_help=False)  # Desactivamos ayuda autom√°tica
    parser.add_argument("--agregar", "-a", type=str, help="Agregar nueva tarea")
    parser.add_argument("--listar", "-l", action="store_true", help="Listar tareas")
    parser.add_argument("--completar", "-c", type=int, help="Completar tarea por ID")
    parser.add_argument("--eliminar", "-e", type=int, help="Eliminar tarea por ID")
    parser.add_argument("--buscar", "-b", type=str, help="Buscar tareas por palabra clave")
    parser.add_argument("--verbose", "-v", action="store_true", help="Modo detallado")
    parser.add_argument("--help", "-h", action="store_true", help="Mostrar ayuda")

    args = parser.parse_args()

    # Configurar logging
    nivel = logging.INFO if args.verbose else logging.WARNING
    configurar_logging(nivel)

    # Mostrar ayuda personalizada
    if args.help:
        mostrar_ayuda_personalizada()
        return

    # Inicializar base de datos
    db = TareaDB()

    try:
        if args.agregar:
            titulo = validar_titulo(args.agregar)
            id_nueva = db.agregar(titulo)
            print(f"‚úÖ Tarea agregada con ID {id_nueva}: '{titulo}'")
            logging.info(f"Tarea agregada: ID {id_nueva}, '{titulo}'")

        elif args.listar:
            tareas = db.listar()
            if not tareas:
                print("üì≠ No hay tareas registradas.")
            else:
                print(f"\nüìã LISTA DE TAREAS ({len(tareas)}):")
                print("=" * 60)
                for tarea in tareas:
                    print(tarea)
                print("=" * 60)

        elif args.completar is not None:
            if db.completar(args.completar):
                print(f"‚úÖ Tarea ID {args.completar} marcada como completada.")
                logging.info(f"Tarea completada: ID {args.completar}")
            else:
                print(f"‚ö†Ô∏è  No se encontr√≥ tarea con ID {args.completar}.")

        elif args.eliminar is not None:
            if db.eliminar(args.eliminar):
                print(f"üóëÔ∏è  Tarea ID {args.eliminar} eliminada.")
                logging.info(f"Tarea eliminada: ID {args.eliminar}")
            else:
                print(f"‚ö†Ô∏è  No se encontr√≥ tarea con ID {args.eliminar}.")

        elif args.buscar:
            resultados = db.buscar(args.buscar)
            if not resultados:
                print(f"üîç No se encontraron tareas con '{args.buscar}'.")
            else:
                print(f"\nüîé RESULTADOS PARA '{args.buscar}' ({len(resultados)}):")
                print("=" * 60)
                for tarea in resultados:
                    print(tarea)
                print("=" * 60)

        else:
            mostrar_ayuda_personalizada()

    except ValueError as ve:
        print(ve)
        logging.error(f"Error de validaci√≥n: {ve}")
    except Exception as e:
        print(f"‚ùå Error inesperado: {e}")
        logging.error(f"Error inesperado: {e}")

if __name__ == "__main__":
    main()
```

---

## üß™ Ejecuci√≥n y Salidas Esperadas

### ‚ûï Agregar tarea

```bash
python main.py -a "Aprender Pandas"
```
```
‚úÖ Tarea agregada con ID 1: 'Aprender Pandas'
```

### üìã Listar tareas

```bash
python main.py -l
```
```
üìã LISTA DE TAREAS (2):
============================================================
 1. Aprender Pandas                     ‚úÖ
 2. Hacer ejercicio                     ‚ùå
============================================================
```

### ‚úÖ Completar tarea

```bash
python main.py -c 2
```
```
‚úÖ Tarea ID 2 marcada como completada.
```

### üóëÔ∏è Eliminar tarea

```bash
python main.py -e 1
```
```
üóëÔ∏è  Tarea ID 1 eliminada.
```

### üîç Buscar tarea

```bash
python main.py -b "Pandas"
```
```
üîé RESULTADOS PARA 'Pandas' (1):
============================================================
 3. Aprender Pandas                     ‚úÖ
============================================================
```

### ‚ùì Mostrar ayuda

```bash
python main.py -h
```
```
üåü SISTEMA DE GESTI√ìN DE TAREAS üåü

Uso:
  python main.py [OPCI√ìN]

Opciones:
  -a, --agregar TEXTO     ‚ûï Agregar nueva tarea
  -l, --listar            üìã Listar todas las tareas
  -c, --completar ID      ‚úÖ Marcar tarea como completada
  -e, --eliminar ID       üóëÔ∏è  Eliminar tarea por ID
  -b, --buscar PALABRA    üîç Buscar tareas por palabra clave
  -v, --verbose           üì¢ Modo detallado (muestra logs)
  -h, --help              ‚ùì Mostrar esta ayuda

Ejemplos:
  python main.py -a "Estudiar Python"
  python main.py -l
  python main.py -c 1
  python main.py -b "Python"
```

---

## üìÑ Archivo de Log Generado (`sistema_tareas.log`)

```
2025-05-04 14:30:45,123 - INFO - Tarea agregada: ID 1, 'Aprender Pandas'
2025-05-04 14:31:10,456 - INFO - Tarea completada: ID 2
2025-05-04 14:32:05,789 - INFO - Tarea eliminada: ID 1
```

---


## 10. Preparaci√≥n de Datos para Machine Learning
> Aprende a limpiar, transformar y preparar tus datos para modelos de ML ‚Äî con c√≥digo listo para producci√≥n, manejo de errores y buenas pr√°cticas.

## üì¶ 10.1. Gu√≠a para Instalar Paquetes Necesarios

### ‚úÖ Opci√≥n 1: Instalaci√≥n manual (recomendada para aprendizaje)

```bash
# Activa tu entorno virtual primero (si lo usas)
# En Windows:
mi_entorno\Scripts\activate

# En Linux/Mac:
source mi_entorno/bin/activate

# Instala los paquetes esenciales
pip install pandas scikit-learn joblib numpy matplotlib
```

### ‚úÖ Opci√≥n 2: Usar `requirements.txt` (recomendado para proyectos y colaboraci√≥n)

Crea un archivo `requirements.txt` en la ra√≠z de tu proyecto:

```txt
# requirements.txt
pandas>=2.0.0
scikit-learn>=1.3.0
joblib>=1.3.0
numpy>=1.24.0
matplotlib>=3.7.0
```

Luego ejecuta:

```bash
pip install -r requirements.txt
```

> üí° **Tip profesional**: Siempre fija versiones m√≠nimas para evitar incompatibilidades.

---

## üßπ 10.2. Limpieza y Preparaci√≥n de Datos ‚Äî Script Completo y Robusto

### üìÑ `src/data_preprocessing.py`

```python
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
import joblib
import logging
import os
from pathlib import Path

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler("preprocessing.log", encoding="utf-8"),
        logging.StreamHandler()
    ]
)

def cargar_datos(ruta):
    """Carga un CSV y valida que exista."""
    if not os.path.exists(ruta):
        raise FileNotFoundError(f"‚ùå Archivo no encontrado: {ruta}")
    
    logging.info(f"üìÇ Cargando datos desde: {ruta}")
    df = pd.read_csv(ruta)
    logging.info(f"üìä Forma inicial: {df.shape}")
    return df

def explorar_datos(df):
    """Muestra informaci√≥n b√°sica del dataset."""
    print("\nüîç INFORMACI√ìN DEL DATASET:")
    print("=" * 50)
    print("Columnas:", list(df.columns))
    print("\n‚ùì Valores nulos por columna:")
    print(df.isnull().sum())
    print(f"\nüìà Tipos de datos:\n{df.dtypes}")
    print(f"\nüìâ Descripci√≥n estad√≠stica:\n{df.describe(include='all').T}")

def limpiar_datos(df):
    """Limpia el dataset paso a paso."""
    logging.info("üßπ Iniciando limpieza de datos...")

    # 1. Eliminar filas con m√°s del 50% de valores nulos
    umbral = len(df.columns) * 0.5
    df = df.dropna(thresh=umbral)
    logging.info(f"üóëÔ∏è  Filas eliminadas por muchos nulos. Nueva forma: {df.shape}")

    # 2. Rellenar Edad (si existe)
    if "Edad" in df.columns:
        if df["Edad"].isnull().any():
            mediana_edad = df["Edad"].median()
            df["Edad"] = df["Edad"].fillna(mediana_edad)
            logging.info(f"üßì Edad rellenada con mediana: {mediana_edad}")

    # 3. Rellenar Ingreso (si existe)
    if "Ingreso" in df.columns:
        if df["Ingreso"].isnull().any():
            media_ingreso = df["Ingreso"].mean()
            df["Ingreso"] = df["Ingreso"].fillna(media_ingreso)
            logging.info(f"üí∞ Ingreso rellenado con media: {media_ingreso:.2f}")

    # 4. Codificar variables categ√≥ricas
    columnas_categoricas = df.select_dtypes(include=["object"]).columns.tolist()
    columnas_categoricas = [col for col in columnas_categoricas if col != "Nombre"]  # Excluir identificadores

    if columnas_categoricas:
        logging.info(f"üî§ Codificando variables categ√≥ricas: {columnas_categoricas}")
        df = pd.get_dummies(df, columns=columnas_categoricas, prefix_sep="_", dummy_na=True)

    return df

def escalar_datos(df, columnas_numericas=None):
    """Escala columnas num√©ricas usando StandardScaler."""
    if columnas_numericas is None:
        columnas_numericas = ["Edad", "Ingreso"]
    
    # Filtrar solo columnas que existan
    columnas_numericas = [col for col in columnas_numericas if col in df.columns]
    
    if not columnas_numericas:
        logging.warning("‚ö†Ô∏è  No hay columnas num√©ricas para escalar.")
        return df, None

    scaler = StandardScaler()
    df[columnas_numericas] = scaler.fit_transform(df[columnas_numericas])
    logging.info(f"üìè Columnas escaladas: {columnas_numericas}")
    
    return df, scaler

def guardar_datos(df, ruta_salida):
    """Guarda el dataset limpio."""
    # Asegurar que el directorio exista
    Path(ruta_salida).parent.mkdir(parents=True, exist_ok=True)
    
    df.to_csv(ruta_salida, index=False, encoding="utf-8")
    logging.info(f"‚úÖ Datos limpios guardados en: {ruta_salida}")
    return ruta_salida

def main():
    try:
        # Rutas (ajusta seg√∫n tu estructura)
        RUTA_ENTRADA = "data/raw/datos_sucios.csv"
        RUTA_SALIDA = "data/processed/datos_limpios.csv"
        RUTA_SCALER = "models/scaler.pkl"

        # Crear estructura de directorios
        for carpeta in ["data/raw", "data/processed", "models", "logs"]:
            Path(carpeta).mkdir(parents=True, exist_ok=True)

        # Proceso completo
        df = cargar_datos(RUTA_ENTRADA)
        explorar_datos(df)
        
        df_limpio = limpiar_datos(df)
        df_limpio, scaler = escalar_datos(df_limpio)
        
        guardar_datos(df_limpio, RUTA_SALIDA)
        
        if scaler:
            joblib.dump(scaler, RUTA_SCALER)
            logging.info(f"üíæ Scaler guardado en: {RUTA_SCALER}")

        print(f"\nüéâ ¬°Proceso completado exitosamente!")
        print(f"‚úÖ Datos limpios: {RUTA_SALIDA}")
        print(f"‚úÖ Scaler guardado: {RUTA_SCALER}")

    except Exception as e:
        logging.error(f"üí• Error durante el procesamiento: {e}")
        raise

if __name__ == "__main__":
    main()
```

---

## üìÇ10.3. Estructura de Proyecto Recomendada

```
proyecto_ml/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ datos_sucios.csv          ‚Üê ¬°Desc√°rgalo del curso!
‚îÇ   ‚îî‚îÄ‚îÄ processed/
‚îÇ       ‚îî‚îÄ‚îÄ datos_limpios.csv         ‚Üê ¬°Se genera autom√°ticamente!
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ scaler.pkl                    ‚Üê ¬°Se genera autom√°ticamente!
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ data_preprocessing.py         ‚Üê Script principal
‚îú‚îÄ‚îÄ logs/
‚îÇ   ‚îî‚îÄ‚îÄ preprocessing.log             ‚Üê Registro de ejecuci√≥n
‚îú‚îÄ‚îÄ requirements.txt                  ‚Üê Dependencias
‚îî‚îÄ‚îÄ README.md                         ‚Üê Instrucciones
```

---

## üß™ 10.4. Ejecuci√≥n Paso a Paso

### Paso 1: Crear entorno virtual (opcional pero recomendado)

```bash
python -m venv ml_entorno
ml_entorno\Scripts\activate    # Windows
source ml_entorno/bin/activate # Linux/Mac
```

### Paso 2: Instalar dependencias

```bash
pip install -r requirements.txt
```

### Paso 3: Colocar `datos_sucios.csv` en `data/raw/`

> Si no lo tienes, aqu√≠ est√° el contenido m√≠nimo para probar:

```csv
Nombre,Edad,Categoria,Ingreso
Ana,25,A,3500
Luis,,B,4200
Maria,30,,5000
Juan,22,A,
,28,C,3800
```

### Paso 4: Ejecutar el script

```bash
python src/data_preprocessing.py
```

### ‚úÖ Salida esperada:

```
2025-05-04 16:30:45,123 - INFO - üìÇ Cargando datos desde: data/raw/datos_sucios.csv
2025-05-04 16:30:45,456 - INFO - üìä Forma inicial: (5, 4)
...
2025-05-04 16:30:46,789 - INFO - üßì Edad rellenada con mediana: 25.0
2025-05-04 16:30:46,890 - INFO - üí∞ Ingreso rellenado con media: 4125.00
2025-05-04 16:30:47,001 - INFO - üî§ Codificando variables categ√≥ricas: ['Categoria']
2025-05-04 16:30:47,112 - INFO - üìè Columnas escaladas: ['Edad', 'Ingreso']
2025-05-04 16:30:47,223 - INFO - ‚úÖ Datos limpios guardados en: data/processed/datos_limpios.csv
2025-05-04 16:30:47,334 - INFO - üíæ Scaler guardado en: models/scaler.pkl

üéâ ¬°Proceso completado exitosamente!
‚úÖ Datos limpios: data/processed/datos_limpios.csv
‚úÖ Scaler guardado: models/scaler.pkl
```

---

## üìÑ 10.5. Archivo `requirements.txt` Completo

```txt
# requirements.txt - Proyecto de Preparaci√≥n de Datos para ML

# Procesamiento de datos
pandas>=2.0.0
numpy>=1.24.0

# Machine Learning
scikit-learn>=1.3.0

# Serializaci√≥n
joblib>=1.3.0

# Visualizaci√≥n (opcional)
matplotlib>=3.7.0

# Para notebooks (opcional)
jupyter>=1.0.0
```

---

## üß© 10.6. Bonus: Script para Verificar Instalaci√≥n

Crea `verificar_instalacion.py`:

```python
def verificar_paquetes():
    paquetes = ["pandas", "sklearn", "joblib", "numpy"]
    todos_instalados = True
    
    print("üîç Verificando instalaci√≥n de paquetes...\n")
    
    for paquete in paquetes:
        try:
            __import__(paquete)
            print(f"‚úÖ {paquete} - INSTALADO")
        except ImportError:
            print(f"‚ùå {paquete} - NO INSTALADO")
            todos_instalados = False
    
    if todos_instalados:
        print("\nüéâ ¬°Todos los paquetes est√°n instalados correctamente!")
    else:
        print("\n‚ö†Ô∏è  Algunos paquetes faltan. Ejecuta: pip install -r requirements.txt")

if __name__ == "__main__":
    verificar_paquetes()
```

Ejec√∫talo con:

```bash
python verificar_instalacion.py
```

---
## CLARIDAD de pkl
### üì¶ ¬øQu√© es un archivo `.pkl` y para qu√© sirve?

---

### Definici√≥n simple

Un archivo con extensi√≥n **`.pkl`** es un archivo **serializado en formato "pickle"**, que permite **guardar y cargar objetos de Python** (como modelos de machine learning, estructuras de datos, scalers, etc.) **en disco**, para usarlos m√°s tarde sin tener que volver a crearlos o entrenarlos.

> El nombre viene de **"pickle"** ‚Äî el m√≥dulo de Python que se encarga de la serializaci√≥n.

---

### ¬øQu√© significa "serializar"?

**Serializar** = Convertir un objeto en memoria (como un modelo entrenado, una lista, un diccionario, un scaler, etc.) en una secuencia de bytes que se puede guardar en un archivo o enviar por red.

**Deserializar** = Hacer el proceso inverso: leer esos bytes y reconstruir el objeto original en memoria.

---

### üÜö `pickle` vs `joblib`

Ambos sirven para lo mismo, pero:

| Caracter√≠stica          | `pickle` (built-in)           | `joblib` (recomendado para ML)       |
|-------------------------|-------------------------------|--------------------------------------|
| Velocidad               | üê¢ M√°s lento con arrays NumPy | üêá M√°s r√°pido con arrays NumPy       |
| Tama√±o de archivo       | M√°s grande                    | M√°s compacto                         |
| Uso t√≠pico              | Objetos peque√±os              | Modelos, datasets, scalers grandes   |
| Compatibilidad          | Nativo en Python              | Necesita `pip install joblib`        |

> ‚úÖ **Recomendaci√≥n profesional**: Usa **`joblib`** para machine learning. Es m√°s eficiente y es el est√°ndar en la comunidad (scikit-learn lo usa internamente).

---

### ‚ö†Ô∏è Advertencias de seguridad

**NUNCA cargues un `.pkl` de fuente no confiable.**

El formato pickle puede ejecutar c√≥digo arbitrario al deserializar. Solo usa archivos `.pkl` generados por ti o por fuentes de confianza.

> üîê Para entornos de producci√≥n o APIs, considera formatos m√°s seguros como `JSON`, `HDF5`, o formatos de modelo como `ONNX`.

---

### üìÅ Ejemplo pr√°ctico: Flujo t√≠pico en ML

```bash
proyecto_ml/
‚îú‚îÄ‚îÄ train.py           # Entrena y guarda modelo.pkl + scaler.pkl
‚îú‚îÄ‚îÄ predict.py         # Carga modelo.pkl + scaler.pkl y predice
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ modelo.pkl
‚îÇ   ‚îî‚îÄ‚îÄ scaler.pkl
‚îî‚îÄ‚îÄ data/
    ‚îî‚îÄ‚îÄ nuevos_datos.csv
```


### üéØ ¬øPor qu√© usar `.pkl`?

| Ventaja                           | Explicaci√≥n                                                                 |
|-----------------------------------|-----------------------------------------------------------------------------|
| ‚è±Ô∏è Ahorra tiempo                 | No necesitas reentrenar modelos cada vez que ejecutas tu app.               |
| üíæ Persistencia                  | Guardas el estado exacto de un objeto complejo.                             |
| üîÑ Consistencia                  | Aseguras que usas los mismos par√°metros/preprocesadores en train y predict. |
| üß© Modularidad                   | Separas entrenamiento de inferencia.                                        |
| üöÄ Producci√≥n                    | Es el formato est√°ndar para desplegar modelos en entornos reales.           |

---

### ‚ùå ¬øCu√°ndo NO usar `.pkl`?

- Si necesitas interoperabilidad con otros lenguajes (usa `JSON`, `Parquet`, `ONNX`).
- Si el archivo ser√° le√≠do por humanos (usa `CSV`, `JSON`).
- Si la seguridad es cr√≠tica y los archivos vienen de fuentes externas.

 
Un archivo **`.pkl` es como una "foto" de un objeto de Python que puedes guardar y restaurar despu√©s. Es esencial en machine learning para no perder horas de entrenamiento y mantener consistencia entre preparaci√≥n y predicci√≥n.**

---
---

## 11. Bonus: Logging, Configuraci√≥n y Manejo de Errores

### üìù Logging

```python
import logging

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler("app.log"),
        logging.StreamHandler()
    ]
)

logging.info("Aplicaci√≥n iniciada")
logging.error("Error al conectar a la base de datos")
```

### Archivo de configuraci√≥n (`config.ini`)

```ini
[DATABASE]
path = tareas.db

[LOGGING]
level = INFO
```

```python
import configparser

config = configparser.ConfigParser()
config.read("config.ini")
db_path = config["DATABASE"]["path"]
```

### Manejo de errores

```python
import logging

def dividir(a, b):
    try:
        return a / b
    except ZeroDivisionError:
        logging.error("Divisi√≥n por cero intentada")
        return None
    except Exception as e:
        logging.error(f"Error inesperado: {e}")
        raise

print(dividir(10, 0))
```

---

